In this document I gave an example of how partial knowledge can be utilized for model identification. First, in Section~\ref{sec:MSR3} we developed an optimization algorithm for feature selection in mixed-effect models. We showed how complex prior knowledge can be embedded into the model via proximal operator and the resulting model can be minimized using a proximal gradient descent. To tackle ill-conditioning arising from such combination of priors we propose a MSR3 relaxation and prove that its solution approaches the solution of the original problem as the relaxation tightens. Next, we showed how a partial knowledge of physics can be embedded into a reduced-order models. We achieve it by projecting true dynamics into a chosen latent space and requiring the gradient field in that space matching the expected dynamics. We show that this methodology helps to identify more stable latent manifolds. It leads to more accurate predictions and lesser sensitivity to noise. We also showed how the ROMs above can be used for compressive sensing and showed that they accurately reconstruct the dynamics from partial observations, significantly surpassing current state-of-the-are methods. 

\paragraph{Perspective Research Directions} Due to the limited resources many directions were left for future work. First, given the success of SR3 framework in linear and linear mixed-effect models it should be extended to generalized linear and generalized mixed-effects models. The fundamental difficulty that arises in such extension is the absence of closed-form marginal log-likelihood. It implies that when one applies an SR3 relaxation on top of the likelihood they would have three nested levels of optimization. A solution for such obstacle could be in re-using the recipe that we developed in Section~\ref{sec:MSR3}. Namely, Algorithm~\ref{alg:pgd_for_value} had two nested optimization methods: for evaluating the value function and for optimizing over it. However we showed that one can ``blend'' both levels of optimization and achieve superior performance results. The same methodology of ``blending'' could possibly be applied to more than two nested optimization loops.

	Our developments in PINODE are also incomplete and invite future work in several promising directions. First, a more systematic way of choosing collocation points would greatly benefit the framework. In Section~\ref{sec:collocations_conditions} we define collocation points and provide a criteria which a good choice of colocations meets. However, we ultimately leave the reader without a constructive algorithm of identifying a collocation family suitable for their problem. At the same time, it has been known that for certain families of differential equations there are basis functions that can span their solutions. Such basis functions frequently poses easily-computable derivatives, which makes them perfect candidates for collocation points for PINODE. Bridging the gap between this new methodology and those classic results would undoubtedly yield a fruitful line of works. Finally, one could utilize PINODE models not only in compressive sensing applications but in any application where one needs to quickly search over a large space of possible simulations. These examples include applications such as medical imaging, model discovery, and online control.
