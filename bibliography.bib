@article{IHME2020covidnature,
abstract = {We use COVID-19 case and mortality data from 1 February 2020 to 21 September 2020 and a deterministic SEIR (susceptible, exposed, infectious and recovered) compartmental framework to model possible trajectories of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infections and the effects of non-pharmaceutical interventions in the United States at the state level from 22 September 2020 through 28 February 2021. Using this SEIR model, and projections of critical driving covariates (pneumonia seasonality, mobility, testing rates and mask use per capita), we assessed scenarios of social distancing mandates and levels of mask use. Projections of current non-pharmaceutical intervention strategies by state—with social distancing mandates reinstated when a threshold of 8 deaths per million population is exceeded (reference scenario)—suggest that, cumulatively, 511,373 (469,578–578,347) lives could be lost to COVID-19 across the United States by 28 February 2021. We find that achieving universal mask use (95{\%} mask use in public) could be sufficient to ameliorate the worst effects of epidemic resurgences in many states. Universal mask use could save an additional 129,574 (85,284–170,867) lives from September 22, 2020 through the end of February 2021, or an additional 95,814 (60,731–133,077) lives assuming a lesser adoption of mask wearing (85{\%}), when compared to the reference scenario.},
author = {{IHME COVID-19 Forecasting Team}},
doi = {10.1038/s41591-020-1132-9},
issn = {1078-8956},
journal = {Nature Medicine},
mendeley-groups = {Other},
month = {oct},
title = {{Modeling COVID-19 scenarios for the United States}},
url = {http://www.nature.com/articles/s41591-020-1132-9},
year = {2020}
}

@article{Hui2017,
author = {Hui, Francis K.C. and M{\"{u}}ller, Samuel and Welsh, A. H.},
doi = {10.1080/01621459.2016.1215989},
file = {:Users/aksh/Documents/Papers/2017/Hui, M{\"{u}}ller, Welsh/Joint Selection in Mixed Models using Regularized PQL/Hui, M{\"{u}}ller, Welsh - 2017 - Joint Selection in Mixed Models using Regularized PQL.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Fixed effects,Generalized linear mixed models,Lasso,Penalized likelihood,Quasi-likelihood,Variable selection},
mendeley-groups = {Feature/Effects Selection},
number = {519},
pages = {1323--1333},
title = {{Joint Selection in Mixed Models using Regularized PQL}},
volume = {112},
year = {2017}
}


@misc{IHME2020Projections,
author = {IHME},
booktitle = {IHME COVID-19 Projections},
mendeley-groups = {Other},
title = {{IHME COVID-19 Projections}},
url = {https://covid19.healthdata.org/global},
year = {2020}
}

@article{sholokhov2023pysr3,
  title={pysr3: A Python Package for Sparse Relaxed Regularized Regression},
  author={Sholokhov, Aleksei and Zheng, Peng and Aravkin, Aleksandr},
  journal={Journal of Open Source Software},
  volume={8},
  number={84},
  pages={5155},
  year={2023}
}

@article{Zheng2018RelaxAndSplit,
abstract = {We develop and analyze a new 'relax-and-split' (RS) approach for inverse problems modeled using nonsmooth nonconvex optimization formulations. RS uses a relaxation technique together with partial minimization, and brings classic techniques including direct factorization, matrix decompositions, and fast iterative methods to bear on nonsmooth nonconvex problems. We also extend the approach to robustify any such inverse problem through trimming, a mechanism that robustifies inverse problems to measurement outliers. We then show practical performance of RS and trimmed RS (TRS) on a diverse set of problems, including: (1) phase retrieval, (2) semi-supervised classification, (3) stochastic shortest path problems, and (4) nonconvex clustering. RS/TRS are easy to implement, competitive with existing methods, and show promising results on difficult inverse problems with nonsmooth and nonconvex features.},
author = {Zheng, Peng and Aravkin, Aleksandr},
doi = {10.1088/1361-6420/aba417},
file = {:Users/aksh/Documents/Papers/2020/Zheng, Aravkin/Relax-and-split method for nonconvex inverse problems Relax-and-split method for nonconvex/Zheng, Aravkin - 2020 - Relax-and-split method for nonconvex inverse problems Relax-and-split method for nonconvex.pdf:pdf},
issn = {13616420},
journal = {Inverse Problems},
keywords = {nonconvex optimization,nonsmooth models,splitting methods},
mendeley-groups = {Relax-and-Split examples},
number = {9},
publisher = {IOP Publishing},
title = {{Relax-and-split method for nonconvex inverse problems}},
volume = {36},
year = {2020}
}

@misc{aravkin2022jimtheory,
      title={Analysis of Relaxation Methods for Feature Selection in Mixed Effects Models}, 
      author={Aleksandr Aravkin and James Burke and Aleksei Sholokhov and Peng Zheng},
      year={2022},
      eprint={2209.10575},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@misc{sholokhov2022relaxation,
      title={A Relaxation Approach to Feature Selection for Linear Mixed Effects Models}, 
      author={Aleksei Sholokhov and James V. Burke and Damian F. Santomauro and Peng Zheng and Aleksandr Aravkin},
      year={2022},
      eprint={2205.06925},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@article{grant2014converting,
  title={Converting an odds ratio to a range of plausible relative risks for better communication of research findings},
  author={Grant, Robert L},
  journal={Bmj},
  volume={348},
  year={2014},
  publisher={British Medical Journal Publishing Group}
}

@article{vanderbei99,
title={An Interior-Point Algorithm for Nonconvex Nonlinear Programming},
author={Vanderbei, Robert and David Shanno}, 
journal={Comp. Opt, and Appl.}, 
volume={13},
year={1999},
pages={231-252}
}

@article{zheng2022burden,
  title={The Burden of Proof studies: assessing the evidence of risk},
  author={Zheng, Peng and Afshin, Ashkan and Biryukov, Stan and Bisignano, Catherine and Brauer, Michael and Bryazka, Dana and Burkart, Katrin and Cercy, Kelly M and Cornaby, Leslie and Dai, Xiaochen and others},
  journal={Nature Medicine},
  volume={28},
  number={10},
  pages={2038--2044},
  year={2022},
  publisher={Nature Publishing Group US New York}
}
@article{lescinsky2022health,
  title={Health effects associated with consumption of unprocessed red meat: a Burden of Proof study},
  author={Lescinsky, Haley and Afshin, Ashkan and Ashbaugh, Charlie and Bisignano, Catherine and Brauer, Michael and Ferrara, Giannina and Hay, Simon I and He, Jiawei and Iannucci, Vincent and Marczak, Laurie B and others},
  journal={Nature Medicine},
  volume={28},
  number={10},
  pages={2075--2082},
  year={2022},
  publisher={Nature Publishing Group US New York}
}
@article{razo2022effects,
  title={Effects of elevated systolic blood pressure on ischemic heart disease: a Burden of Proof study},
  author={Razo, Christian and Welgan, Catherine A and Johnson, Catherine O and McLaughlin, Susan A and Iannucci, Vincent and Rodgers, Anthony and Wang, Nelson and LeGrand, Kate E and Sorensen, Reed JD and He, Jiawei and others},
  journal={Nature Medicine},
  volume={28},
  number={10},
  pages={2056--2065},
  year={2022},
  publisher={Nature Publishing Group US New York}
}
@article{stanaway2022health,
  title={Health effects associated with vegetable consumption: a Burden of Proof study},
  author={Stanaway, Jeffrey D and Afshin, Ashkan and Ashbaugh, Charlie and Bisignano, Catherine and Brauer, Michael and Ferrara, Giannina and Garcia, Vanessa and Haile, Demewoz and Hay, Simon I and He, Jiawei and others},
  journal={Nature Medicine},
  volume={28},
  number={10},
  pages={2066--2074},
  year={2022},
  publisher={Nature Publishing Group US New York}
}
@article{dai2022health,
  title={Health effects associated with smoking: a Burden of Proof study},
  author={Dai, Xiaochen and Gil, Gabriela F and Reitsma, Marissa B and Ahmad, Noah S and Anderson, Jason A and Bisignano, Catherine and Carr, Sinclair and Feldman, Rachel and Hay, Simon I and He, Jiawei and others},
  journal={Nature Medicine},
  volume={28},
  number={10},
  pages={2045--2055},
  year={2022},
  publisher={Nature Publishing Group US New York}
}


@article{wang2013converting,
  title={Converting odds ratio to relative risk in cohort studies with partial data information},
  author={Wang, Zhu},
  journal={Journal of Statistical Software},
  volume={55},
  pages={1--11},
  year={2013}
}

@article{murray1997understanding,
  title={Understanding DALYs},
  author={Murray, Christopher JL and Acharya, Arnab K},
  journal={Journal of health economics},
  volume={16},
  number={6},
  pages={703--730},
  year={1997},
  publisher={Elsevier}
}

@book{pinheiro2006mixed,
  title={Mixed-effects models in S and S-PLUS},
  author={Pinheiro, Jos{\'e} and Bates, Douglas},
  year={2006},
  publisher={Springer science \& business media}
}

@book{Wright-IP-book,
title={Primal-Dual Interior-Point Methods},
author={Stephen J. Wright},
year={1997},
publisher={SIAM}}

@article{Burke-Engle18,
title={Line Search and Trust-Region Methods for Convex-Composite Optimization
},
author={J.V. Burke and A. Engle},
journal={arXiv:1806.05218},
year={2018},
DOI={https://doi.org/10.48550/arXiv.1806.05218}}

@article{Practice,
title={A Relaxation Approach to Feature Selection for Linear Mixed Effects Models},
author={A. Sholokhov and J.V. Burke and D.F. Santomauro and P. Zheng and A. Aravkin},
journal={In Preparation},
year={2022}}

@article{Theory1,
title={Analysis of Relaxation Methods for Feature Selection in Mixed Effects Models},
author={A. Aravkin and J.V. Burke and A. Sholokhov and P. Zheng},
journal={https://arxiv.org/abs/2205.06925},
year={2022}}


@article{LS02,
title={Inverses of $2\times 2$ block matrices},
author={T.-T. Lu and S.-H. Shiou},
journal={Computers and Mathematics with Applications},
year={2002},
volume={43},
pages={119-129}}

@article{ABBP2021,
title={Algorithms for Block Tridiagonal Systems: Foundations and New Results for Generalized Kalman Smoothing},
author={Aravkin, A. and Burke, J.V. and Bell, B. and Pillonetto, G.},
journal={To appear in 19th IFAC Symposium on System Identification (SYSID 2021)},
year={2021}
}

@article{ABF13,
title={Variational Properties of Value Functions},
author={A.Y. Aravkin and J.V. Burke and M.P. Friedlander},
journal={SIAM J. on Opt.},
volume={23},
year={2013},
pages={1689 - 1717}
}

@article{ABDFM18,
title={Foundations of gauge and perspective duality},
author={A.Y. Aravkin and J.V. Burke and D. Drusvyatskyi and M.P. Friedlander and
K.J. Macphee},
journal={SIAM J. on Opt.},
volume={28},
year={2018},
pages={2406 - 2434}
}



@article{Kucukelbir2017,
abstract = {Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD), also called algorithmic differentiation or simply "autodiff", is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational fluid dynamics, atmospheric sciences, and engineering design optimization. Until very recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other's results. Despite its relevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names "dynamic computational graphs" and "differentiable programming". We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main implementation techniques. By precisely defining the main differentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms "autodiff", "automatic differentiation", and "symbolic differentiation" as these are encountered more and more in machine learning settings.},
archivePrefix = {arXiv},
arxivId = {1502.05767},
author = {Kucukelbir, Alp and Tran, Dustin and Ranganath, Rajesh and Gelman, Andrew and Blei, David M.},
doi = {10.1016/j.advwatres.2018.01.009},
eprint = {1502.05767},
file = {:Users/aksh/Downloads/17-468.pdf:pdf},
isbn = {0002-9645 (Print)$\backslash$r0002-9645 (Linking)},
issn = {03091708},
journal = {Journal of Machine Learning},
mendeley-groups = {Algorithmic Differentiation},
number = {14},
pages = {1--45},
pmid = {7020497},
title = {{Automatic Differentiation in Machine Learning: a Survey Atılım}},
url = {http://jmlr.org/papers/v18/16-107.html},
volume = {18},
year = {2017}
}

@article{tibshirani1996regression,
  title={Regression shrinkage and selection via the lasso},
  author={Tibshirani, Robert},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={58},
  number={1},
  pages={267--288},
  year={1996},
  publisher={Wiley Online Library}
}

@article{ibrahim2011fixed,
  title={Fixed and random effects selection in mixed effects models},
  author={Ibrahim, Joseph G and Zhu, Hongtu and Garcia, Ramon I and Guo, Ruixin},
  journal={Biometrics},
  volume={67},
  number={2},
  pages={495--503},
  year={2011},
  publisher={Wiley Online Library}
}

@Article{glmnet,
    title = {Regularization Paths for Generalized Linear Models via
      Coordinate Descent},
    author = {Jerome Friedman and Trevor Hastie and Robert Tibshirani},
    journal = {Journal of Statistical Software},
    year = {2010},
    volume = {33},
    number = {1},
    pages = {1--22},
    url = {https://www.jstatsoft.org/v33/i01/},
  }

@book{Shalev-Shwartz2014,
abstract = {Machine learning is one of the fastest growing areas of computer science, with far-reaching applications. The aim of this textbook is to introduce machine learning, and the algorithmic paradigms it offers, in a principled way. The book provides an extensive theoretical account of the fundamental ideas underlying machine learning and the mathematical derivations that transform these principles into practical algorithms. Following a presentation of the basics of the field, the book covers a wide array of central topics that have not been addressed by previous textbooks. These include a discussion of the computational complexity of learning and the concepts of convexity and stability; important algorithmic paradigms including stochastic gradient descent, neural networks, and structured output learning; and emerging theoretical concepts such as the PAC-Bayes approach and compression-based bounds. Designed for an advanced undergraduate or beginning graduate course, the text makes the fundamentals and algorithms of machine learning accessible to students and non-expert readers in statistics, computer science, mathematics, and engineering.},
address = {Cambridge},
author = {Shalev-Shwartz, Shai and Ben-David, Shai},
booktitle = {Understanding Machine Learning: From Theory to Algorithms},
doi = {10.1017/CBO9781107298019},
file = {:Users/aksh/Documents/Books/Машинное обучение и анализ данных /Про все и сразу/understanding-machine-learning-theory-algorithms.pdf:pdf},
isbn = {9781107298019},
mendeley-groups = {Essential Books},
pages = {1--397},
publisher = {Cambridge University Press},
title = {{Understanding Machine Learning}},
url = {http://ebooks.cambridge.org/ref/id/CBO9781107298019},
volume = {9781107057},
year = {2014}
}

@book{Hastie2017,
abstract = {During the past decade there has been an explosion in computation and information technology. With it has come a vast amount of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Hastie, Trevor and Tibshirani, Robert},
booktitle = {Math. Intell.},
doi = {111},
eprint = {arXiv:1011.1669v3},
isbn = {978-0-387-84857-0},
issn = {03436993},
mendeley-groups = {Essential Books},
pmid = {15512507},
title = {{The Elements of Statistical Learning Second Edition}},
year = {2017}
}

@article{Moody1992,
author = {Moody, John E},
mendeley-groups = {Other},
number = {1},
pages = {847--854},
title = {{The Effective Number of Parameters : An Analysis of Generalization and Regularization in Nonlinear Learning Systems}}
}

@incollection{Tipping2004,
author = {Tipping, Michael E.},
doi = {10.1007/978-3-540-28650-9_3},
file = {:Users/aksh/Downloads/bayesian{\_}regression{\_}overview.pdf:pdf},
mendeley-groups = {Bayesian Approach},
pages = {41--62},
title = {{Bayesian Inference: An Introduction to Principles and Practice in Machine Learning}},
url = {http://link.springer.com/10.1007/978-3-540-28650-9{\_}3},
year = {2004}
}

@article{Fox2006,
abstract = {Statistics lectures have been a source of much bewilderment and frustration for generations of students. This book attempts to remedy the situation by expounding a logical and unified approach to the whole subject of data analysis. This text is intended as a tutorial guide for senior undergraduates and research students in science and engineering. After explaining the basic principles of Bayesian probability theory, their use is illustrated with a variety of examples ranging from elementary parameter estimation to image processing. Other topics covered include reliability analysis, multivariate optimization, least-squares and maximum likelihood, error-propagation, hypothesis testing, maximum entropy and experimental design. The Second Edition of this successful tutorial book contains a new chapter on extensions to the ubiquitous least-squares procedure, allowing for the straightforward handling of outliers and unknown correlated noise, and a cutting-edge contribution from John Skilling on a novel numerical technique for Bayesian computation called 'nested sampling'.},
author = {Fox, Eric P. and Sivia, D. S.},
doi = {10.2307/1270652},
issn = {00401706},
journal = {Technometrics},
mendeley-groups = {Bayesian Approach},
title = {{Data Analysis: A Bayesian Tutorial}},
year = {2006}
}

@article{Mosegaard1995SamplingFromPosterior,
abstract = {Probabilistic formulation of inverse problems leads to the definition of a probability distribution in the model space. This probability distribution combines a priori information with new information obtained by measuring some observable parameters (data). As, in the general case, the theory linking data with model parameters is nonlinear, the a posteriori probability in the model space may not be easy to describe (it may be multimodal, some moments may not be defined, etc.). When analysing an inverse problem, obtaining a maximum likelihood model is usually not sufficient, as we normally also wish to have information on the resolution power of the data. In the general case we may have a large number of model parameters, and an inspection of the marginal probability densities of interest may be impractical, or even useless. But it is possible to pseudorandomly generate a large collection of models according to the posterior probability distribution and to analyse and display the models in such a way that information on the relative likelihoods of model properties is conveyed to the spectator. This can be accomplished by means of an efficient Monte Carlo method, even in cases where no explicit formula for the a priori distribution is available. The most well known importance sampling method, the Metropolis algorithm, can be generalized, and this gives a method that allows analysis of (possibly highly nonlinear) inverse problems with complex a priori information and data with an arbitrary noise distribution.},
author = {Mosegaard, Klaus and Tarantola, Albert},
doi = {10.1029/94jb03097},
file = {:Users/aksh/Documents/Papers/Mosegaard, Tarantola/1995/Journal of Geophysical Research Solid Earth/Mosegaard, Tarantola - 1995 - Monte Carlo sampling of solutions to inverse problems.pdf:pdf},
journal = {Journal of Geophysical Research: Solid Earth},
keywords = {doi:10.1029/9,http://dx.doi.org/10.1029/94JB03097},
mendeley-groups = {Bayesian Approach,Monte Carlo Methods},
number = {B7},
pages = {12431--12447},
title = {{Monte Carlo sampling of solutions to inverse problems}},
volume = {100},
year = {1995}
}

@article{Murray2017MeasuringGlobalHealth,
abstract = {The 2014-2015 outbreak of Ebola virus (EBOV), originating from Guinea, is now responsible for the infection of {\textgreater} 20,000 people in 9 countries. Whereas past filovirus outbreaks in sub-Saharan Africa have been rapidly brought under control with comparably few cases, this outbreak has been particularly resistant to containment efforts. Both the general population and primary health care workers have been affected by this outbreak, with hundreds of doctors and nurses being infected in the line of duty. In the absence of approved therapeutics, several caregivers have turned to investigational new drugs as well as experimental therapies in an effort to save lives. This review aims to summarize the candidates currently under consideration for postexposure use in infected patients during the largest EBOV outbreak in history.},
author = {Murray, Christopher J.L. and Lopez, Alan D.},
doi = {10.1016/S0140-6736(17)32367-X},
file = {:Users/aksh/Documents/Papers/Murray, Lopez/2017/The Lancet/Murray, Lopez - 2017 - Measuring global health motivation and evolution of the Global Burden of Disease Study.pdf:pdf},
issn = {1474547X},
journal = {The Lancet},
mendeley-groups = {Epidemiology Modelling},
number = {10100},
pages = {1460--1464},
publisher = {Elsevier Ltd},
title = {{Measuring global health: motivation and evolution of the Global Burden of Disease Study}},
url = {http://dx.doi.org/10.1016/S0140-6736(17)32367-X},
volume = {390},
year = {2017}
}

@article{Polson2019BayesianRegularization,
abstract = {Bayesian regularization is a central tool in modern-day statistical and machine learning methods. Many applications involve high-dimensional sparse signal recovery problems. The goal of our paper is to provide a review of the literature on penalty-based regularization approaches, from Tikhonov (Ridge, Lasso) to horseshoe regularization.},
archivePrefix = {arXiv},
arxivId = {arXiv:1902.06269v1},
author = {Polson, Nicholas G. and Sokolov, Vadim},
doi = {10.1002/wics.1463},
eprint = {arXiv:1902.06269v1},
file = {:Users/aksh/Documents/Papers/Polson, Sokolov/2019/Wiley Interdisciplinary Reviews Computational Statistics/Polson, Sokolov - 2019 - Bayesian regularization From Tikhonov to horseshoe.pdf:pdf},
issn = {19390068},
journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
keywords = {Bayesian regression,horseshoe,lasso,regularization},
mendeley-groups = {Bayesian Approach},
number = {4},
pages = {1--16},
title = {{Bayesian regularization: From Tikhonov to horseshoe}},
volume = {11},
year = {2019}
}

@article{Kuczera1998AssessmentOfParametersWithMCMC,
abstract = {Two Monte Carlo-based approaches for assessing parameter uncertainty in complex hydrologic models are considered. The first, known as importance sampling, has been implemented in the generalised likelihood uncertainty estimation (GLUE) framework of Beven and Binley. The second, known as the Metropolis algorithm, differs from importance sampling in that it uses a random walk that adapts to the true probability distribution describing parameter uncertainty. Three case studies are used to investigate and illustrate these Monte Carlo approaches. The first considers a simple water balance model for which exact results are known. It is shown that importance sampling is inferior to Metropolis sampling. Unless a large number of random samples are drawn, importance sampling can produce seriously misleading results. The second and third case studies consider more complex catchment models to illustrate the insights the Metropolis algorithm can offer. They demonstrate assessment of parameter uncertainty in the presence of bimodality, evaluation of the significance of split-sample tests, use of prior information and the assessment of confidence limits on hydrologic responses not used in calibration. When compared with the capabilities of traditional inference based on first-order approximation, the Metropolis algorithm provides a quantum advance in our capability to deal with parameter uncertainty in hydrologic models.},
author = {Kuczera, George and Parent, Eric},
doi = {10.1016/S0022-1694(98)00198-X},
file = {:Users/aksh/Documents/Papers/Kuczera, Parent/1998/Journal of Hydrology/Kuczera, Parent - 1998 - Monte Carlo assessment of parameter uncertainty in conceptual catchment models The Metropolis algorithm.pdf:pdf},
issn = {00221694},
journal = {Journal of Hydrology},
keywords = {Bayesian inference,Conceptual catchment models,Importance sampling,Markov Chain Monte Carlo sampling,Parameter uncertainty,Rainfall-runoff models},
mendeley-groups = {Monte Carlo Methods},
number = {1-4},
pages = {69--85},
title = {{Monte Carlo assessment of parameter uncertainty in conceptual catchment models: The Metropolis algorithm}},
volume = {211},
year = {1998}
}

@article{Carlin1995BayesianModelChoice,
abstract = {Markov chain Monte Carlo (MCMC) integration methods enable the fitting of models of virtually unlimited complexity, and as such have revolutionized the practice of Bayesian data analysis. However, comparison across models may not proceed in a completely analogous fashion, owing to violations of the conditions sufficient to ensure convergence of the Markov chain. In this paper we present a framework for Bayesian model choice, along with an MCMC algorithm that does not suffer from convergence difficulties. Our algorithm applies equally well to problems where only one model is contemplated but its proper size is not known at the outset, such as problems involving integer-valued parameters, multiple changepoints or finite mixture distributions. We illustrate our approach with two published examples.},
author = {Carlin, Bradley P. and Chib, Siddhartha},
doi = {10.1111/j.2517-6161.1995.tb02042.x},
file = {:Users/aksh/Documents/Papers/Carlin, Chib/1995/Journal of the Royal Statistical Society Series B (Methodological)/Carlin, Chib - 1995 - Bayesian Model Choice Via Markov Chain Monte Carlo Methods.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
keywords = {bayes factor,finite mixture model,gibbs sampler,integer-valued,models of varying size,multiple changepoint model,parameters},
mendeley-groups = {Monte Carlo Methods},
number = {3},
pages = {473--484},
title = {{Bayesian Model Choice Via Markov Chain Monte Carlo Methods}},
volume = {57},
year = {1995}
}


@article{attouch2013convergence,
  title={Convergence of descent methods for semi-algebraic and tame problems: proximal algorithms, forward--backward splitting, and regularized Gauss--Seidel methods},
  author={Attouch, Hedy and Bolte, J{\'e}r{\^o}me and Svaiter, Benar Fux},
  journal={Mathematical Programming},
  volume={137},
  number={1},
  pages={91--129},
  year={2013},
  publisher={Springer}
}

@book{rockafellar2009variational,
  title={Variational analysis},
  author={Rockafellar, R Tyrrell and Wets, Roger J-B},
  volume={317},
  year={2009},
  publisher={Springer Science \& Business Media}
}

@book{AB17,
title={First-Order Methods in Optimization},
author={Amir Beck},
isbn={9781611974980},
doi={10.1137/1.9781611974997},
year={2017},
series={MOS-SIAM Series on Optimization},
publisher={SIAM}
}

@misc{Abraham2015MetaregEpidemBook,
address = {Seattle},
author = {Abraham, D},
isbn = {9780295991849},
keywords = {Epidemiology -- Statistical methods,Meta-analysis,World health -- Statistical methods},
mendeley-groups = {Epidemiology Modelling},
publisher = {University of Washington Press},
series = {Publications on global health},
title = {{An integrative metaregression framework for descriptive epidemiology}},
year = {2015}
}

@book{Davison1998BootstrapMethods,
abstract = {Bootstrap methods are computer-intensive methods of statistical analysis, which use simulation to calculate standard errors, confidence intervals, and significance tests. The methods apply for any level of modelling, and so can be used for fully parametric, semiparametric, and completely nonparametric analysis. This 1997 book gives a broad and up-to-date coverage of bootstrap methods, with numerous applied examples, developed in a coherent way with the necessary theoretical basis. Applications include stratified data; finite populations; censored and missing data; linear, nonlinear, and smooth regression models; classification; time series and spatial problems. Special features of the book include: extensive discussion of significance tests and confidence intervals; material on various diagnostic methods; and methods for efficient computation, including improved Monte Carlo simulation. Each chapter includes both practical and theoretical exercises. S-Plus programs for implementing the methods described in the text are available from the supporting website.},
author = {Buckland, S. T. and Davison, A. C. and Hinkley, D. V.},
booktitle = {Biometrics},
doi = {10.2307/3109789},
issn = {0006341X},
mendeley-groups = {Bootstrap},
title = {{Bootstrap Methods and Their Application}},
year = {1998}
}


@article{bolte2014proximal,
  title={Proximal alternating linearized minimization for nonconvex and nonsmooth problems},
  author={Bolte, J{\'e}r{\^o}me and Sabach, Shoham and Teboulle, Marc},
  journal={Mathematical Programming},
  volume={146},
  number={1-2},
  pages={459--494},
  year={2014},
  publisher={Springer}
}


@article{lindstrom_newton-raphson_1988,
	title = {Newton-{Raphson} and {EM} {Algorithms} for {Linear} {Mixed}-{Effects} {Models} for {Repeated}-{Measures} {Data}},
	doi = {10.1080/01621459.1988.10478693},
	language = {en},
	author = {Lindstrom, Mary J and Bates, Douglas M},
	month = dec,
	year = {1988},
	pages = {10},
	file = {Lindstrom and Bates - Newton-Raphson and EM Algorithms for Linear Mixed-.pdf:/Users/aksh/Documents/Papers/storage/JSIEDAXD/Lindstrom and Bates - Newton-Raphson and EM Algorithms for Linear Mixed-.pdf:application/pdf}
}


@article{Harville1977ML,
	title = {Maximum {Likelihood} {Approaches} to {Variance} {Component} {Estimation} and to {Related} {Problems}},
	volume = {72},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1977.10480998},
	doi = {10/ggbzhj},
	language = {en},
	number = {358},
	urldate = {2019-10-29},
	journal = {Journal of the American Statistical Association},
	author = {Harville, David A.},
	month = jun,
	year = {1977},
	note = {ZSCC: 0002743},
	pages = {320--338},
	file = {Harville - 1977 - Maximum Likelihood Approaches to Variance Componen.pdf:/Users/aksh/Documents/Papers/storage/7LWJ8HF6/Harville - 1977 - Maximum Likelihood Approaches to Variance Componen.pdf:application/pdf}
}

@article{Jain2017,
abstract = {A vast majority of machine learning algorithms train their models and perform inference by solving optimization problems. In order to capture the learning and prediction problems accurately structural constraints such as sparsity or low rank are frequently imposed or else the objective itself is designed to be a non-convex function. This is especially true of algorithms that operate in high-dimensional spaces or that train non-linear models such as tensor models and deep networks. The freedom to express the learning problem as a non-convex optimization problem gives immense modeling power to the algorithm designer, but often such problems are NP-hard to solve. A popular workaround to this has been to relax non-convex problems to convex ones and use traditional methods to solve the (convex) relaxed optimization problems. However this approach may be lossy and nevertheless presents significant challenges for large scale optimization. On the other hand, direct approaches to non-convex optimization have met with resounding success in several domains and remain the methods of choice for the practitioner, as they frequently outperform relaxation-based techniques - popular heuristics include projected gradient descent and alternating minimization. However, these are often poorly understood in terms of their convergence and other properties. This monograph presents a selection of recent advances that bridge a long-standing gap in our understanding of these heuristics. We hope that an insight into the inner workings of these methods will allow the reader to appreciate the unique marriage of task structure and generative models that allow these heuristic techniques to (provably) succeed. The monograph will lead the reader through several widely used non-convex optimization techniques, as well as applications thereof. The goal of this monograph is to both, introduce the rich literature in this area, as well as equip the reader with the tools and techniques needed to analyze these simple procedures for non-convex problems.},
archivePrefix = {arXiv},
arxivId = {1712.07897},
author = {Jain, Prateek and Kar, Purushottam},
doi = {10.1561/2200000058},
eprint = {1712.07897},
file = {:Users/aksh/Downloads/1712.07897.pdf:pdf},
issn = {19358245},
journal = {Foundations and Trends in Machine Learning},
mendeley-groups = {Other},
number = {3-4},
pages = {142--336},
title = {{Non-convex optimization for machine learning}},
volume = {10},
year = {2017}
}

@article{Ueda2010,
abstract = {The regularized Newton method (RNM) is one of the efficient solution methods for the unconstrained convex optimization. It is well-known that the RNM has good convergence properties as compared to the steepest descent method and the pure Newton's method. For example, Li, Fukushima, Qi and Yamashita showed that the RNM has a quadratic rate of convergence under the local error bound condition. Recently, Polyak showed that the global complexity bound of the RNM, which is the first iteration k such that ∥ ∇ f(x k)∥ ≤ $\epsilon$, is O($\epsilon$ -4), where f is the objective function and $\epsilon$ is a given positive constant. In this paper, we consider a RNM extended to the unconstrained "nonconvex" optimization. We show that the extended RNM (E-RNM) has the following properties. (a) The E-RNM has a global convergence property under appropriate conditions. (b) The global complexity bound of the E-RNM is O($\epsilon$ -2) if ∇ 2 f is Lipschitz continuous on a certain compact set. (c) The E-RNM has a superlinear rate of convergence under the local error bound condition. {\textcopyright} 2009 Springer Science+Business Media, LLC.},
author = {Ueda, Kenji and Yamashita, Nobuo},
doi = {10.1007/s00245-009-9094-9},
file = {:Users/aksh/Downloads/Ueda-Yamashita2010{\_}Article{\_}ConvergencePropertiesOfTheRegu.pdf:pdf},
issn = {0095-4616},
journal = {Applied Mathematics and Optimization},
keywords = {Global complexity bound,Global convergence,Local error bound,Regularized Newton methods,Superlinear convergence},
mendeley-groups = {Second-Order Optimization Methods},
month = {aug},
number = {1},
pages = {27--46},
title = {{Convergence Properties of the Regularized Newton Method for the Unconstrained Nonconvex Optimization}},
url = {http://link.springer.com/10.1007/s00245-009-9094-9},
volume = {62},
year = {2010}
}

@article{Peng2012LMMSelectionOverview,
abstract = {Mixed effect models are fundamental tools for the analysis of longitudinal data, panel data and cross-sectional data. They are widely used by various fields of social sciences, medical and biological sciences. However, the complex nature of these models has made variable selection and parameter estimation a challenging problem. In this paper, we propose a simple iterative procedure that estimates and selects fixed and random effects for linear mixed models. In particular, we propose to utilize the partial consistency property of the random effect coefficients and select groups of random effects simultaneously via a data-oriented penalty function (the smoothly clipped absolute deviation penalty function). We show that the proposed method is a consistent variable selection procedure and possesses some oracle properties. Simulation studies and a real data analysis are also conducted to empirically examine the performance of this procedure. {\textcopyright} 2012 Elsevier Inc.},
author = {Peng, Heng and Lu, Ying},
doi = {10.1016/j.jmva.2012.02.005},
file = {:Users/aksh/Downloads/1-s2.0-S0047259X12000395-main.pdf:pdf},
issn = {0047259X},
journal = {Journal of Multivariate Analysis},
keywords = {Group selection,Model selection,Oracle property,Penalized least squares,SCAD function},
mendeley-groups = {Feature/Effects Selection},
pages = {109--129},
publisher = {Elsevier Inc.},
title = {{Model selection in linear mixed effect models}},
url = {http://dx.doi.org/10.1016/j.jmva.2012.02.005},
volume = {109},
year = {2012}
}

@article{Audenaert2010spectral,
  title={Spectral radius of Hadamard product versus conventional product for non-negative matrices},
  author={Audenaert, Koenraad MR},
  journal={Linear algebra and its applications},
  volume={432},
  number={1},
  pages={366--368},
  year={2010},
  publisher={Elsevier}
}

@article{Drnovvsek2016inequalities,
  title={Inequalities on the spectral radius and the operator norm of Hadamard products of positive operators on sequence spaces},
  author={Drnov{\v{s}}ek, Roman and Peperko, Aljo{\v{s}}a and others},
  journal={Banach Journal of Mathematical Analysis},
  volume={10},
  number={4},
  pages={800--814},
  year={2016},
  publisher={Tusi Mathematical Research Group}
}

@article{Muller2013,
abstract = {Linear mixed effects models are highly flexible in handling a broad range of data types and are therefore widely used in applications. A key part in the analysis of data is model selection, which often aims to choose a parsimonious model with other desirable properties from a possibly very large set of candidate statistical models. Over the last 5-10 years the literature on model selection in linear mixed models has grown extremely rapidly. The problem is much more complicated than in linear regression because selection on the covariance structure is not straightforward due to computational issues and boundary problems arising from positive semidefinite constraints on covariance matrices. To obtain a better understanding of the available methods, their properties and the relationships between them, we review a large body of literature on linear mixed model selection. We arrange, implement, discuss and compare model selection methods based on four major approaches: information criteria such as AIC or BIC, shrinkage methods based on penalized loss functions such as LASSO, the Fence procedure and Bayesian techniques. {\textcopyright} 2013 Institute of Mathematical Statistics.},
author = {M{\"{u}}ller, Samuel and Scealy, J. L. and Welsh, A. H.},
doi = {10.1214/12-STS410},
file = {:Users/aksh/Documents/Papers/2013/M{\"{u}}ller, Scealy, Welsh/Model selection in linear mixed models/M{\"{u}}ller, Scealy, Welsh - 2013 - Model selection in linear mixed models.pdf:pdf},
issn = {08834237},
journal = {Statistical Science},
keywords = {AIC,BIC,Bayes factor,Cholesky decomposition,Fence,Information criteria,LASSO,Linear mixed model,Model selection,Shrinkage methods},
mendeley-groups = {Feature/Effects Selection},
number = {2},
pages = {135--167},
title = {{Model selection in linear mixed models}},
volume = {28},
year = {2013}
}

@article{Feinleib2001,
author = {Feinleib, Manning},
doi = {10.1093/aje/154.1.93-a},
editor = {Porta, Miquel},
isbn = {9780199976720},
issn = {1476-6256},
journal = {American Journal of Epidemiology},
mendeley-groups = {Epidemiology Modelling,Essential Books},
month = {jul},
number = {1},
pages = {93--94},
publisher = {Oxford University Press},
title = {{A Dictionary of Epidemiology, Fourth Edition - Edited by John M. Last, Robert A. Spasoff, and Susan S. Harris}},
url = {http://www.oxfordreference.com/view/10.1093/acref/9780199976720.001.0001/acref-9780199976720 https://academic.oup.com/aje/article-lookup/doi/10.1093/aje/154.1.93-a},
volume = {154},
year = {2001}
}

@article{Harville1974,
author = {Harville, David A.},
doi = {10.1093/biomet/61.2.383},
issn = {0006-3444},
journal = {Biometrika},
mendeley-groups = {Fundamentals of Mixed Models},
number = {2},
pages = {383--385},
title = {{Bayesian inference for variance components using only error contrasts}},
url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/61.2.383},
volume = {61},
year = {1974}
}
@article{Patterson1971,
author = {Patterson, H. D. and Thompson, R.},
doi = {10.2307/2334389},
issn = {00063444},
journal = {Biometrika},
mendeley-groups = {Fundamentals of Mixed Models},
month = {dec},
number = {3},
pages = {545},
title = {{Recovery of Inter-Block Information when Block Sizes are Unequal}},
url = {https://www.jstor.org/stable/2334389?origin=crossref},
volume = {58},
year = {1971}
}

@article{Harville1976,
author = {Harville, David},
doi = {10.1214/aos/1176343414},
file = {:Users/aksh/Documents/Papers/1986/Efron/Institute of Mathematical Statistics is collaborating with JSTOR to digitize, preserve, and extend access to The Annals of Statistics..org/Efron - 1986 - Institute of Mathematical Statistics is collaborating with JSTOR to digitize, preserve, and extend access to The Annals.pdf:pdf},
issn = {0090-5364},
journal = {The Annals of Statistics},
mendeley-groups = {Fundamentals of Mixed Models},
month = {mar},
number = {2},
pages = {384--395},
title = {{Extension of the Gauss-Markov Theorem to Include the Estimation of Random Effects}},
url = {http://projecteuclid.org/euclid.aos/1176343414},
volume = {4},
year = {1976}
}

@article{Dempster1977,
abstract = {A series solution of the general three-dimensional equations of linear elasticity is used to find accurate natural frequencies and mode shapes for the flexural vibrations of thick free circular plates. The approximate solution for thick plates, which includes shear and rotary inertia effects, is compared with the accurate series solution. It is found that the approximate solution yields frequencies of sufficient accuracy for most engineering applications within the range of applicability of the approximate theory. {\textcopyright} 1979 by ASME.},
annote = {Creators of EM algorithm as a concept (Q-functions and all this stuff)},
author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
doi = {10.1111/j.2517-6161.1977.tb01600.x},
file = {:Users/aksh/Documents/Papers/1977/Dempster, Laird, Rubin/Maximum Likelihood from Incomplete Data Via the EM Algorithm/Dempster, Laird, Rubin - 1977 - Maximum Likelihood from Incomplete Data Via the EM Algorithm.pdf:pdf},
issn = {00359246},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
mendeley-groups = {EM-algorithm},
month = {sep},
number = {1},
pages = {1--22},
title = {{Maximum Likelihood from Incomplete Data Via the EM Algorithm}},
url = {http://doi.wiley.com/10.1111/j.2517-6161.1977.tb01600.x},
volume = {39},
year = {1977}
}

@article{Lindstrom1988,
author = {Lindstrom, Mary J. and Bates, Douglas M.},
doi = {10.2307/2290128},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Growth curve,Longitudinal data,Random effects},
mendeley-groups = {Optimization in MMs,Fundamentals of Mixed Models},
month = {dec},
number = {404},
pages = {1014},
title = {{Newton-Raphson and EM Algorithms for Linear Mixed-Effects Models for Repeated-Measures Data}},
url = {https://www.jstor.org/stable/2290128?origin=crossref},
volume = {83},
year = {1988}
}

@article{Tibshirani1996,
author = {Tibshirani, Robert},
doi = {10.1111/j.2517-6161.1996.tb02080.x},
issn = {00359246},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
mendeley-groups = {Feature/Effects Selection},
month = {jan},
number = {1},
pages = {267--288},
title = {{Regression Shrinkage and Selection Via the Lasso}},
url = {http://doi.wiley.com/10.1111/j.2517-6161.1996.tb02080.x},
volume = {58},
year = {1996}
}


@article{Xu2015,
abstract = {The goal of this paper is to develop a double penalized hierarchical likelihood (DPHL) with a modified Cholesky decomposition for simultaneously selecting fixed and random effects in mixed effects models. DPHL avoids the use of data likelihood, which usually involves a high-dimensional integral, to define an objective function for variable selection. The resulting DPHL-based estimator enjoys the oracle properties with no requirement on the convexity of loss function. Moreover, a two-stage algorithm is proposed to effectively implement this approach. An H-likelihood-based Bayesian information criterion (BIC) is developed for tuning parameter selection. Simulated data and a real data set are examined to illustrate the efficiency of the proposed method.},
author = {Xu, Peirong and Wang, Tao and Zhu, Hongtu and Zhu, Lixing},
doi = {10.1007/s12561-013-9105-x},
issn = {18671772},
journal = {Statistics in Biosciences},
keywords = {Hierarchical likelihood,Mixed effects models,Modified Cholesky decomposition,Penalized likelihood,Variable selection},
number = {1},
pages = {108--128},
title = {{Double Penalized H-Likelihood for Selection of Fixed and Random Effects in Mixed Effects Models}},
volume = {7},
year = {2015}
}

@article{Ghosh2018,
abstract = {Mixed-effect models are very popular for analyzing data with a hierarchical structure. In medical applications, typical examples include repeated observations within subjects in a longitudinal design, patients nested within centers in a multicenter design. However, recently, due to the medical advances, the number of fixed-effect covariates collected from each patient can be quite large, e.g., data on gene expressions of each patient, and all of these variables are not necessarily important for the outcome. So, it is very important to choose the relevant covariates correctly for obtaining the optimal inference for the overall study. On the other hand, the relevant random effects will often be low-dimensional and pre-specified. In this paper, we consider regularized selection of important fixed-effect variables in linear mixed-effect models along with maximum penalized likelihood estimation of both fixed and random-effect parameters based on general non-concave penalties. Asymptotic and variable selection consistency with oracle properties are proved for low-dimensional cases as well as for high dimensionality of non-polynomial order of sample size (number of parameters is much larger than sample size). We also provide a suitable computationally efficient algorithm for implementation. Additionally, all the theoretical results are proved for a general non-convex optimization problem that applies to several important situations well beyond the mixed model setup (like finite mixture of regressions) illustrating the huge range of applicability of our proposal.},
archivePrefix = {arXiv},
arxivId = {1607.02883},
author = {Ghosh, Abhik and Thoresen, Magne},
doi = {10.1007/s10182-017-0298-z},
eprint = {1607.02883},
issn = {18638171},
journal = {AStA Advances in Statistical Analysis},
mendeley-groups = {Feature/Effects Selection},
number = {2},
pages = {179--210},
title = {{Non-concave penalization in linear mixed-effect models and regularized selection of fixed effects}},
volume = {102},
year = {2018}
}

@book{Miller2002,
annote = {Great reference to subset selection (exhaustive search methods)},
author = {Miller, Alan},
doi = {10.1201/9781420035933},
isbn = {9780429119187},
mendeley-groups = {Feature/Effects Selection},
month = {apr},
publisher = {Chapman and Hall/CRC},
title = {{Subset Selection in Regression}},
url = {https://www.taylorfrancis.com/books/9781420035933},
year = {2002}
}

@article{Zou2006,
abstract = {The lasso is a popular technique for simultaneous estimation and variable selection. Lasso variable selection has been shown to be consistent under certain conditions. In this work we derive a necessary condition for the lasso variable selection to be consistent. Consequently, there exist certain scenarios where the lasso is inconsistent for variable selection. We then propose a new version of the lasso, called the adaptive lasso, where adaptive weights are used for penalising different coefficients in the ℓ1 penalty. We show that the adaptive lasso enjoys the oracle properties; namely, it performs as well us if the true underlying model were given in advance. Similar to the lasso, the adaptive lasso is shown to be near-minimax optimal. Furthermore, the adaptive lasso can be solved by the same efficient algorithm for solving the lasso. We also discuss the extension of the adaptive lasso in generalized linear models and show that the oracle properties still hold under mild regularity conditions. As a byproduct of our theory, the nonnegalive garotte is shown to be consistent for variable selection. {\textcopyright} 2006 American Statistical Association.},
author = {Zou, Hui},
doi = {10.1198/016214506000000735},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Asymptotic normality,Lasso,Minimax,Oracle inequality,Oracle procedure,Variable selection},
mendeley-groups = {Feature/Effects Selection},
number = {476},
pages = {1418--1429},
title = {{The adaptive lasso and its oracle properties}},
volume = {101},
year = {2006}
}

@article{Zou2005,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
annote = {Creators of Elastic Net. The goal is to combine interpretability (lasso) and similtaneous selection for highly correlated predictors.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Zou, Hui and Hastie, Trevor},
doi = {10.1111/j.1467-9868.2005.00503.x},
eprint = {arXiv:1011.1669v3},
isbn = {9788578110796},
issn = {1369-7412},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {icle},
mendeley-groups = {Feature/Effects Selection},
month = {apr},
number = {2},
pages = {301--320},
pmid = {25246403},
title = {{Regularization and variable selection via the elastic net}},
url = {http://doi.wiley.com/10.1111/j.1467-9868.2005.00503.x},
volume = {67},
year = {2005}
}


@article{Bradley1998,
abstract = {Computational comparison is made between two feature selection approaches for finding a separating plane that discriminates between two point sets in an n-dimensional feature space that utilizes as few of the n features (dimensions) as possible. In the concave minimization approach [19, 5] a separating plane is generated by minimizing a weighted sum of distances of misclassified points to two parallel planes that bound the sets and which determine the separating plane midway between them. Furthermore, the number of dimensions of the space used to determine the plane is minimized. In the support vector machine approach [27, 7, 1, 10, 24, 28], in addition to minimizing the weighted sum of distances of misclassified points to the bounding planes, we also maximize the distance between the two bounding planes that generate the separating plane. Computational results show that feature suppression is an indirect consequence of the support vector machine approach when an appropriate norm is us...},
annote = {Introduce L1 regularization to SVMs},
author = {Bradley, P and Mangasarian, O},
journal = {Proceedings of the International Conference on Machine Learning},
mendeley-groups = {Feature/Effects Selection},
number = {6},
pages = {82--90},
title = {{Feature Selection via Concave Minimization and Support Vector Machines}},
year = {1998}
}

@article{Lan2006,
annote = {Introduce shrinkage operator (lasso) for selecting FIXED effects in linear mixed models setting. This direction was later continued by Arun Krishna (2008)},
author = {Lan, Lan},
journal = {PhD thesis},
mendeley-groups = {Feature/Effects Selection},
title = {{Variable Selection in Linear Mixed Model for Longitudinal Data}},
year = {2006}
}


@article{Chen2003,
annote = {Introduced selection of random effects in mixed effect models using modified Cholesky decomposition of Gamma = DLL'D.},
author = {Chen, Zhen and Dunson, David B},
doi = {10.1111/j.0006-341X.2003.00089.x},
issn = {0006-341X},
journal = {Biometrics},
keywords = {aging,bayes factor,homogeneity test,latent variables,longitudinal data,mcmc,model aver-,variable selection,variance components},
mendeley-groups = {Feature/Effects Selection},
month = {dec},
number = {4},
pages = {762--769},
title = {{Random Effects Selection in Linear Mixed Models}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0006-341X.2003.00089.x},
volume = {59},
year = {2003}
}

@article{Xie2020,
abstract = {Reinforcement learning is one of the paradigms and methodologies of machine learning developed in the computational intelligence community. Reinforcement learning algorithms present a major challenge in complex dynamics recently. In the perspective of variable selection, we often come across situations where too many variables are included in the full model at the initial stage of modeling. Due to a high-dimensional and intractable integral of longitudinal data, likelihood inference is computationally challenging. It can be computationally difficult such as very slow convergence or even nonconvergence, for the computationally intensive methods. Recently, hierarchical likelihood (h-likelihood) plays an important role in inferences for models having unobservable or unobserved random variables. This paper focuses linear models with random effects in the mean structure and proposes a penalized h-likelihood algorithm which incorporates variable selection procedures in the setting of mean modeling via h-likelihood. The penalized h-likelihood method avoids the messy integration for the random effects and is computationally efficient. Furthermore, it demonstrates good performance in relevant-variable selection. Throughout theoretical analysis and simulations, it is confirmed that the penalized h-likelihood algorithm produces good fixed effect estimation results and can identify zero regression coefficients in modeling the mean structure.},
author = {Xie, Yanxi and Li, Yuewen and Xia, Zhijie and Yan, Ruixia and Luan, Dongqing},
doi = {10.1155/2020/8941652},
issn = {1076-2787},
journal = {Complexity},
mendeley-groups = {Feature/Effects Selection},
pages = {1--13},
title = {{A Penalized h-Likelihood Variable Selection Algorithm for Generalized Linear Regression Models with Random Effects}},
volume = {2020},
year = {2020}
}

@article{Lee1996,
abstract = {We propose a class of double hierarchical generalized linear models in which ran- dom effects can be specified for both the mean and dispersion. Heteroscedasticity between clusters can be modelled by introducing random effects in the dispersion model, as is hetero- geneity between clusters in the mean model.This class will, among other things, enable models with heavy-tailed distributions to be explored, providing robust estimation against outliers.The h-likelihood provides a unified framework for this new class of models and gives a single algorithm for fitting all members of the class. This algorithm does not require quadrature or prior probabilities.},
annote = {Proposed h-Likelihood for dealing with},
author = {Lee, Y. and Nelder, J. A.},
doi = {10.1111/j.2517-6161.1996.tb02105.x},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
keywords = {canonical link,dispersion components,generalized linear mixed model,h-likelihood,hierarchical likelihood,likelihood,marginal likelihood,profile,quasi-h-likelihood,random effect,restricted maximum},
mendeley-groups = {Fundamentals of Mixed Models},
number = {4},
pages = {619--656},
title = {{Hierarchical Generalized Linear Models}},
volume = {58},
year = {1996}
}

@article{Laird1982,
author = {Laird, Nan M and Ware, James H},
doi = {10.2307/2529876},
file = {:Users/aksh/Documents/Papers/2007/Laird, Ware/Laird-Ware-Biometrics-1982.Pdf/Laird, Ware - 2007 - Laird-Ware-Biometrics-1982.Pdf.pdf:pdf},
issn = {0006341X},
journal = {Biometrics},
mendeley-groups = {Fundamentals of Mixed Models},
month = {dec},
number = {4},
pages = {963},
title = {{Random-Effects Models for Longitudinal Data}},
url = {http://www.stat.cmu.edu/{~}brian/720/week07/laird-ware-biometrics-1982.pdf https://www.jstor.org/stable/2529876?origin=crossref},
volume = {38},
year = {1982}
}

@article{Laird1987,
author = {Laird, Nan and Lange, Nicholas and Stram, Daniel},
doi = {10.1080/01621459.1987.10478395},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Aitken acceleration,Growth curves with random parameters,Linear patterned covariance matrices,Mixed models,Restricted maximum likelihood},
mendeley-groups = {EM-algorithm,Fundamentals of Mixed Models},
number = {397},
pages = {97--105},
title = {{Maximum likelihood computations with repeated measures: Application of the EM algorithm}},
volume = {82},
year = {1987}
}

@article{Wu1983,
abstract = {The Cox regression model for censored survival data specifies that covariates have a proportional effect on the hazard function of the life-time distribution of an individual. In this paper we discuss how this model can be extended to a model where covariate processes have a proportional effect on the intensity process of a multivariate counting process. This permits a statistical regression analysis of the intensity of a recurrent event allowing for complicated censoring patterns and time dependent covariates. Furthermore, this formulation gives rise to proofs with very simple structure using martingale techniques for the asymptotic properties of the estimators from such a model. Finally an example of a statistical analysis is included.},
author = {Wu, C. F. Jeff},
doi = {10.1214/aos/1176346060},
issn = {0090-5364},
journal = {The Annals of Statistics},
mendeley-groups = {EM-algorithm},
month = {mar},
number = {1},
pages = {95--103},
title = {{On the Convergence Properties of the EM Algorithm}},
url = {http://projecteuclid.org/euclid.aos/1176345976 http://projecteuclid.org/euclid.aos/1176346060},
volume = {11},
year = {1983}
}

@article{Balakrishnan2017,
abstract = {The EM algorithm is a widely used tool in maximum-likelihood estimation in incomplete data problems. Existing theoretical work has focused on conditions under which the iterates or likelihood values converge, and the associated rates of convergence. Such guarantees do not distinguish whether the ultimate fixed point is a near global optimum or a bad local optimum of the sample likelihood, nor do they relate the obtained fixed point to the global optima of the idealized population likelihood (obtained in the limit of infinite data). This paper develops a theoretical framework for quantifying when and how quickly EM-type iterates converge to a small neighborhood of a given global optimum of the population likelihood. For correctly specified models, such a characterization yields rigorous guarantees on the performance of certain two-stage estimators in which a suitable initial pilot estimator is refined with iterations of the EM algorithm. Our analysis is divided into two parts: a treatment of the EM and first-order EM algorithms at the population level, followed by results that apply to these algorithms on a finite set of samples. Our conditions allow for a characterization of the region of convergence of EM-type iterates to a given population fixed point, that is, the region of the parameter space over which convergence is guaranteed to a point within a small neighborhood of the specified population fixed point. We verify our conditions and give tight characterizations of the region of convergence for three canonical problems of interest: symmetric mixture of two Gaussians, symmetric mixture of two regressions and linear regression with covariates missing completely at random.},
annote = {Latest, to date, statistical guarantees for EM algorithm},
archivePrefix = {arXiv},
arxivId = {1408.2156},
author = {Balakrishnan, Sivaraman and Wainwright, Martin J. and Yu, Bin},
doi = {10.1214/16-AOS1435},
eprint = {1408.2156},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {EM algorithm,First-order EM algorithm,Maximum likelihood estimation,Nonconvex optimization},
mendeley-groups = {EM-algorithm},
month = {feb},
number = {1},
pages = {77--120},
title = {{Statistical guarantees for the EM algorithm: From population to sample-based analysis}},
url = {http://projecteuclid.org/euclid.aos/1487667618},
volume = {45},
year = {2017}
}

@article{Liu1994,
author = {Liu, Chuanhai and Rubin, Donald B.},
doi = {10.2307/2337067},
issn = {00063444},
journal = {Biometrika},
mendeley-groups = {EM-algorithm},
month = {dec},
number = {4},
pages = {633},
title = {{The ECME Algorithm: A Simple Extension of EM and ECM with Faster Monotone Convergence}},
url = {https://www.jstor.org/stable/2337067?origin=crossref},
volume = {81},
year = {1994}
}

@article{Liu1998,
author = {Liu, C},
doi = {10.1093/biomet/85.4.755},
issn = {0006-3444},
journal = {Biometrika},
mendeley-groups = {EM-algorithm},
month = {dec},
number = {4},
pages = {755--770},
title = {{Parameter expansion to accelerate EM: the PX-EM algorithm}},
url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/85.4.755},
volume = {85},
year = {1998}
}

@article{Jennrich1986,
author = {Jennrich, Robert I. and Schluchter, Mark D.},
doi = {10.2307/2530695},
issn = {0006341X},
journal = {Biometrics},
mendeley-groups = {Fundamentals of Mixed Models},
month = {dec},
number = {4},
pages = {805},
title = {{Unbalanced Repeated-Measures Models with Structured Covariance Matrices}},
url = {https://www.jstor.org/stable/2530695?origin=crossref},
volume = {42},
year = {1986}
}

@inbook{TrustRegionBook,

title = {Part III Trust-Region Methods for Constrained Optimization with Convex Constraints},
booktitle = {Trust Region Methods},
chapter = {},
pages = {439-439},
doi = {10.1137/1.9780898719857.pt3},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9780898719857.pt3},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9780898719857.pt3}
}

@article{Nash2000,
abstract = {Truncated-Newton methods are a family of methods for solving large optimization problems. Over the past two decades, a solid convergence theory has been derived for the methods. In addition, many algorithmic enhancements have been developed and studied, resulting in a number of publicly available software packages. The result has been a collection of powerful, flexible, and adaptable tools for large-scale nonlinear optimization. (C) 2000 Elsevier Science B.V. All rights reserved.},
author = {Nash, Stephen G.},
doi = {10.1016/S0377-0427(00)00426-X},
file = {:Users/aksh/Documents/Papers/2000/Nash/A survey of truncated-Newton methods/Nash - 2000 - A survey of truncated-Newton methods.pdf:pdf},
issn = {03770427},
journal = {Journal of Computational and Applied Mathematics},
mendeley-groups = {Optimization in MMs},
number = {1-2},
pages = {45--59},
title = {{A survey of truncated-Newton methods}},
volume = {124},
year = {2000}
}

@article{Bertsekas1982,
author = {Bertsekas, Dimitri P.},
doi = {10.1137/0320018},
file = {:Users/aksh/Documents/Papers/1982/Optimization/Problems With Simple Constraints/Optimization - 1982 - Problems With Simple Constraints.pdf:pdf},
issn = {0363-0129},
journal = {SIAM Journal on Control and Optimization},
mendeley-groups = {Optimization in MMs},
month = {mar},
number = {2},
pages = {221--246},
title = {{Projected Newton Methods for Optimization Problems with Simple Constraints}},
url = {http://epubs.siam.org/doi/10.1137/0320018},
volume = {20},
year = {1982}
}

@article{Potra2000,
author = {Potra, Florian A. and Wright, Stephen J.},
doi = {10.1016/S0377-0427(00)00433-7},
issn = {03770427},
journal = {Journal of Computational and Applied Mathematics},
mendeley-groups = {Optimization in MMs},
month = {dec},
number = {1-2},
pages = {281--302},
title = {{Interior-point methods}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0377042700004337},
volume = {124},
year = {2000}
}

@article{Baraldi2019,
author = {Baraldi, Robert and Kumar, Rajiv and Aravkin, Aleksandr},
doi = {10.1109/TSP.2019.2946029},
issn = {1053-587X},
journal = {IEEE Transactions on Signal Processing},
mendeley-groups = {Relax-and-Split examples},
month = {nov},
number = {22},
pages = {5811--5823},
title = {{Basis Pursuit Denoise With Nonsmooth Constraints}},
url = {https://ieeexplore.ieee.org/document/8861392/},
volume = {67},
year = {2019}
}

@article{Zheng2019SR3,
author = {Zheng, Peng and Askham, Travis and Brunton, Steven L. and Kutz, J. Nathan and Aravkin, Aleksandr Y.},
doi = {10.1109/ACCESS.2018.2886528},
issn = {2169-3536},
journal = {IEEE Access},
mendeley-groups = {Relax-and-Split examples},
pages = {1404--1423},
title = {{A Unified Framework for Sparse Relaxed Regularized Regression: SR3}},
url = {https://ieeexplore.ieee.org/document/8573778/},
volume = {7},
year = {2019}
}

@article{Champion2020,
author = {Champion, Kathleen and Zheng, Peng and Aravkin, Aleksandr Y. and Brunton, Steven L. and Kutz, J. Nathan},
doi = {10.1109/ACCESS.2020.3023625},
issn = {2169-3536},
journal = {IEEE Access},
mendeley-groups = {Relax-and-Split examples},
pages = {169259--169271},
title = {{A Unified Sparse Optimization Framework to Learn Parsimonious Physics-Informed Models From Data}},
url = {https://ieeexplore.ieee.org/document/9194760/},
volume = {8},
year = {2020}
}

@unpublished{Belyy2018,
abstract = {Multi-class classification with a very large number of classes, or extreme classification, is a challenging problem from both statistical and computational perspectives. Most of the classical approaches to multi-class classification, including one-vs-rest or multi-class support vector machines, require the exact estimation of the classifier's margin, at both the training and the prediction steps making them intractable in extreme classification scenarios. In this paper, we study the impact of computing an approximate margin using nearest neighbor (ANN) search structures combined with locality-sensitive hashing (LSH). This approximation allows to dramatically reduce both the training and the prediction time without a significant loss in performance. We theoretically prove that this approximation does not lead to a significant loss of the risk of the model and provide empirical evidence over five publicly available large scale datasets, showing that the proposed approach is highly competitive with respect to state-of-the-art approaches on time, memory and performance measures.},
archivePrefix = {arXiv},
arxivId = {1811.09863},
author = {Belyy, Anton and Sholokhov, Aleksei},
eprint = {1811.09863},
mendeley-groups = {Other},
title = {{MEMOIR: Multi-class Extreme Classification with Inexact Margin}},
url = {http://arxiv.org/abs/1811.09863},
year = {2018}
}

@article{Jajuga1991,
author = {Jajuga, Krzysztof},
doi = {10.1016/0165-0114(91)90064-W},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
mendeley-groups = {Other},
month = {jan},
number = {1},
pages = {43--50},
title = {{L1-norm based fuzzy clustering}},
url = {https://linkinghub.elsevier.com/retrieve/pii/016501149190064W},
volume = {39},
year = {1991}
}

@article{Shalev-Shwartz2011,
doi = {10.1007/s10107-010-0420-4},
file = {::},
isbn = {9781595937933},
issn = {00255610},
journal = {Mathematical Programming},
keywords = {SVM,Stochastic gradient descent},
mendeley-groups = {Pegasos},
number = {1},
pages = {3--30},
title = {{Pegasos: Primal estimated sub-gradient solver for SVM}},
volume = {127},
year = {2011}
}

@article{Kim2019,
abstract = {Contextual multi-armed bandit algorithms are widely used in sequential decision tasks such as news article recommendation systems, web page ad placement algorithms, and mobile health. Most of the existing algorithms have regret proportional to a polynomial function of the context dimension, d. In many applications however, it is often the case that contexts are high-dimensional with only a sparse subset of size s0(« d) being correlated with the reward. We consider the stochastic linear contextual bandit problem and propose a novel algorithm, namely the Doubly-Robust Lasso Bandit algorithm, which exploits the sparse structure of the regression parameter as in Lasso, while blending the doubly-robust technique used in missing data literature. The high-probability upper bound of the regret incurred by the proposed algorithm does not depend on the number of arms and scales with log(d) instead of a polynomial function of d. The proposed algorithm shows good performance when contexts of different arms are correlated and requires less tuning parameters than existing methods.},
author = {Kim, Gi Soo and Paik, Myunghee Cho},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
mendeley-groups = {Other},
number = {NeurIPS},
title = {{Doubly-robust lasso bandit}},
volume = {32},
year = {2019}
}

@article{Vaida2005,
author = {Vaida, Florin and Blanchard, Suzette},
doi = {10.1093/biomet/92.2.351},
issn = {1464-3510},
journal = {Biometrika},
mendeley-groups = {AIC/BIC},
month = {jun},
number = {2},
pages = {351--370},
title = {{Conditional Akaike information for mixed-effects models}},
url = {http://academic.oup.com/biomet/article/92/2/351/233128/Conditional-Akaike-information-for-mixedeffects},
volume = {92},
year = {2005}
}

@article{Jones2011,
author = {Jones, Richard H.},
doi = {10.1002/sim.4323},
issn = {02776715},
journal = {Statistics in Medicine},
mendeley-groups = {AIC/BIC},
month = {nov},
number = {25},
pages = {3050--3056},
title = {{Bayesian information criterion for longitudinal and clustered data}},
url = {http://doi.wiley.com/10.1002/sim.4323},
volume = {30},
year = {2011}
}

@article{Pinheiro2000,
address = {New York, NY},
author = {Pinheiro, Jos{\'{e}} C. and Bates, Douglas M.},
journal = {Journal of the American Statistical Association},
doi = {10.1007/978-1-4419-0318-1},
isbn = {978-1-4419-0317-4},
issn = {0162-1459},
mendeley-groups = {Essential Books},
month = {sep},
number = {455},
pages = {1135--1136},
publisher = {Springer New York},
series = {Statistics and Computing},
title = {{Mixed-Effects Models in Sand S-PLUS}},
url = {http://www.tandfonline.com/doi/abs/10.1198/jasa.2001.s411 http://link.springer.com/10.1007/978-1-4419-0318-1},
volume = {96},
year = {2000}
}

@article{Krishna2008,
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Bondell, Howard D. and Krishna, Arun and Ghosh, Sujit K.},
doi = {10.1111/j.1541-0420.2010.01391.x},
eprint = {NIHMS150003},
isbn = {6176321972},
issn = {0006341X},
journal = {Biometrics},
keywords = {epiblast,gfp fusion,histone h2b-,icm,lineage specification,live imaging,mouse blastocyst,pdgfr $\alpha$,primitive endoderm},
mendeley-groups = {Feature/Effects Selection},
month = {dec},
number = {4},
pages = {1069--1077},
pmid = {1000000221},
title = {{Joint Variable Selection for Fixed and Random Effects in Linear Mixed-Effects Models}},
url = {http://doi.wiley.com/10.1111/j.1541-0420.2010.01391.x},
volume = {66},
year = {2010}
}

@article{Fan2012,
abstract = {This paper is concerned with the selection and estimation of fixed and random effects in linear mixed effects models.We propose a class of nonconcave penalized profile likelihood methods for selecting and estimating important fixed effects. To overcome the difficulty of unknown covariance matrix of random effects, we propose to use a proxy matrix in the penalized profile likelihood. We establish conditions on the choice of the proxy matrix and show that the proposed procedure enjoys the model selection consistency where the number of fixed effects is allowed to grow exponentially with the sample size.We further propose a group variable selection strategy to simultaneously select and estimate important random effects, where the unknown covariance matrix of random effects is replaced with a proxy matrix.We prove that, with the proxy matrix appropriately chosen, the proposed procedure can identify all true random effects with asymptotic probability one, where the dimension of random effects vector is allowed to increase exponentially with the sample size. Monte Carlo simulation studies are conducted to examine the finite-sample performance of the proposed procedures. We further illustrate the proposed procedures via a real data example. {\textcopyright} 2012 Institute of Mathematical Statistics.},
author = {Fan, Yingying and Li, Runze},
doi = {10.1214/12-AOS1028},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {Adaptive Lasso,Group variable selection,Linear mixed effects models,Oracle property,SCAD},
mendeley-groups = {Feature/Effects Selection},
month = {aug},
number = {4},
pages = {2043--2068},
title = {{Variable selection in linear mixed effects models}},
url = {http://projecteuclid.org/euclid.aos/1351602536},
volume = {40},
year = {2012}
}

@article{Lin2013,
author = {Lin, Bingqing and Pang, Zhen and Jiang, Jiming},
doi = {10.1080/10618600.2012.681219},
issn = {10618600},
journal = {Journal of Computational and Graphical Statistics},
keywords = {BIC,LASSO,Mixed-effects models},
mendeley-groups = {Feature/Effects Selection},
number = {2},
pages = {341--355},
title = {{Fixed and random effects selection by REML and pathwise coordinate optimization}},
volume = {22},
year = {2013}
}

@article{Hui2017,
author = {Hui, Francis K.C. and M{\"{u}}ller, Samuel and Welsh, A. H.},
doi = {10.1080/01621459.2016.1215989},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Fixed effects,Generalized linear mixed models,Lasso,Penalized likelihood,Quasi-likelihood,Variable selection},
mendeley-groups = {Feature/Effects Selection},
number = {519},
pages = {1323--1333},
title = {{Joint Selection in Mixed Models using Regularized PQL}},
volume = {112},
year = {2017}
}

@article{Fan2001,
author = {Fan, Jianqing and Li, Runze},
doi = {10.1198/016214501753382273},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {hard thresholding,lasso,nonnegative garrote,oracle estimator,penalized likelihood,scad,soft thresholding},
mendeley-groups = {Feature/Effects Selection},
month = {dec},
number = {456},
pages = {1348--1360},
title = {{Variable Selection via Nonconcave Penalized Likelihood and its Oracle Properties}},
url = {http://www.tandfonline.com/doi/abs/10.1198/016214501753382273},
volume = {96},
year = {2001}
}

@article{Lange1989,
author = {Lange, Nicholas and Laird, Nan M.},
doi = {10.1080/01621459.1989.10478761},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Covariance components,Design of experiments,Longitudinal data analysis,Random-effects models,Repeated measures,Restricted maximum likelihood estimation,Variance components},
mendeley-groups = {Fundamentals of Mixed Models},
month = {mar},
number = {405},
pages = {241--247},
title = {{The Effect of Covariance Structure on Variance Estimation in Balanced Growth-Curve Models with Random Parameters}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1989.10478761},
volume = {84},
year = {1989}
}

@article{Kojima1991,
author = {Kojima, Masakazu and Megiddo, Nimrod and Noma, Toshihito and Yoshise, Akiko},
doi = {10.1016/0167-6377(91)90010-M},
issn = {01676377},
journal = {Operations Research Letters},
mendeley-groups = {Interior Point Methods},
month = {jul},
number = {5},
pages = {247--254},
title = {{A unified approach to interior point algorithms for linear complementarity problems: A summary}},
url = {https://linkinghub.elsevier.com/retrieve/pii/016763779190010M},
volume = {10},
year = {1991}
}

@book{Nesterov1994,
author = {Nesterov, Yurii and Nemirovskii, Arkadii},
doi = {10.1137/1.9781611970791},
isbn = {978-0-89871-319-0},
mendeley-groups = {Interior Point Methods},
month = {jan},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Interior-Point Polynomial Algorithms in Convex Programming}},
url = {http://epubs.siam.org/doi/book/10.1137/1.9781611970791},
year = {1994}
}

@book{Wright1997,
author = {Wright, Stephen J.},
doi = {10.1137/1.9781611971453},
isbn = {978-0-89871-382-4},
mendeley-groups = {Interior Point Methods},
month = {jan},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Primal-Dual Interior-Point Methods}},
url = {http://epubs.siam.org/doi/book/10.1137/1.9781611971453},
year = {1997}
}

@article{aravkin2013sparse,
  title={Sparse/Robust Estimation and Kalman Smoothing with Nonsmooth Log-Concave Densities: Modeling, Computation, and Theory.},
  author={Aravkin, Aleksandr Y and Burke, James V and Pillonetto, Gianluigi},
  journal={Journal of Machine Learning Research},
  volume={14},
  year={2013}
}
@article{aravkin2017generalized,
  title={Generalized Kalman smoothing: Modeling and algorithms},
  author={Aravkin, Aleksandr and Burke, James V and Ljung, Lennart and Lozano, Aurelie and Pillonetto, Gianluigi},
  journal={Automatica},
  volume={86},
  pages={63--86},
  year={2017},
  publisher={Elsevier}
}

@article{rockafellar1993lagrange,
  title={Lagrange multipliers and optimality},
  author={Rockafellar, R Tyrrell},
  journal={SIAM review},
  volume={35},
  number={2},
  pages={183--238},
  year={1993},
  publisher={SIAM}
}

@misc{IHME2020Projections,
author = {IHME},
booktitle = {IHME COVID-19 Projections},
mendeley-groups = {Other},
title = {{IHME COVID-19 Projections}},
url = {https://covid19.healthdata.org/global},
year = {2020}
}

@article{Sugiura1978,
author = {Sugiura, Nariaki},
doi = {10.1080/03610927808827599},
issn = {0361-0926},
journal = {Communications in Statistics - Theory and Methods},
mendeley-groups = {AIC/BIC},
month = {jan},
number = {1},
pages = {13--26},
title = {{Further analysts of the data by akaike' s information criterion and the finite corrections}},
url = {http://www.tandfonline.com/doi/abs/10.1080/03610927808827599},
volume = {7},
year = {1978}
}

@article{Fang2011,
abstract = {For model selection in mixed effects models, Vaida and Blan-chard (2005) demonstrated that the marginal Akaike information criterion is appropriate as to the questions regarding the population and the con-ditional Akaike information criterion is appropriate as to the questions re-garding the particular clusters in the data. This article shows that the marginal Akaike information criterion is asymptotically equivalent to the leave-one-cluster-out cross-validation and the conditional Akaike informa-tion criterion is asymptotically equivalent to the leave-one-observation-out cross-validation.},
author = {Fang, Yixin},
file = {:Users/aksh/Documents/Papers/2011/Fang/Asymptotic Equivalence between Cross-Validations and Akaike Information Criteria in Mixed-Effects Models/Fang - 2011 - Asymptotic Equivalence between Cross-Validations and Akaike Information Criteria in Mixed-Effects Models.pdf:pdf},
journal = {Journal of Data Science},
keywords = {AIC,degrees of freedom,functional data,model selection},
mendeley-groups = {AIC/BIC},
pages = {15--21},
title = {{Asymptotic Equivalence between Cross-Validations and Akaike Information Criteria in Mixed-Effects Models}},
volume = {9},
year = {2011}
}

@article{Polyak1964,
author = {Polyak, B.T.},
doi = {10.1016/0041-5553(64)90137-5},
issn = {00415553},
journal = {USSR Computational Mathematics and Mathematical Physics},
mendeley-groups = {Other},
month = {jan},
number = {5},
pages = {1--17},
title = {{Some methods of speeding up the convergence of iteration methods}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0041555364901375},
volume = {4},
year = {1964}
}

@book{Nesterov2004,
address = {Boston, MA},
author = {Nesterov, Yurii},
doi = {10.1007/978-1-4419-8853-9},
isbn = {978-1-4613-4691-3},
mendeley-groups = {Other},
publisher = {Springer US},
series = {Applied Optimization},
title = {{Introductory Lectures on Convex Optimization}},
url = {http://link.springer.com/10.1007/978-1-4419-8853-9},
volume = {87},
year = {2004}
}

@book{nocedal2006numerical,
  title={Numerical optimization},
  author={Nocedal, Jorge and Wright, Stephen},
  year={2006},
  publisher={Springer Science \& Business Media}
}

@book{Still2018,
author = {Still, Georg},
mendeley-groups = {Other},
publisher = {Optimization Online},
title = {{Lectures on Parametric Optimization: An Introduction}},
year = {2018}
}

@article{Craven1984,
author = {Craven, B. D.},
doi = {10.1137/1026121},
issn = {0036-1445},
journal = {SIAM Review},
mendeley-groups = {Essential Books},
month = {oct},
number = {4},
pages = {594--595},
title = {{Non-Linear Parametric Optimization (B. Bank, J. Guddat, D. Klatte, B. Kummer and K. Tammer)}},
url = {http://epubs.siam.org/doi/10.1137/1026121},
volume = {26},
year = {1984}
}

@book{Bonnans2000,
address = {New York, NY},
author = {Bonnans, J. Fr{\'{e}}d{\'{e}}ric and Shapiro, Alexander},
doi = {10.1007/978-1-4612-1394-9},
isbn = {978-1-4612-7129-1},
mendeley-groups = {Essential Books},
publisher = {Springer New York},
title = {{Perturbation Analysis of Optimization Problems}},
url = {http://link.springer.com/10.1007/978-1-4612-1394-9},
year = {2000}
}



@article{Golub1973,
author = {Golub, G. H. and Pereyra, V.},
doi = {10.1137/0710036},
issn = {0036-1429},
journal = {SIAM Journal on Numerical Analysis},
mendeley-groups = {Other},
month = {apr},
number = {2},
pages = {413--432},
title = {{The Differentiation of Pseudo-Inverses and Nonlinear Least Squares Problems Whose Variables Separate}},
url = {http://epubs.siam.org/doi/10.1137/0710036},
volume = {10},
year = {1973}
}

@article{Aravkin2012,
author = {Aravkin, Aleksandr Y and van Leeuwen, Tristan},
doi = {10.1088/0266-5611/28/11/115016},
issn = {0266-5611},
journal = {Inverse Problems},
mendeley-groups = {Other},
month = {nov},
number = {11},
pages = {115016},
title = {{Estimating nuisance parameters in inverse problems}},
url = {https://iopscience.iop.org/article/10.1088/0266-5611/28/11/115016},
volume = {28},
year = {2012}
}

@article{Aravkin2018,
author = {Aravkin, Aleksandr Y. and Drusvyatskiy, Dmitriy and van Leeuwen, Tristan},
doi = {10.1109/TAC.2017.2754474},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
mendeley-groups = {Other},
month = {jul},
number = {7},
pages = {2131--2138},
title = {{Efficient Quadratic Penalization Through the Partial Minimization Technique}},
url = {https://ieeexplore.ieee.org/document/8046106/},
volume = {63},
year = {2018}
}

@article{Yu2015,
abstract = {This study investigates an ill-posed problem (multicollinearity) in Hierarchical Linear Models from both the data and the model perspectives. We propose an intuitive, effective approach to diagnosing the presence of multicollinearity and its remedies in this class of models. A simulation study demonstrates the impacts of multicollinearity on coefficient estimates, associated standard errors, and variance components at various levels of multicollinearity for finite sample sizes typical in social science studies. We further investigate the role multicollinearity plays at each level for estimation of coefficient parameters in terms of shrinkage. Based on these analyses, we recommend a top-down method for assessing multicollinearity in HLMs that first examines the contextual predictors (Level-2 in a two-level model) and then the individual predictors (Level-1) and uses the results for data collection, research problem redefinition, model re-specification, variable selection and estimation of a final model.},
author = {Yu, Han and Jiang, Shanhe and Land, Kenneth C.},
doi = {10.1016/j.ssresearch.2015.04.008},
issn = {0049089X},
journal = {Social Science Research},
keywords = {Covariate pool,Hierarchical linear models,Multicollinearity,Singular value decomposition,Top-down diagnosis},
mendeley-groups = {Multicollinearity},
month = {sep},
pages = {118--136},
pmid = {26188442},
publisher = {Elsevier Inc.},
title = {{Multicollinearity in hierarchical linear models}},
url = {http://dx.doi.org/10.1016/j.ssresearch.2015.04.008 https://linkinghub.elsevier.com/retrieve/pii/S0049089X15000885},
volume = {53},
year = {2015}
}

@article{Buscemi2019Survey,
abstract = {Linear mixed-effects models are a class of models widely used for analyzing different types of data: longitudinal, clustered and panel data. Many fields, in which a statistical methodology is required, involve the employment of linear mixed models, such as biology, chemistry, medicine, finance and so forth. One of the most important processes, in a statistical analysis, is given by model selection. Hence, since there are a large number of linear mixed model selection procedures available in the literature, a pressing issue is how to identify the best approach to adopt in a specific case. We outline mainly all approaches focusing on the part of the model subject to selection (fixed and/or random), the dimensionality of models and the structure of variance and covariance matrices, and also, wherever possible, the existence of an implemented application of the methodologies set out.},
annote = {The most up-to-date literature review found on this issue.},
author = {Buscemi, Simona and Plaia, Antonella},
doi = {10.1007/s10182-019-00359-z},
issn = {1863818X},
journal = {AStA Advances in Statistical Analysis},
keywords = {AIC,BIC,LASSO,Linear mixed model,MCP,MDL,Mixed model selection,Shrinkage methods},
mendeley-groups = {Feature/Effects Selection,Surveys Summaries Overviews},
publisher = {Springer Berlin Heidelberg},
title = {{Model selection in linear mixed-effect models}},
url = {https://doi.org/10.1007/s10182-019-00359-z},
year = {2019}
}

@article{Marino2017multiinput,
abstract = {Missing covariate data hamper variable selection in multilevel regression settings. Current variable selection techniques for multiply-imputed data commonly address missingness in the predictors through list-wise deletion and stepwise-selection methods that are problematic. Moreover, most variable selection methods are developed for independent linear regression models and do not accommodate multilevel mixed effects regression models with incomplete covariate data. We develop a novel methodology that is able to perform covariate selection across multiply-imputed data for multilevel random effects models when missing data are present. Specifically, we propose to stack the multiply-imputed data sets from a multiple imputation procedure and to apply a group variable selection procedure through group lasso regularization to assess the overall impact of each predictor on the outcome across the imputed data sets. Simulations confirm the advantageous performance of the proposed method compared with the competing methods. We applied the method to reanalyse the Healthy Directions–Small Business cancer prevention study, which evaluated a behavioural intervention programme targeting multiple risk-related behaviours in a working-class, multi-ethnic population. Copyright {\textcopyright} 2017 John Wiley & Sons, Ltd.},
annote = {They work in the setting where missing covariates are filled with multiple imputation technique. Multiple imputation samples missing values P times from posterior distribution given existing values iteratively (Gibbs sampler). When we fill covariate this way, we obtain P replications of the dataset. (Y, X1, X2..., XP). The authors propose to stach those horizontally and then penalize likelihood with \lam*\sum ||b_j||, where the norm is the second one (without square). Sufficiently large lambda can drive the whole blocks b_j for the replication (Y, Xj) to zero, and we end up kicking out some variables because they don't enter any blocks. To combine coefficients to the final estimate they use Rubin-1987 approach. Intrestingly, this approach also allow to estimate the uncertainty around betas. They use BIC to tune Lambda. They do simulation study and find that their method does not perform well on one imputation but performs well on multiple ones. They compare it with lasso on complete data (drop coefs with p-value <0.05). For real data, they use HD-SB study (Sorensen 2005) (diet + inactivity vs cancer) (Cool, should consider).},
author = {Marino, Miguel and Buxton, Orfeu M. and Li, Yi},
doi = {10.1002/sta4.133},
issn = {20491573},
journal = {Stat},
keywords = {BIC,Rubin's rules,cancer prevention,group lasso,intervention studies,multilevel,multiple imputation,regularization},
mendeley-groups = {Feature/Effects Selection},
number = {1},
pages = {31--46},
title = {{Covariate selection for multilevel models with missing data}},
volume = {6},
year = {2017}
}

@article{Yu2020TimeVaryingBeta,
abstract = {The associations between covariates and the outcomes often vary over time, regardless of whether the covariate is time-varying or time-invariant. For example, we hypothesize that the impact of chronic diseases, such as diabetes and heart disease, on people's physical functions differ with aging. However, the age-varying effect would be missed if one models the covariate simply as a time-invariant covariate (yes/no) with a time-constant coefficient. We propose a fused lasso-based time-varying linear mixed effect (FTLME) model and an efficient two-stage parameter estimation algorithm to estimate the longitudinal trajectories of fixed-effect coefficients. Simulation studies are presented to demonstrate the efficacy of the method and its computational efficiency in estimating smooth time-varying effects in high dimensional settings. A real data example on the Health and Retirement Study (HRS) analysis is used to demonstrate the practical usage of our method to infer age-varying impact of chronic disease on older people's physical functions.},
annote = {They proposed a mixed model with fixed effects that vary over time. To achieve this they expand matrix X so that for each time point i and covariate j they have \beta_ij. They add two regularizers: first norm of beta and first norm of variations of adjacent coefficients. Two hyperparameters are chosen with BIC. The estimation procedure relies on path algorithm (Lasso solver?). To use it, they get V = ZGZ+L, decompose it with cholesky and transform the quadratic as (yR - XR*beta)*(yR-XR*beta) which seems to be a good idea since we don't fit gamma and beta simultaneously. After beta is found with path, they take "empirical" estimations for noise, covariance matrix, and V, and repeat all again. On synthetic trial, they compare it only with lin regression: LR+lasso and LR+lasso+variations. For real data study, they use Health and Retirement Survey (HRS) to estimate how chances of getting certain chronic diseases depend on age over time. They estimate uncertainty with bootstrap.},
author = {Yu, Jaehong and Zhong, Hua},
doi = {10.1080/02664763.2020.1791805},
file = {:Users/aksh/Documents/Papers/2020/Yu, Zhong/Time varying mixed effects model with fused lasso regularization/Yu, Zhong - 2020 - Time varying mixed effects model with fused lasso regularization.pdf:pdf},
issn = {0266-4763},
journal = {Journal of Applied Statistics},
keywords = {Fused lasso,linear mixed effect model,longitudinal analysis,regularization,time-varying fixed effect},
mendeley-groups = {Feature/Effects Selection},
month = {jul},
number = {0},
pages = {1--14},
publisher = {Taylor & Francis},
title = {{Time varying mixed effects model with fused lasso regularization}},
url = {https://doi.org/02664763.2020.1791805 https://www.tandfonline.com/doi/full/10.1080/02664763.2020.1791805},
volume = {0},
year = {2020}
}

@article{Fan2001NonconcaveRegularizers,
abstract = {Variable selection is fundamental to high-dimensional statistical modeling, including nonparametric regression. Many approaches in use are stepwise selection procedures, which can be computationally expensive and ignore stochastic errors in the variable selection process. In this article, penalized likelihood approaches are proposed to handle these kinds of problems. The proposed methods select variables and estimate coef? cients simultaneously. Hence they enable us to construct con? dence intervals for estimated parameters. The proposed approaches are distinguished from others in that the penalty functions are symmetric, nonconcave on 401ˆ5, and have singularities at the origin to produce sparse solutions. Furthermore, the penalty functions should be bounded by a constant to reduce bias and satisfy certain conditions to yield continuous solutions. A new algorithm is proposed for optimizing penalized likelihood functions. The proposed ideas are widely applicable. They are readily applied to a variety of parametric models such as generalized linear models and robust regression models. They can also be applied easily to nonparametric modeling by using wavelets and splines. Rates of convergence of the proposed penalized likelihood estimators are established. Furthermore, with proper choice of regularization parameters, we show that the proposed estimators perform as well as the oracle procedure in variable selection; namely, they work as well as if the correct submodel were known. Our simulation shows that the newly proposed methods compare favorably with other variable selection techniques. Furthermore, the standard error formulas are tested to be accurate enough for practical applications.},
author = {Fan, Jianqing and Li, Runze},
doi = {10.1198/016214501753382273},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {hard thresholding,lasso,nonnegative garrote,oracle estimator,penalized likelihood,scad,soft thresholding},
mendeley-groups = {Feature/Effects Selection},
month = {dec},
number = {456},
pages = {1348--1360},
title = {{Variable Selection via Nonconcave Penalized Likelihood and its Oracle Properties}},
url = {http://www.tandfonline.com/doi/abs/10.1198/016214501753382273},
volume = {96},
year = {2001}
}

@book{belsley2005regression,
  title={Regression diagnostics: Identifying influential data and sources of collinearity},
  author={Belsley, David A and Kuh, Edwin and Welsch, Roy E},
  volume={571},
  year={2005},
  publisher={John Wiley \& Sons}
}

@article{Lesaffre1993,
author = {Lesaffre, Emmanuel and Marx, Brian D.},
doi = {10.1080/03610929308831126},
issn = {0361-0926},
journal = {Communications in Statistics - Theory and Methods},
mendeley-groups = {Multicollinearity},
month = {jan},
number = {7},
pages = {1933--1952},
title = {{Collinearity in generalized linear regression}},
url = {http://www.tandfonline.com/doi/abs/10.1080/03610929308831126},
volume = {22},
year = {1993}
}

@article{Bonate1999,
abstract = {PURPOSE To demonstrate how correlations among predictor variables in a population pharmacokinetic model affect the ability to discern which covariates should enter into the structural pharmacokinetic model. METHODS Monte Carlo simulation was used to generate multiple-dose concentration-time data similar to that seen in a Phase III clinical trial. The drugs' pharmacokinetics were dependent on two covariates. Five data sets were simulated with increasing correlation between the two covariates. All data sets were analyzed using NONMEM both with and without inclusion of the covariates in the structural pharmacokinetic model. Summary measures for ill-conditioning and sensitivity analysis were used to examine how increasing correlation among covariates affects the accuracy and precision of the parameter estimates. RESULTS When covariates were included in the structural pharmacokinetic model and the correlation between covariates increased, the standard error of the parameter estimates increased and the value of parameter estimates themselves became increasingly biased. When the correlation between predictor variables was 0.75, the standard errors of the parameter estimates were too large to declare statistical significance. CONCLUSIONS Correlations among predictor variables greater than 0.5 when entered into the model simultaneously should be a warning to researchers because the (1) the accuracy of the parameter estimates themselves may be biased and (2) the precision of the estimates may be inflated due to ill-conditioning.},
annote = {Variance parameters biased downwards when multicollinearity is pres},
author = {Bonate, Peter L.},
doi = {10.1023/a:1018828709196},
file = {:Users/aksh/Documents/Papers/1999/Bonate/The effect of collinearity on parameter estimates in nonlinear mixed effect models/Bonate - 1999 - The effect of collinearity on parameter estimates in nonlinear mixed effect models.pdf:pdf},
issn = {0724-8741},
journal = {Pharmaceutical research},
keywords = {NONMEM,Reformulation,Regression diagnostics,Sensitivity analysis,Validation},
mendeley-groups = {Multicollinearity},
month = {may},
number = {5},
pages = {709--17},
pmid = {10350015},
title = {{The effect of collinearity on parameter estimates in nonlinear mixed effect models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10350015},
volume = {16},
year = {1999}
}

@article{Shieh2003,
abstract = {This study investigates the quality of multilevel model parameter estimates and standard errors as a function of varying magnitudes of correlation among Level 1 predictors and model characteristics. The results of the study showthat with multicollinearity presented at Level 1 of a two-level mixed-effects linear model, the fixed-effect parameter estimates produce relatively unbiased values; however, the variance and covariance component estimates produce downwardly biased values except for Level 1 variance (< 5%). The standard errors associated with the parameter estimates are also biased under varied magnitudes of Level 1 predictor correlation.},
annote = {Variance parameters biased downwards when multicollinearity is present},
author = {Shieh, Yann-Yann and Fouladi, Rachel T.},
doi = {10.1177/0013164403258402},
issn = {0013-1644},
journal = {Educational and Psychological Measurement},
mendeley-groups = {Multicollinearity},
month = {dec},
number = {6},
pages = {951--985},
title = {{The Effect of Multicollinearity on Multilevel Modeling Parameter Estimates and Standard Errors}},
url = {http://journals.sagepub.com/doi/10.1177/0013164403258402},
volume = {63},
year = {2003}
}

@article{Su2017,
annote = {See the title (it talks about just a linear regression tho)},
author = {Su, Weijie and Bogdan, Ma{\l}gorzata and Cand{\`{e}}s, Emmanuel},
doi = {10.1214/16-AOS1521},
issn = {0090-5364},
journal = {The Annals of Statistics},
mendeley-groups = {Feature/Effects Selection},
month = {oct},
number = {5},
title = {{False discoveries occur early on the Lasso path}},
url = {https://projecteuclid.org/journals/annals-of-statistics/volume-45/issue-5/False-discoveries-occur-early-on-the-Lasso-path/10.1214/16-AOS1521.full},
volume = {45},
year = {2017}
}

@article{dersimonian1986meta,
  title={Meta-analysis in clinical trials},
  author={DerSimonian, Rebecca and Laird, Nan},
  journal={Controlled clinical trials},
  volume={7},
  number={3},
  pages={177--188},
  year={1986},
  publisher={Elsevier}
}


@article{murray2020global,
  title={Global burden of 87 risk factors in 204 countries and territories, 1990--2019: a systematic analysis for the Global Burden of Disease Study 2019},
  author={Murray, Christopher JL and Aravkin, Aleksandr Y and Zheng, Peng and Abbafati, Cristiana and Abbas, Kaja M and Abbasi-Kangevari, Mohsen and Abd-Allah, Foad and Abdelalim, Ahmed and Abdollahi, Mohammad and Abdollahpour, Ibrahim and others},
  journal={The Lancet},
  volume={396},
  number={10258},
  pages={1223--1249},
  year={2020},
  publisher={Elsevier}
}

@book{zuur2009mixed,
  title={Mixed effects models and extensions in ecology with R},
  author={Zuur, Alain and Ieno, Elena N and Walker, Neil and Saveliev, Anatoly A and Smith, Graham M},
  year={2009},
  publisher={Springer Science \& Business Media}
}

@article{covid2020modeling,
  title={Modeling COVID-19 scenarios for the {United States}},
  author={Robert C. Reiner  and  Ryan M. Barber and James K. Collins and  Peng Zheng and Simon I. Hay and Stephen S. Lim and Christopher J. L. Murray and {IHME COVID-19 Forecasting Team}},
  journal={Nature medicine},
  year={2020},
  publisher={Springer Science and Business Media LLC}
}



@article{zheng2021trimmed,
  title={Trimmed constrained mixed effects models: formulations and algorithms},
  author={Zheng, Peng and Barber, Ryan and Sorensen, Reed JD and Murray, Christopher JL and Aravkin, Aleksandr Y},
  journal={Journal of Computational and Graphical Statistics},
  pages={1--13},
  year={2021},
  publisher={Taylor \& Francis}
}

@article{Berahas2017,
abstract = {Sketching, a dimensionality reduction technique, has received much attention in the statistics community. In this paper, we study sketching in the context of Newton's method for solving finite-sum optimization problems in which the number of variables and data points are both large. We study two forms of sketching that perform dimensionality reduction in data space: Hessian subsampling and randomized Hadamard transformations. Each has its own advantages, and their relative tradeoffs have not been investigated in the optimization literature. Our study focuses on practical versions of the two methods in which the resulting linear systems of equations are solved approximately, at every iteration, using an iterative solver. The advantages of using the conjugate gradient method vs. a stochastic gradient iteration are revealed through a set of numerical experiments, and a complexity analysis of the Hessian subsampling method is presented.},
archivePrefix = {arXiv},
arxivId = {1705.06211},
author = {Berahas, Albert S. and Bollapragada, Raghu and Nocedal, Jorge},
eprint = {1705.06211},
mendeley-groups = {Mathematics/Machine learning/Deep Learning},
month = {may},
title = {{An Investigation of Newton-Sketch and Subsampled Newton Methods}},
url = {http://arxiv.org/abs/1705.06211},
year = {2017}
}

@article{Ibrahim2011,
author = {Ibrahim, Joseph G. and Zhu, Hongtu and Garcia, Ramon I. and Guo, Ruixin},
doi = {10.1111/j.1541-0420.2010.01463.x},
issn = {0006341X},
journal = {Biometrics},
mendeley-groups = {Feature/Effects Selection},
month = {jun},
number = {2},
pages = {495--503},
title = {{Fixed and Random Effects Selection in Mixed Effects Models}},
url = {http://doi.wiley.com/10.1111/j.1541-0420.2010.01463.x},
volume = {67},
year = {2011}
}

@article{pourahmadi2011covariance,
  title={Covariance estimation: The GLM and regularization perspectives},
  author={Pourahmadi, Mohsen},
  journal={Statistical Science},
  pages={369--387},
  year={2011},
  publisher={JSTOR}
}

@article{fan2014robust,
  title={Robust variable selection in linear mixed models},
  author={Fan, Yali and Qin, Guoyou and Zhu, Zhong Yi},
  journal={Communications in Statistics-Theory and Methods},
  volume={43},
  number={21},
  pages={4566--4581},
  year={2014},
  publisher={Taylor \& Francis}
}

@article{pan2018simultaneous,
  title={A simultaneous variable selection methodology for linear mixed models},
  author={Pan, Juming and Shang, Junfeng},
  journal={Journal of Statistical Computation and Simulation},
  volume={88},
  number={17},
  pages={3323--3337},
  year={2018},
  publisher={Taylor \& Francis}
}

@article{schelldorfer2011estimation,
  title={Estimation for high-dimensional linear mixed-effects models using l1-penalization},
  author={Schelldorfer, J{\"u}rg and B{\"u}hlmann, Peter and DE GEER, SARA VAN},
  journal={Scandinavian Journal of Statistics},
  volume={38},
  number={2},
  pages={197--214},
  year={2011},
  publisher={Wiley Online Library}
}

@article{chen2015inference,
  title={Inference for mixed models of ANOVA type with high-dimensional data},
  author={Chen, Fei and Li, Zaixing and Shi, Lei and Zhu, Lixing},
  journal={Journal of Multivariate Analysis},
  volume={133},
  pages={382--401},
  year={2015},
  publisher={Elsevier}
}

@article{fan1997comments,
  title={Comments on ``wavelets in statistics: A review'' by a. antoniadis},
  author={Fan, Jianqing},
  journal={Journal of the Italian Statistical Society},
  volume={6},
  number={2},
  pages={131},
  year={1997},
  publisher={Springer}
}

@article{BM94,
  title={Exposing Constraints},
  author={Burke, J.V. and Mor\'e, J.},
  journal={SIAM J. Optim.},
  volume={4},
  pages={573-595},
  year={1994}
}

@article{Rob82,
  title={Generalized Equations and their Solutions, Part II: Applications to Nonlinear Programming},
  author={Robinson, S.M.},
  journal={Math. Prog. Studies},
  volume={19},
  pages={200-221},
  year={1982}
}

@book{HJ85,
author = {Horn, R.A. and Johnson, C.R.},
booktitle = {Matrix Analysis},
title={Matrix Analysis},
publisher = {Cambridge University Press},
isbn = {978-0-521-54823-6},
year = {1985}
}

@book{BC10,
author = {Bauschke, H.H. and Combettes, P.L.},
booktitle = {Convex Analysis and Monotone Operator Theory in Hilbert Spaces},
publisher = {Canadian Mathematical Society},
isbn = {978-1-4419-9466-0},
issn = {1613-5237},
year = {2010}
}

@article{schelldorfer2011estimation,
  title={Estimation for high-dimensional linear mixed-effects models using ℓ1-penalization},
  author={Schelldorfer, J{\"u}rg and B{\"u}hlmann, Peter and DE GEER, SARA VAN},
  journal={Scandinavian Journal of Statistics},
  volume={38},
  number={2},
  pages={197--214},
  year={2011},
  publisher={Wiley Online Library}
}

@article{groll2014variable,
  title={Variable selection for generalized linear mixed models by L 1-penalized estimation},
  author={Groll, Andreas and Tutz, Gerhard},
  journal={Statistics and Computing},
  volume={24},
  number={2},
  pages={137--154},
  year={2014},
  publisher={Springer}
}

@article{jiang2008fence,
  title={Fence methods for mixed model selection},
  author={Jiang, Jiming and Rao, J Sunil and Gu, Zhonghua and Nguyen, Thuan},
  journal={The Annals of Statistics},
  volume={36},
  number={4},
  pages={1669--1692},
  year={2008},
  publisher={Institute of Mathematical Statistics}
}

@article{lin2013pco,
  title={Fixed and random effects selection by REML and pathwise coordinate optimization},
  author={Lin, Bingqing and Pang, Zhen and Jiang, Jiming},
  journal={Journal of Computational and Graphical Statistics},
  volume={22},
  number={2},
  pages={341--355},
  year={2013},
  publisher={Taylor \& Francis}
}

%% Dynamical systems
@article{bramburger2020poincare,
  title={Poincar{\'e} maps for multiscale physics discovery and nonlinear Floquet theory},
  author={Bramburger, Jason J and Kutz, J Nathan},
  journal={Physica D: Nonlinear Phenomena},
  pages={132479},
  year={2020},
  publisher={Elsevier}
}

@article{bramburger2020sparse,
  title={Sparse Identification of Slow Timescale Dynamics},
  author={Bramburger, Jason J and Dylewsky, Daniel and Kutz, J Nathan},
  journal={arXiv preprint arXiv:2006.00940},
  year={2020}
}

@article{parish2020time,
  title={Time-series machine-learning error models for approximate solutions to parameterized dynamical systems},
  author={Parish, Eric J and Carlberg, Kevin T},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={365},
  pages={112990},
  year={2020},
  publisher={Elsevier}
}

@article{lange2020fourier,
  title={From Fourier to Koopman: Spectral Methods for Long-term Time Series Prediction},
  author={Lange, Henning and Brunton, Steven L and Kutz, Nathan},
  journal={arXiv preprint arXiv:2004.00574},
  year={2020}
}

@article{regazzoni2019machine,
  title={Machine learning for fast and reliable solution of time-dependent differential equations},
  author={Regazzoni, Francesco and Ded{\`e}, Luca and Quarteroni, Alfio},
  journal={J. Comp. Phys.},
  volume={397},
  pages={108852},
  year={2019},
  publisher={Elsevier}
}

@article{dylewsky2019dynamic,
  title={Dynamic mode decomposition for multiscale nonlinear physics},
  author={Dylewsky, Daniel and Tao, Molei and Kutz, J Nathan},
  journal={Physical Review E},
  volume={99},
  number={6},
  pages={063311},
  year={2019},
  publisher={APS}
}

@book{mccormick1987multigrid,
  title={Multigrid methods},
  author={McCormick, Stephen F},
  year={1987},
  publisher={SIAM}
}

@book{trottenberg2000multigrid,
  title={Multigrid},
  author={Trottenberg, Ulrich and Oosterlee, Cornelius W and Schuller, Anton},
  year={2000},
  publisher={Elsevier}
}


@book{hildebrand1987introduction,
  title={Introduction to numerical analysis},
  author={Hildebrand, Francis Begnaud},
  year={1987},
  publisher={Courier Corporation}
}

@book{conte2017elementary,
  title={Elementary numerical analysis: an algorithmic approach},
  author={Conte, Samuel Daniel and De Boor, Carl},
  year={2017},
  publisher={SIAM}
}

@book{guckenheimer2013nonlinear,
  title={Nonlinear oscillations, dynamical systems, and bifurcations of vector fields},
  author={Guckenheimer, John and Holmes, Philip},
  volume={42},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@book{wiggins2003introduction,
  title={Introduction to applied nonlinear dynamical systems and chaos},
  author={Wiggins, Stephen},
  volume={2},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@article{byrne1987stiff,
  title={Stiff ODE solvers: A review of current and coming attractions},
  author={Byrne, George D and Hindmarsh, Alan C},
  journal={Journal of Computational physics},
  volume={70},
  number={1},
  pages={1--62},
  year={1987},
  publisher={Elsevier}
}

@article{enright1975comparing,
  title={Comparing numerical methods for stiff systems of ODE: s},
  author={Enright, Wayne H and Hull, TE and Lindberg, Bengt},
  journal={BIT Numerical Mathematics},
  volume={15},
  number={1},
  pages={10--48},
  year={1975},
  publisher={Springer}
}

@book{courant2008methods,
  title={Methods of Mathematical Physics: Partial Differential Equations},
  author={Courant, Richard and Hilbert, David},
  year={2008},
  publisher={John Wiley \& Sons}
}
@article{kass2018computational,
  title={Computational neuroscience: Mathematical and statistical perspectives},
  author={Kass, Robert E and Amari, Shun-Ichi and Arai, Kensuke and Brown, Emery N and Diekman, Casey O and Diesmann, Markus and Doiron, Brent and Eden, Uri T and Fairhall, Adrienne L and Fiddyment, Grant M and others},
  journal={Annual review of statistics and its application},
  volume={5},
  pages={183--214},
  year={2018},
  publisher={Annual Reviews}
}
@book{daley1993atmospheric,
  title={Atmospheric data analysis},
  author={Daley, Roger},
  number={2},
  year={1993},
  publisher={Cambridge university press}
}
@article{gavin1989stock,
  title={The stock market and exchange rate dynamics},
  author={Gavin, Michael},
  journal={Journal of international money and finance},
  volume={8},
  number={2},
  pages={181--200},
  year={1989},
  publisher={Elsevier}
}

%% System Identification
% historical literature
@book{billings2013nonlinear,
  title={Nonlinear system identification: NARMAX methods in the time, frequency, and spatio-temporal domains},
  author={Billings, Stephen A},
  year={2013},
  publisher={John Wiley \& Sons}
}
@article{juang1993system,
  title={System identification},
  author={Juang, Jer-Nan},
  journal={fvms},
  volume={5},
  pages={119--134},
  year={1993}
}
% Minimal realization theory of Ho and Kalman
@article{ho1966effective,
  title={Effective construction of linear state-variable models from input/output functions},
  author={Ho, BL and K{\'a}lm{\'a}n, Rudolf E},
  journal={at-Automatisierungstechnik},
  volume={14},
  number={1-12},
  pages={545--548},
  year={1966},
  publisher={OLDENBOURG WISSENSCHAFTSVERLAG}
}
% ERA
@article{juang1985eigensystem,
  title={An eigensystem realization algorithm for modal parameter identification and model reduction},
  author={Juang, Jer-Nan and Pappa, Richard S},
  journal={Journal of guidance, control, and dynamics},
  volume={8},
  number={5},
  pages={620--627},
  year={1985}
}
@article{longman1989recursive,
  title={Recursive form of the eigensystem realization algorithm for system identification},
  author={Longman, Richard W and Juang, Jer-Nan},
  journal={Journal of Guidance, Control, and Dynamics},
  volume={12},
  number={5},
  pages={647--652},
  year={1989}
}
% OKID
@article{juang1993identification,
  title={Identification of observer/Kalman filter Markov parameters-Theory and experiments},
  author={Juang, Jer-Nan and Phan, Minh and Horta, Lucas G and Longman, Richard W},
  journal={Journal of Guidance, Control, and Dynamics},
  volume={16},
  number={2},
  pages={320--329},
  year={1993}
}
@inproceedings{phan1991identification,
  title={Identification of linear multivariable systems from a single set of data by identification of observers with assigned real eigenvalues},
  author={Phan, Minh and Juang, Jer-Nan and Longman, Richard},
  booktitle={32nd Structures, Structural Dynamics, and Materials Conference},
  pages={949},
  year={1991}
}
@article{phan1993linear,
  title={Linear system identification via an asymptotically stable observer},
  author={Phan, Minh and Horta, Lucas G and Juang, Jer-Nan and Longman, Richard W},
  journal={Journal of Optimization Theory and Applications},
  volume={79},
  number={1},
  pages={59--86},
  year={1993},
  publisher={Springer}
}
% DMD
@book{kutz2016dynamic,
  title={Dynamic mode decomposition: data-driven modeling of complex systems},
  author={Kutz, J Nathan and Brunton, Steven L and Brunton, Bingni W and Proctor, Joshua L},
  year={2016},
  publisher={SIAM}
}
@article{schmid2010dynamic,
  title={Dynamic mode decomposition of numerical and experimental data},
  author={Schmid, Peter J},
  journal={Journal of fluid mechanics},
  volume={656},
  pages={5--28},
  year={2010},
  publisher={Cambridge University Press}
}
@article{rowley2009spectral,
  title={Spectral analysis of nonlinear flows},
  author={Rowley, Clarence W and Mezi{\'c}, Igor and Bagheri, Shervin and Schlatter, Philipp and Henningson, Dan S},
  journal={Journal of fluid mechanics},
  volume={641},
  pages={115--127},
  year={2009},
  publisher={Cambridge University Press}
}
@article{arbabi2017ergodic,
  title={Ergodic theory, dynamic mode decomposition, and computation of spectral properties of the Koopman operator},
  author={Arbabi, Hassan and Mezic, Igor},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={16},
  number={4},
  pages={2096--2126},
  year={2017},
  publisher={SIAM}
}
@article{jovanovic2014sparsity,
  title={Sparsity-promoting dynamic mode decomposition},
  author={Jovanovi{\'c}, Mihailo R and Schmid, Peter J and Nichols, Joseph W},
  journal={Physics of Fluids},
  volume={26},
  number={2},
  pages={024103},
  year={2014},
  publisher={American Institute of Physics}
}

@article{bistrian2017randomized,
  title={Randomized dynamic mode decomposition for nonintrusive reduced order modelling},
  author={Bistrian, Diana Alina and Navon, Ionel Michael},
  journal={International Journal for Numerical Methods in Engineering},
  volume={112},
  number={1},
  pages={3--25},
  year={2017},
  publisher={Wiley Online Library}
}

@article{erichson2019randomized,
  title={Randomized dynamic mode decomposition},
  author={Erichson, N Benjamin and Mathelin, Lionel and Kutz, J Nathan and Brunton, Steven L},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={18},
  number={4},
  pages={1867--1891},
  year={2019},
  publisher={SIAM}
}

@article{williams2015data,
  title={A data--driven approximation of the koopman operator: Extending dynamic mode decomposition},
  author={Williams, Matthew O and Kevrekidis, Ioannis G and Rowley, Clarence W},
  journal={Journal of Nonlinear Science},
  volume={25},
  number={6},
  pages={1307--1346},
  year={2015},
  publisher={Springer}
}

@article{le2017higher,
  title={Higher order dynamic mode decomposition},
  author={Le Clainche, Soledad and Vega, Jos{\'e} M},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={16},
  number={2},
  pages={882--925},
  year={2017},
  publisher={SIAM}
}

@article{proctor2016dynamic,
  title={Dynamic mode decomposition with control},
  author={Proctor, Joshua L and Brunton, Steven L and Kutz, J Nathan},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={15},
  number={1},
  pages={142--161},
  year={2016},
  publisher={SIAM}
}

@article{hemati2017biasing,
  title={De-biasing the dynamic mode decomposition for applied Koopman spectral analysis of noisy datasets},
  author={Hemati, Maziar S and Rowley, Clarence W and Deem, Eric A and Cattafesta, Louis N},
  journal={Theoretical and Computational Fluid Dynamics},
  volume={31},
  number={4},
  pages={349--368},
  year={2017},
  publisher={Springer}
}

@article{dawson2016characterizing,
  title={Characterizing and correcting for the effect of sensor noise in the dynamic mode decomposition},
  author={Dawson, Scott TM and Hemati, Maziar S and Williams, Matthew O and Rowley, Clarence W},
  journal={Experiments in Fluids},
  volume={57},
  number={3},
  pages={42},
  year={2016},
  publisher={Springer}
}

@article{askham2018variable,
  title={Variable projection methods for an optimized dynamic mode decomposition},
  author={Askham, Travis and Kutz, J Nathan},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={17},
  number={1},
  pages={380--416},
  year={2018},
  publisher={SIAM}
}

@article{proctor2015discovering,
  title={Discovering dynamic patterns from infectious disease data using dynamic mode decomposition},
  author={Proctor, Joshua L and Eckhoff, Philip A},
  journal={International health},
  volume={7},
  number={2},
  pages={139--145},
  year={2015},
  publisher={Oxford University Press}
}

@article{brunton2016extracting,
  title={Extracting spatial--temporal coherent patterns in large-scale neural recordings using dynamic mode decomposition},
  author={Brunton, Bingni W and Johnson, Lise A and Ojemann, Jeffrey G and Kutz, J Nathan},
  journal={Journal of neuroscience methods},
  volume={258},
  pages={1--15},
  year={2016},
  publisher={Elsevier}
}

@article{mann2016dynamic,
  title={Dynamic mode decomposition for financial trading strategies},
  author={Mann, Jordan and Kutz, J Nathan},
  journal={Quantitative Finance},
  volume={16},
  number={11},
  pages={1643--1655},
  year={2016},
  publisher={Taylor \& Francis}
}

@article{taylor2018dynamic,
  title={Dynamic mode decomposition for plasma diagnostics and validation},
  author={Taylor, Roy and Kutz, J Nathan and Morgan, Kyle and Nelson, Brian A},
  journal={Review of Scientific Instruments},
  volume={89},
  number={5},
  pages={053501},
  year={2018},
  publisher={AIP Publishing LLC}
}

@article{berger2015estimation,
  title={Estimation of perturbations in robotic behavior using dynamic mode decomposition},
  author={Berger, Erik and Sastuba, Mark and Vogt, David and Jung, Bernhard and Ben Amor, Heni},
  journal={Advanced Robotics},
  volume={29},
  number={5},
  pages={331--343},
  year={2015},
  publisher={Taylor \& Francis}
}

@inproceedings{berger2014dynamic,
  title={Dynamic mode decomposition for perturbation estimation in human robot interaction},
  author={Berger, Erik and Sastuba, Mark and Vogt, David and Jung, Bernhard and Amor, Heni Ben},
  booktitle={The 23rd IEEE International Symposium on Robot and Human Interactive Communication},
  pages={593--600},
  year={2014},
  organization={IEEE}
}

@article{erichson2019compressed,
  title={Compressed dynamic mode decomposition for background modeling},
  author={Erichson, N Benjamin and Brunton, Steven L and Kutz, J Nathan},
  journal={Journal of Real-Time Image Processing},
  volume={16},
  number={5},
  pages={1479--1492},
  year={2019},
  publisher={Springer}
}

@article{grosek2014dynamic,
  title={Dynamic mode decomposition for real-time background/foreground separation in video},
  author={Grosek, Jacob and Kutz, J Nathan},
  journal={arXiv preprint arXiv:1404.7592},
  year={2014}
}

@article{bi2018dynamic,
  title={Dynamic mode decomposition based video shot detection},
  author={Bi, Chongke and Yuan, Ye and Zhang, Jiawan and Shi, Yun and Xiang, Yiqing and Wang, Yuehuan and Zhang, RongHui},
  journal={IEEE Access},
  volume={6},
  pages={21397--21407},
  year={2018},
  publisher={IEEE}
}

@article{bagheri2013koopman,
  title={Koopman-mode decomposition of the cylinder wake},
  author={Bagheri, Shervin},
  journal={Journal of Fluid Mechanics},
  volume={726},
  pages={596--623},
  year={2013},
  publisher={Cambridge University Press}
}

@article{basley2013space,
  title={Space-time aspects of a three-dimensional multi-modulated open cavity flow},
  author={Basley, J{\'e}r{\'e}my and Pastur, Luc R and Delprat, Nathalie and Lusseyran, Fran{\c{c}}ois},
  journal={Physics of Fluids},
  volume={25},
  number={6},
  pages={064105},
  year={2013},
  publisher={American Institute of Physics}
}

@phdthesis{bellani2011experimental,
  title={Experimental studies of complex flows through image-based techniques},
  author={Bellani, Gabriele},
  year={2011},
  school={KTH Royal Institute of Technology}
}

@inproceedings{mizuno2011investigation,
  title={Investigation of wall-bounded turbulent flow using dynamic mode decomposition},
  author={Mizuno, Yoshinori and Duke, Daniel and Atkinson, Callum and Soria, Julio},
  booktitle={Journal of Physics: Conference Series},
  volume={318},
  number={4},
  pages={042040},
  year={2011},
  organization={IOP Publishing}
}


@article{kamb2020time,
  title={Time-delay observables for Koopman: Theory and applications},
  author={Kamb, Mason and Kaiser, Eurika and Brunton, Steven L and Kutz, J Nathan},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={19},
  number={2},
  pages={886--917},
  year={2020},
  publisher={SIAM}
}

@article{pan2020structure,
  title={On the structure of time-delay embedding in linear models of non-linear dynamical systems},
  author={Pan, Shaowu and Duraisamy, Karthik},
  journal={Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume={30},
  number={7},
  pages={073135},
  year={2020},
  publisher={AIP Publishing LLC}
}

@article{tu2013dynamic,
  title={On dynamic mode decomposition: Theory and applications},
  author={Tu, Jonathan H and Rowley, Clarence W and Luchtenburg, Dirk M and Brunton, Steven L and Kutz, J Nathan},
  journal={arXiv preprint arXiv:1312.0041},
  year={2013}
}
% Symbolic Regression
@article{bongard2007automated,
  title={Automated reverse engineering of nonlinear dynamical systems},
  author={Bongard, Josh and Lipson, Hod},
  journal={Proceedings of the National Academy of Sciences},
  volume={104},
  number={24},
  pages={9943--9948},
  year={2007},
  publisher={National Acad Sciences}
}
@article{schmidt2009distilling,
  title={Distilling free-form natural laws from experimental data},
  author={Schmidt, Michael and Lipson, Hod},
  journal={science},
  volume={324},
  number={5923},
  pages={81--85},
  year={2009},
  publisher={American Association for the Advancement of Science}
}
@article{schmidt2011automated,
  title={Automated refinement and inference of analytical models for metabolic networks},
  author={Schmidt, Michael D and Vallabhajosyula, Ravishankar R and Jenkins, Jerry W and Hood, Jonathan E and Soni, Abhishek S and Wikswo, John P and Lipson, Hod},
  journal={Physical biology},
  volume={8},
  number={5},
  pages={055011},
  year={2011},
  publisher={IOP Publishing}
}
% Gaussian Process
@article{raissi2018hidden,
  title={Hidden physics models: Machine learning of nonlinear partial differential equations},
  author={Raissi, Maziar and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={357},
  pages={125--141},
  year={2018},
  publisher={Elsevier}
}
@article{kocijan2005dynamic,
  title={Dynamic systems identification with Gaussian processes},
  author={Kocijan, Ju{\v{s}} and Girard, Agathe and Banko, Bla{\v{z}} and Murray-Smith, Roderick},
  journal={Mathematical and Computer Modelling of Dynamical Systems},
  volume={11},
  number={4},
  pages={411--424},
  year={2005},
  publisher={Taylor \& Francis}
}
@article{raissi2017machine,
  title={Machine learning of linear differential equations using Gaussian processes},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={348},
  pages={683--693},
  year={2017},
  publisher={Elsevier}
}
@article{raissi2017inferring,
  title={Inferring solutions of differential equations using noisy multi-fidelity data},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={335},
  pages={736--746},
  year={2017},
  publisher={Elsevier}
}
@article{raissi2018numerical,
  title={Numerical Gaussian processes for time-dependent and nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  journal={SIAM Journal on Scientific Computing},
  volume={40},
  number={1},
  pages={A172--A198},
  year={2018},
  publisher={SIAM}
}
% Sparse Regression
%  - ODEs
@article{brunton2016discovering,
  title={Discovering governing equations from data by sparse identification of nonlinear dynamical systems},
  author={Brunton, Steven L and Proctor, Joshua L and Kutz, J Nathan},
  journal={Proceedings of the national academy of sciences},
  volume={113},
  number={15},
  pages={3932--3937},
  year={2016},
  publisher={National Acad Sciences}
}
@article{loiseau2018constrained,
  title={Constrained sparse Galerkin regression},
  author={Loiseau, Jean-Christophe and Brunton, Steven L},
  journal={Journal of Fluid Mechanics},
  volume={838},
  pages={42--67},
  year={2018},
  publisher={Cambridge University Press}
}
@article{chang2019identification,
  title={Identification of physical processes via combined data-driven and data-assimilation methods},
  author={Chang, Haibin and Zhang, Dongxiao},
  journal={Journal of Computational Physics},
  volume={393},
  pages={337--350},
  year={2019},
  publisher={Elsevier}
}
@article{wu2019learning,
  title={Learning physics by data for the motion of a sphere falling in a non-Newtonian fluid},
  author={Wu, Zongmin and Zhang, Ran},
  journal={Communications in Nonlinear Science and Numerical Simulation},
  volume={67},
  pages={577--593},
  year={2019},
  publisher={Elsevier}
}


@article{Ying:2006,
	Author = {L. Ying AND E. J. Cand\`es},
	Journal = {Journal of Computational Physics},
	Pages = {184--215},
	Title = {The phase flow method},
	Volume = {220},
	Year = {2006}}

@article{Brunton2010chaos,
	Author = {S. L. Brunton and C. W. Rowley},
	Journal = {Chaos},
	Pages = {017503},
	Title = {Fast computation of {FTLE} fields for unsteady flows: a comparison of methods},
	Volume = {20},
	Year = {2010}}

@article{Luchtenburg2014jcp,
	Author = {D. M. Luchtenburg and S. L. Brunton and C. W. Rowley},
	Journal = {Journal of Computational Physics},
	Pages = {783--802},
	Title = {Long-time uncertainty propagation using generalized polynomial chaos and flow map composition},
	Volume = {274},
	Year = {2014}}

@article{Brunton2015amr,
	Author = {S. L. Brunton and B. R. Noack},
	Journal = {Applied Mechanics Reviews},
	Pages = {050801-1--050801-48},
	Title = {Closed-loop turbulence control: Progress and challenges},
	Volume = {67},
	Year = {2015}}

@article{Brunton2017natcomm,
	Author = {S. L. Brunton and B. W. Brunton and J. L. Proctor and E. Kaiser and J. N. Kutz},
	Journal = {Nature Communications},
	Number = {19},
	Pages = {1--9},
	Title = {Chaos as an intermittently forced linear system},
	Volume = {8},
	Year = {2017}}

@book{Brunton2019book,
	Author = {S. L. Brunton and J. N. Kutz},
	Publisher = {Cambridge University Press},
	Title = {Data-Driven Science and Engineering: Machine Learning, Dynamical Systems, and Control},
	Year = {2019}}

@article{Brunton2020arfm,
	Author = {Steven L. Brunton and Bernd R. Noack and Petros Koumoutsakos},
	Journal = {Annual Review of Fluid Mechanics},
	Pages = {477--508},
	Title = {Machine Learning for Fluid Mechanics},
	Volume = {52},
	Year = {2020}}


@article{mangan2017model,
  title={Model selection for dynamical systems via sparse regression and information criteria},
  author={Mangan, Niall M and Kutz, J Nathan and Brunton, Steven L and Proctor, Joshua L},
  journal={Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={473},
  number={2204},
  pages={20170009},
  year={2017},
  publisher={The Royal Society Publishing}
}
@article{schaeffer2017sparse,
  title={Sparse model selection via integral terms},
  author={Schaeffer, Hayden and McCalla, Scott G},
  journal={Physical Review E},
  volume={96},
  number={2},
  pages={023302},
  year={2017},
  publisher={APS}
}
@article{schaeffer2018extracting1,
  title={Extracting sparse high-dimensional dynamics from limited data},
  author={Schaeffer, Hayden and Tran, Giang and Ward, Rachel},
  journal={SIAM Journal on Applied Mathematics},
  volume={78},
  number={6},
  pages={3279--3295},
  year={2018},
  publisher={SIAM}
}
@article{schaeffer2018extracting2,
  title={Extracting structured dynamical systems using sparse optimization with very few samples},
  author={Schaeffer, Hayden and Tran, Giang and Ward, Rachel and Zhang, Linan},
  journal={arXiv preprint arXiv:1805.04158},
  year={2018}
}
@article{tran2017exact,
  title={Exact recovery of chaotic systems from highly corrupted data},
  author={Tran, Giang and Ward, Rachel},
  journal={Multiscale Modeling \& Simulation},
  volume={15},
  number={3},
  pages={1108--1129},
  year={2017},
  publisher={SIAM}
}
@article{wang2011predicting,
  title={Predicting catastrophes in nonlinear dynamical systems by compressive sensing},
  author={Wang, Wen-Xu and Yang, Rui and Lai, Ying-Cheng and Kovanis, Vassilios and Grebogi, Celso},
  journal={Physical review letters},
  volume={106},
  number={15},
  pages={154101},
  year={2011},
  publisher={APS}
}

% operator learning
@article{wang2021long,
  title={Long-time integration of parametric evolution equations with physics-informed DeepONets},
  author={Wang, Sifan and Perdikaris, Paris},
  journal={arXiv preprint arXiv:2106.05384},
  year={2021}
}

@article{lu2021learning,
  title={Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators},
  author={Lu, Lu and Jin, Pengzhan and Pang, Guofei and Zhang, Zhongqiang and Karniadakis, George Em},
  journal={Nature Machine Intelligence},
  volume={3},
  number={3},
  pages={218--229},
  year={2021},
  publisher={Nature Publishing Group}
}

%  - PDEs
@article{rudy2017data,
  title={Data-driven discovery of partial differential equations},
  author={Rudy, Samuel H and Brunton, Steven L and Proctor, Joshua L and Kutz, J Nathan},
  journal={Science Advances},
  volume={3},
  number={4},
  pages={e1602614},
  year={2017},
  publisher={American Association for the Advancement of Science}
}
@article{schaeffer2017learning,
  title={Learning partial differential equations via data discovery and sparse optimization},
  author={Schaeffer, Hayden},
  journal={Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={473},
  number={2197},
  pages={20160446},
  year={2017},
  publisher={The Royal Society Publishing}
}
%  - SDEs
@article{boninsegna2018sparse,
  title={Sparse learning of stochastic dynamical equations},
  author={Boninsegna, Lorenzo and N{\"u}ske, Feliks and Clementi, Cecilia},
  journal={The Journal of chemical physics},
  volume={148},
  number={24},
  pages={241723},
  year={2018},
  publisher={AIP Publishing LLC}
}
% others
@article{chen1990non,
  title={Non-linear systems identification using radial basis functions},
  author={Chen, S and Billings, SA and Cowan, CFN and Grant, PM},
  journal={International Journal of Systems Science},
  volume={21},
  number={12},
  pages={2513--2539},
  year={1990},
  publisher={Taylor \& Francis}
}
% Neural Networks
@article{gonzalez1998identification,
  title={Identification of distributed parameter systems: A neural net based approach},
  author={Gonzalez-Garcia, R and Rico-Martinez, R and Kevrekidis, IG},
  journal={Computers \& chemical engineering},
  volume={22},
  pages={S965--S968},
  year={1998},
  publisher={Elsevier}
}
@article{milano2002neural,
  title={Neural network modeling for near wall turbulent flow},
  author={Milano, Michele and Koumoutsakos, Petros},
  journal={Journal of Computational Physics},
  volume={182},
  number={1},
  pages={1--26},
  year={2002},
  publisher={Elsevier}
}
@article{raissi2018multistep,
  title={Multistep neural networks for data-driven discovery of nonlinear dynamical systems},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  journal={arXiv preprint arXiv:1801.01236},
  year={2018}
}
@article{rudy2019deep,
  title={Deep learning of dynamics and signal-noise decomposition with time-stepping constraints},
  author={Rudy, Samuel H and Kutz, J Nathan and Brunton, Steven L},
  journal={Journal of Computational Physics},
  volume={396},
  pages={483--506},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{kim2020robust,
  title={Robust Neural Networks inspired by Strong Stability Preserving Runge-Kutta methods},
  author={Kim, Byungjoo and Chudomelka, Bryce and Park, Jinyoung and Kang, Jaewoo and Hong, Youngjoon and Kim, Hyunwoo J},
  booktitle={European Conference on Computer Vision},
  pages={416--432},
  year={2020},
  organization={Springer}
}

@article{qin2019data,
  title={Data driven governing equations approximation using deep neural networks},
  author={Qin, Tong and Wu, Kailiang and Xiu, Dongbin},
  journal={Journal of Computational Physics},
  volume={395},
  pages={620--635},
  year={2019},
  publisher={Elsevier}
}

@article{bar2019learning,
  title={Learning data-driven discretizations for partial differential equations},
  author={Bar-Sinai, Yohai and Hoyer, Stephan and Hickey, Jason and Brenner, Michael P},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={31},
  pages={15344--15349},
  year={2019},
  publisher={National Acad Sciences}
}
@article{pan2018data,
  title={Data-driven discovery of closure models},
  author={Pan, Shaowu and Duraisamy, Karthik},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={17},
  number={4},
  pages={2381--2413},
  year={2018},
  publisher={SIAM}
}
@article{wan2018data,
  title={Data-assisted reduced-order modeling of extreme events in complex dynamical systems},
  author={Wan, Zhong Yi and Vlachas, Pantelis and Koumoutsakos, Petros and Sapsis, Themistoklis},
  journal={PloS one},
  volume={13},
  number={5},
  year={2018},
  publisher={Public Library of Science}
}
@article{liu2020multiresolution,
  title={Multiresolution Convolutional Autoencoders},
  author={Liu, Yuying and Ponce, Colin and Brunton, Steven L and Kutz, J Nathan},
  journal={arXiv preprint arXiv:2004.04946},
  year={2020}
}
@article{douglas1992mgnet,
  title={MGNet: a multigrid and domain decomposition network},
  author={Douglas, Craig C},
  journal={ACM SIGNUM Newsletter},
  volume={27},
  number={4},
  pages={2--8},
  year={1992},
  publisher={ACM New York, NY, USA}
}
@article{jacobsen2017multiscale,
  title={Multiscale hierarchical convolutional networks},
  author={Jacobsen, J{\"o}rn-Henrik and Oyallon, Edouard and Mallat, St{\'e}phane and Smeulders, Arnold WM},
  journal={arXiv preprint arXiv:1703.04140},
  year={2017}
}

@article{lusch2018deep,
  title={Deep learning for universal linear embeddings of nonlinear dynamics},
  author={Lusch, Bethany and Kutz, J Nathan and Brunton, Steven L},
  journal={Nature communications},
  volume={9},
  number={1},
  pages={1--10},
  year={2018},
  publisher={Nature Publishing Group}
}
@article{gin2021deep,
  title={Deep learning models for global coordinate transformations that linearise PDEs},
  author={Gin, Craig and Lusch, Bethany and Brunton, Steven L and Kutz, J Nathan},
  journal={European Journal of Applied Mathematics},
  volume={32},
  number={3},
  pages={515--539},
  year={2021},
  publisher={Cambridge University Press}
}

@article{li2017extended,
  title={Extended dynamic mode decomposition with dictionary learning: A data-driven adaptive spectral decomposition of the Koopman operator},
  author={Li, Qianxiao and Dietrich, Felix and Bollt, Erik M and Kevrekidis, Ioannis G},
  journal={Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume={27},
  number={10},
  pages={103111},
  year={2017},
  publisher={AIP Publishing LLC}
}

@article{terao2021extended,
  title={Extended dynamic mode decomposition with dictionary learning using neural ordinary differential equations},
  author={Terao, Hiroaki and Shirasaka, Sho and Suzuki, Hideyuki},
  journal={Nonlinear Theory and Its Applications, IEICE},
  volume={12},
  number={4},
  pages={626--638},
  year={2021},
  publisher={The Institute of Electronics, Information and Communication Engineers}
}

@inproceedings{yeung2019learning,
  title={Learning deep neural network representations for Koopman operators of nonlinear dynamical systems},
  author={Yeung, Enoch and Kundu, Soumya and Hodas, Nathan},
  booktitle={2019 American Control Conference (ACC)},
  pages={4832--4839},
  year={2019},
  organization={IEEE}
}

@inproceedings{han2020deep,
  title={Deep learning of koopman representation for control},
  author={Han, Yiqiang and Hao, Wenjian and Vaidya, Umesh},
  booktitle={2020 59th IEEE Conference on Decision and Control (CDC)},
  pages={1890--1895},
  year={2020},
  organization={IEEE}
}

@article{morton2019deep,
  title={Deep variational Koopman models: Inferring Koopman observations for uncertainty-aware dynamics modeling and control},
  author={Morton, Jeremy and Witherden, Freddie D and Kochenderfer, Mykel J},
  journal={arXiv preprint arXiv:1902.09742},
  year={2019}
}

@article{al2021deep,
  title={Deep learning for Koopman operator optimal control},
  author={Al-Gabalawy, Mostafa},
  journal={ISA transactions},
  year={2021},
  publisher={Elsevier}
}

@article{li2019learning,
  title={Learning compositional koopman operators for model-based control},
  author={Li, Yunzhu and He, Hao and Wu, Jiajun and Katabi, Dina and Torralba, Antonio},
  journal={arXiv preprint arXiv:1910.08264},
  year={2019}
}

@article{champion2019data,
  title={Data-driven discovery of coordinates and governing equations},
  author={Champion, Kathleen and Lusch, Bethany and Kutz, J Nathan and Brunton, Steven L},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={45},
  pages={22445--22451},
  year={2019},
  publisher={National Acad Sciences}
}
@article{pathak2017using,
  title={Using machine learning to replicate chaotic attractors and calculate Lyapunov exponents from data},
  author={Pathak, Jaideep and Lu, Zhixin and Hunt, Brian R and Girvan, Michelle and Ott, Edward},
  journal={Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume={27},
  number={12},
  pages={121102},
  year={2017},
  publisher={AIP Publishing LLC}
}
@article{lu2018attractor,
  title={Attractor reconstruction by machine learning},
  author={Lu, Zhixin and Hunt, Brian R and Ott, Edward},
  journal={Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume={28},
  number={6},
  pages={061104},
  year={2018},
  publisher={AIP Publishing LLC}
}
@article{pan2018long,
  title={Long-time predictive modeling of nonlinear dynamical systems using neural networks},
  author={Pan, Shaowu and Duraisamy, Karthik},
  journal={Complexity},
  volume={2018},
  year={2018},
  publisher={Hindawi}
}
@article{pathak2018hybrid,
  title={Hybrid forecasting of chaotic processes: Using machine learning in conjunction with a knowledge-based model},
  author={Pathak, Jaideep and Wikner, Alexander and Fussell, Rebeckah and Chandra, Sarthak and Hunt, Brian R and Girvan, Michelle and Ott, Edward},
  journal={Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume={28},
  number={4},
  pages={041101},
  year={2018},
  publisher={AIP Publishing LLC}
}
@article{vlachas2018data,
  title={Data-driven forecasting of high-dimensional chaotic systems with long short-term memory networks},
  author={Vlachas, Pantelis R and Byeon, Wonmin and Wan, Zhong Y and Sapsis, Themistoklis P and Koumoutsakos, Petros},
  journal={Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={474},
  number={2213},
  pages={20170844},
  year={2018},
  publisher={The Royal Society Publishing}
 }
@inproceedings{wiewel2019latent,
  title={Latent space physics: Towards learning the temporal evolution of fluid flow},
  author={Wiewel, Steffen and Becher, Moritz and Thuerey, Nils},
  booktitle={Computer Graphics Forum},
  volume={38},
  pages={71--82},
  year={2019},
  organization={Wiley Online Library}
}

@article{raissi2018deep,
  title={Deep hidden physics models: Deep learning of nonlinear partial differential equations},
  author={Raissi, Maziar},
  journal={The Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={932--955},
  year={2018},
  publisher={JMLR. org}
}
@article{long2017pde,
  title={PDE-net: Learning PDEs from data},
  author={Long, Zichao and Lu, Yiping and Ma, Xianzhong and Dong, Bin},
  journal={arXiv preprint arXiv:1710.09668},
  year={2017}
}
@article{long2019pde,
  title={PDE-Net 2.0: Learning PDEs from data with a numeric-symbolic hybrid deep network},
  author={Long, Zichao and Lu, Yiping and Dong, Bin},
  journal={Journal of Computational Physics},
  volume={399},
  pages={108925},
  year={2019},
  publisher={Elsevier}
}
@inproceedings{kim2019deep,
  title={Deep fluids: A generative network for parameterized fluid simulations},
  author={Kim, Byungsoo and Azevedo, Vinicius C and Thuerey, Nils and Kim, Theodore and Gross, Markus and Solenthaler, Barbara},
  booktitle={Computer Graphics Forum},
  volume={38},
  pages={59--70},
  year={2019},
  organization={Wiley Online Library}
}

%% PINNs
@article{raissi2017physics,
  title={Physics informed deep learning (part i): Data-driven solutions of nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  journal={arXiv preprint arXiv:1711.10561},
  year={2017}
}

@article{raissi2019physics,
  title={Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George E},
  journal={Journal of Computational Physics},
  volume={378},
  pages={686--707},
  year={2019},
  publisher={Elsevier}
}
@article{pang2019fpinns,
  title={fPINNs: Fractional physics-informed neural networks},
  author={Pang, Guofei and Lu, Lu and Karniadakis, George Em},
  journal={SIAM Journal on Scientific Computing},
  volume={41},
  number={4},
  pages={A2603--A2626},
  year={2019},
  publisher={SIAM}
}
@article{fang2019physics,
  title={A physics-informed neural network framework for PDEs on 3D surfaces: Time independent problems},
  author={Fang, Zhiwei and Zhan, Justin},
  journal={IEEE Access},
  volume={8},
  pages={26328--26335},
  year={2019},
  publisher={IEEE}
}
@article{zhang2020learning,
  title={Learning in modal space: Solving time-dependent stochastic PDEs using physics-informed neural networks},
  author={Zhang, Dongkun and Guo, Ling and Karniadakis, George Em},
  journal={SIAM Journal on Scientific Computing},
  volume={42},
  number={2},
  pages={A639--A665},
  year={2020},
  publisher={SIAM}
}
@article{kharazmi2021hp,
  title={hp-VPINNs: Variational physics-informed neural networks with domain decomposition},
  author={Kharazmi, Ehsan and Zhang, Zhongqiang and Karniadakis, George Em},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={374},
  pages={113547},
  year={2021},
  publisher={Elsevier}
}
@article{jagtap2020conservative,
  title={Conservative physics-informed neural networks on discrete domains for conservation laws: Applications to forward and inverse problems},
  author={Jagtap, Ameya D and Kharazmi, Ehsan and Karniadakis, George Em},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={365},
  pages={113028},
  year={2020},
  publisher={Elsevier}
}
@article{jagtap2020extended,
  title={Extended physics-informed neural networks (xpinns): A generalized space-time domain decomposition based deep learning framework for nonlinear partial differential equations},
  author={Jagtap, Ameya D and Karniadakis, George Em},
  journal={Communications in Computational Physics},
  volume={28},
  number={5},
  pages={2002--2041},
  year={2020}
}
@article{shukla2021parallel,
  title={Parallel physics-informed neural networks via domain decomposition},
  author={Shukla, Khemraj and Jagtap, Ameya D and Karniadakis, George Em},
  journal={arXiv preprint arXiv:2104.10013},
  year={2021}
}
@inproceedings{hennigh2021nvidia,
  title={NVIDIA SimNet™: An AI-Accelerated Multi-Physics Simulation Framework},
  author={Hennigh, Oliver and Narasimhan, Susheela and Nabian, Mohammad Amin and Subramaniam, Akshay and Tangsali, Kaustubh and Fang, Zhiwei and Rietmann, Max and Byeon, Wonmin and Choudhry, Sanjay},
  booktitle={International Conference on Computational Science},
  pages={447--461},
  year={2021},
  organization={Springer}
}
@article{yang2019adversarial,
  title={Adversarial uncertainty quantification in physics-informed neural networks},
  author={Yang, Yibo and Perdikaris, Paris},
  journal={Journal of Computational Physics},
  volume={394},
  pages={136--152},
  year={2019},
  publisher={Elsevier}
}
@article{zhang2019quantifying,
  title={Quantifying total uncertainty in physics-informed neural networks for solving forward and inverse stochastic problems},
  author={Zhang, Dongkun and Lu, Lu and Guo, Ling and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={397},
  pages={108850},
  year={2019},
  publisher={Elsevier}
}
@article{zhu2019physics,
  title={Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data},
  author={Zhu, Yinhao and Zabaras, Nicholas and Koutsourelakis, Phaedon-Stelios and Perdikaris, Paris},
  journal={Journal of Computational Physics},
  volume={394},
  pages={56--81},
  year={2019},
  publisher={Elsevier}
}
@article{sun2020physics,
  title={Physics-constrained bayesian neural network for fluid flow reconstruction with sparse and noisy data},
  author={Sun, Luning and Wang, Jian-Xun},
  journal={Theoretical and Applied Mechanics Letters},
  volume={10},
  number={3},
  pages={161--169},
  year={2020},
  publisher={Elsevier}
}
@article{yang2021b,
  title={B-PINNs: Bayesian physics-informed neural networks for forward and inverse PDE problems with noisy data},
  author={Yang, Liu and Meng, Xuhui and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={425},
  pages={109913},
  year={2021},
  publisher={Elsevier}
}
@article{meng2020composite,
  title={A composite neural network that learns from multi-fidelity data: Application to function approximation and inverse PDE problems},
  author={Meng, Xuhui and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={401},
  pages={109020},
  year={2020},
  publisher={Elsevier}
}
@article{jagtap2020adaptive,
  title={Adaptive activation functions accelerate convergence in deep and physics-informed neural networks},
  author={Jagtap, Ameya D and Kawaguchi, Kenji and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={404},
  pages={109136},
  year={2020},
  publisher={Elsevier}
}
@article{wang2021understanding,
  title={Understanding and mitigating gradient flow pathologies in physics-informed neural networks},
  author={Wang, Sifan and Teng, Yujun and Perdikaris, Paris},
  journal={SIAM Journal on Scientific Computing},
  volume={43},
  number={5},
  pages={A3055--A3081},
  year={2021},
  publisher={SIAM}
}

@article{maddu2021inverse,
  title={Inverse Dirichlet Weighting Enables Reliable Training of Physics Informed Neural Networks},
  author={Maddu, Suryanarayana and Sturm, Dominik and M{\"u}ller, Christian L and Sbalzarini, Ivo F},
  journal={Machine Learning: Science and Technology},
  year={2021},
  publisher={IOP Publishing}
}

@article{zubov2021neuralpde,
  title={NeuralPDE: Automating physics-informed neural networks (PINNs) with error approximations},
  author={Zubov, Kirill and McCarthy, Zoe and Ma, Yingbo and Calisto, Francesco and Pagliarino, Valerio and Azeglio, Simone and Bottero, Luca and Luj{\'a}n, Emmanuel and Sulzer, Valentin and Bharambe, Ashutosh and others},
  journal={arXiv preprint arXiv:2107.09443},
  year={2021}
}

@article{lu2021physics,
  title={Physics-informed neural networks with hard constraints for inverse design},
  author={Lu, Lu and Pestourie, Raphael and Yao, Wenjie and Wang, Zhicheng and Verdugo, Francesc and Johnson, Steven G},
  journal={arXiv preprint arXiv:2102.04626},
  year={2021}
}
@article{gao2021phygeonet,
  title={PhyGeoNet: physics-informed geometry-adaptive convolutional neural networks for solving parameterized steady-state PDEs on irregular domain},
  author={Gao, Han and Sun, Luning and Wang, Jian-Xun},
  journal={Journal of Computational Physics},
  volume={428},
  pages={110079},
  year={2021},
  publisher={Elsevier}
}
@article{shin2020convergence,
  title={On the convergence of physics informed neural networks for linear second-order elliptic and parabolic type PDEs},
  author={Shin, Yeonjong and Darbon, Jerome and Karniadakis, George Em},
  journal={arXiv preprint arXiv:2004.01806},
  year={2020}
}
@article{mishra2020estimates,
  title={Estimates on the generalization error of physics informed neural networks (PINNs) for approximating PDEs},
  author={Mishra, Siddhartha and Molinaro, Roberto},
  journal={arXiv preprint arXiv:2006.16144},
  year={2020}
}
@article{wang2022and,
  title={When and why PINNs fail to train: A neural tangent kernel perspective},
  author={Wang, Sifan and Yu, Xinling and Perdikaris, Paris},
  journal={Journal of Computational Physics},
  volume={449},
  pages={110768},
  year={2022},
  publisher={Elsevier}
}
@article{wang2021learning,
  title={Learning the solution operator of parametric partial differential equations with physics-informed DeepOnets},
  author={Wang, Sifan and Wang, Hanwen and Perdikaris, Paris},
  journal={arXiv preprint arXiv:2103.10974},
  year={2021}
}


%% Deep Learning
% General
@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}
@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}
@article{baldi1989neural,
  title={Neural networks and principal component analysis: Learning from examples without local minima},
  author={Baldi, Pierre and Hornik, Kurt},
  journal={Neural networks},
  volume={2},
  number={1},
  pages={53--58},
  year={1989},
  publisher={Elsevier}
}


@article{taira:07ibfs,
	Author = {K. Taira and T. Colonius},
	Journal = {Journal of Computational Physics},
	Number = 2,
	Pages = {2118-2137},
	Title = {The immersed boundary method: a projection approach.},
	Volume = 225,
	Year = 2007}

@article{taira:fastIBPM,
	Author = {T. Colonius and K. Taira},
	Journal = {Computer Methods in Applied Mechanics and Engineering},
	Pages = {2131-2146},
	Title = {A fast immersed boundary method using a nullspace approach and multi-domain far-field boundary conditions},
	Volume = {197},
	Year = {2008}}


@article{hornik1989multilayer,
	Author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	Journal = {Neural networks},
	Number = {5},
	Pages = {359--366},
	Title = {Multilayer feedforward networks are universal approximators},
	Volume = {2},
	Year = {1989}}

% transfer learning
@article{chen2015net2net,
  title={Net2net: Accelerating learning via knowledge transfer},
  author={Chen, Tianqi and Goodfellow, Ian and Shlens, Jonathon},
  journal={arXiv preprint arXiv:1511.05641},
  year={2015}
}
% Image Processing
@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}
@article{farabet2012learning,
  title={Learning hierarchical features for scene labeling},
  author={Farabet, Clement and Couprie, Camille and Najman, Laurent and LeCun, Yann},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={8},
  pages={1915--1929},
  year={2012},
  publisher={IEEE}
}
@inproceedings{tompson2014joint,
  title={Joint training of a convolutional network and a graphical model for human pose estimation},
  author={Tompson, Jonathan J and Jain, Arjun and LeCun, Yann and Bregler, Christoph},
  booktitle={Advances in neural information processing systems},
  pages={1799--1807},
  year={2014}
}
@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}
% Speech Recognition
@inproceedings{mikolov2011strategies,
  title={Strategies for training large scale neural network language models},
  author={Mikolov, Tom{\'a}{\v{s}} and Deoras, Anoop and Povey, Daniel and Burget, Luk{\'a}{\v{s}} and {\v{C}}ernock{\`y}, Jan},
  booktitle={2011 IEEE Workshop on Automatic Speech Recognition \& Understanding},
  pages={196--201},
  year={2011},
  organization={IEEE}
}
@article{senior2012deep,
  title={Deep neural networks for acoustic modeling in speech recognition},
  author={Senior, A and Vanhoucke, V and Nguyen, P and Sainath, T and others},
  journal={IEEE Signal processing magazine},
  year={2012}
}
@inproceedings{sainath2013deep,
  title={Deep convolutional neural networks for LVCSR},
  author={Sainath, Tara N and Mohamed, Abdel-rahman and Kingsbury, Brian and Ramabhadran, Bhuvana},
  booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
  pages={8614--8618},
  year={2013},
  organization={IEEE}
}
% Natural Language Processing
@article{collobert2011natural,
  title={Natural language processing (almost) from scratch},
  author={Collobert, Ronan and Weston, Jason and Bottou, L{\'e}on and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
  journal={Journal of machine learning research},
  volume={12},
  number={Aug},
  pages={2493--2537},
  year={2011}
}
@article{bordes2014question,
  title={Question answering with subgraph embeddings},
  author={Bordes, Antoine and Chopra, Sumit and Weston, Jason},
  journal={arXiv preprint arXiv:1406.3676},
  year={2014}
}
@article{jean2014using,
  title={On using very large target vocabulary for neural machine translation},
  author={Jean, S{\'e}bastien and Cho, Kyunghyun and Memisevic, Roland and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.2007},
  year={2014}
}
@inproceedings{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  booktitle={Advances in neural information processing systems},
  pages={3104--3112},
  year={2014}
}
% Science
@article{wehmeyer2018time,
  title={Time-lagged autoencoders: Deep learning of slow collective variables for molecular kinetics},
  author={Wehmeyer, Christoph and No{\'e}, Frank},
  journal={The Journal of chemical physics},
  volume={148},
  number={24},
  pages={241703},
  year={2018},
  publisher={AIP Publishing LLC}
}
@article{mardt2018vampnets,
  title={VAMPnets for deep learning of molecular kinetics},
  author={Mardt, Andreas and Pasquali, Luca and Wu, Hao and No{\'e}, Frank},
  journal={Nature communications},
  volume={9},
  number={1},
  pages={1--11},
  year={2018},
  publisher={Nature Publishing Group}
}
@article{ma2015deep,
  title={Deep neural nets as a method for quantitative structure--activity relationships},
  author={Ma, Junshui and Sheridan, Robert P and Liaw, Andy and Dahl, George E and Svetnik, Vladimir},
  journal={Journal of chemical information and modeling},
  volume={55},
  number={2},
  pages={263--274},
  year={2015},
  publisher={ACS Publications}
}
@inproceedings{ciodaro2012online,
  title={Online particle detection with neural networks based on topological calorimetry information},
  author={Ciodaro, T and Deva, D and De Seixas, JM and Damazio, D},
  booktitle={Journal of physics: conference series},
  volume={368},
  number={1},
  pages={012030},
  year={2012},
  organization={IOP Publishing}
}
@article{helmstaedter2013connectomic,
  title={Connectomic reconstruction of the inner plexiform layer in the mouse retina},
  author={Helmstaedter, Moritz and Briggman, Kevin L and Turaga, Srinivas C and Jain, Viren and Seung, H Sebastian and Denk, Winfried},
  journal={Nature},
  volume={500},
  number={7461},
  pages={168--174},
  year={2013},
  publisher={Nature Publishing Group}
}
@article{leung2014deep,
  title={Deep learning of the tissue-regulated splicing code},
  author={Leung, Michael KK and Xiong, Hui Yuan and Lee, Leo J and Frey, Brendan J},
  journal={Bioinformatics},
  volume={30},
  number={12},
  pages={i121--i129},
  year={2014},
  publisher={Oxford University Press}
}
@article{xiong2015human,
  title={The human splicing code reveals new insights into the genetic determinants of disease},
  author={Xiong, Hui Y and Alipanahi, Babak and Lee, Leo J and Bretschneider, Hannes and Merico, Daniele and Yuen, Ryan KC and Hua, Yimin and Gueroussov, Serge and Najafabadi, Hamed S and Hughes, Timothy R and others},
  journal={Science},
  volume={347},
  number={6218},
  pages={1254806},
  year={2015},
  publisher={American Association for the Advancement of Science}
}
% Back Propagation 
@book{werbos1994roots,
  title={The roots of backpropagation: from ordered derivatives to neural networks and political forecasting},
  author={Werbos, Paul John},
  volume={1},
  year={1994},
  publisher={John Wiley \& Sons}
}
@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group}
}
@inproceedings{7fa6b6a5cde14bcfbd7ab3a8f19d0d56,
title = "Une procedure d'apprentissage pour reseau a seuil asymmetrique (A learning scheme for asymmetric threshold networks)",
author = "Yann Lecun",
year = "1985",
language = "English (US)",
pages = "599--604",
booktitle = "Proceedings of Cognitiva 85, Paris, France",
}
% optimization
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}
@article{zhu1997algorithm,
  title={Algorithm 778: L-BFGS-B: Fortran subroutines for large-scale bound-constrained optimization},
  author={Zhu, Ciyou and Byrd, Richard H and Lu, Peihuang and Nocedal, Jorge},
  journal={ACM Transactions on Mathematical Software (TOMS)},
  volume={23},
  number={4},
  pages={550--560},
  year={1997},
  publisher={ACM New York, NY, USA}
}
@misc{Tieleman2012,
  title={{Lecture 6.5---RmsProp: Divide the gradient by a running average of its recent magnitude}},
  author={Tieleman, T. and Hinton, G.},
  howpublished={COURSERA: Neural Networks for Machine Learning},
  year={2012}
}
@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}
% RNN
@misc{Hochreiter:91,
  added-at = {2008-03-11T14:52:34.000+0100},
  author = {Hochreiter, S.},
  biburl = {https://www.bibsonomy.org/bibtex/21e476a44125e2b2b588d2fafbb5f69b0/idsia},
  citeulike-article-id = {2381309},
  comment = {See www7.informatik.tu-muenchen.de/\~{}hochreit; advisor: J. Schmidhuber},
  interhash = {c89e6c3623f880f8f4fbe62fd0d320ac},
  intrahash = {1e476a44125e2b2b588d2fafbb5f69b0},
  keywords = {juergen},
  priority = {2},
  timestamp = {2008-03-11T14:54:33.000+0100},
  title = {{Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, Institut f\"{u}r Informatik, Lehrstuhl Prof. Brauer, Technische Universit\"{a}t M\"{u}nchen}},
  year = 1991
}
@article{bengio1994learning,
  title={Learning long-term dependencies with gradient descent is difficult},
  author={Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
  journal={IEEE transactions on neural networks},
  volume={5},
  number={2},
  pages={157--166},
  year={1994},
  publisher={IEEE}
}
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}
@book{jaeger2002tutorial,
  title={Tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the" echo state network" approach},
  author={Jaeger, Herbert},
  volume={5},
  year={2002},
  publisher={GMD-Forschungszentrum Informationstechnik Bonn}
}
@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013}
}
% ResNet
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
% CNN
@article{peng2018red,
  title={Red-net: A recurrent encoder--decoder network for video-based face alignment},
  author={Peng, Xi and Feris, Rogerio S and Wang, Xiaoyu and Metaxas, Dimitris N},
  journal={International Journal of Computer Vision},
  volume={126},
  number={10},
  pages={1103--1119},
  year={2018},
  publisher={Springer}
}
@article{mallat2016understanding,
  title={Understanding deep convolutional networks},
  author={Mallat, St{\'e}phane},
  journal={Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={374},
  number={2065},
  pages={20150203},
  year={2016},
  publisher={The Royal Society Publishing}
}
@incollection{lecun1999object,
  title={Object recognition with gradient-based learning},
  author={LeCun, Yann and Haffner, Patrick and Bottou, L{\'e}on and Bengio, Yoshua},
  booktitle={Shape, contour and grouping in computer vision},
  pages={319--345},
  year={1999},
  publisher={Springer}
}
@article{hubel1962receptive,
  title={Receptive fields, binocular interaction and functional architecture in the cat's visual cortex},
  author={Hubel, David H and Wiesel, Torsten N},
  journal={The Journal of physiology},
  volume={160},
  number={1},
  pages={106--154},
  year={1962},
  publisher={Wiley Online Library}
}
% Approximation theory
@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}
@article{ma2018priori,
  title={A Priori Estimates for Two-layer Neural Networks},
  author={Ma, Chao and Wu, Lei and others},
  journal={arXiv preprint arXiv:1810.06397},
  year={2018}
}
@article{ma2019priori,
  title={A priori estimates of the population risk for residual networks},
  author={Ma, Chao and Wang, Qingcan and others},
  journal={arXiv preprint arXiv:1903.02154},
  year={2019}
}
@article{ma2019barron,
  title={Barron spaces and the compositional function spaces for neural network models},
  author={Ma, Chao and Wu, Lei and others},
  journal={arXiv preprint arXiv:1906.08039},
  year={2019}
}
@article{poggio2019theoretical,
  title={Theoretical Issues in Deep Networks: Approximation, Optimization and Generalization},
  author={Poggio, Tomaso and Banburski, Andrzej and Liao, Qianli},
  journal={arXiv preprint arXiv:1908.09375},
  year={2019}
}
% Connection to Dynamical Systems
@article{weinan2017proposal,
  title={A proposal on machine learning via dynamical systems},
  author={Weinan, E},
  journal={Communications in Mathematics and Statistics},
  volume={5},
  number={1},
  pages={1--11},
  year={2017},
  publisher={Springer}
}
@article{weinan2019mean,
  title={A mean-field optimal control formulation of deep learning},
  author={Weinan, E and Han, Jiequn and Li, Qianxiao},
  journal={Research in the Mathematical Sciences},
  volume={6},
  number={1},
  pages={10},
  year={2019},
  publisher={Springer}
}
@article{ma2019machine,
  title={Machine Learning from a Continuous Viewpoint},
  author={Ma, Chao and Wu, Lei and others},
  journal={arXiv preprint arXiv:1912.12777},
  year={2019}
}
@article{li2015dynamics,
  title={Dynamics of stochastic gradient algorithms},
  author={Li, Qianxiao and Tai, Cheng and Weinan, E},
  journal={arXiv preprint arXiv:1511.06251},
  year={2015}
}
@inproceedings{li2017stochastic,
  title={Stochastic modified equations and adaptive stochastic gradient algorithms},
  author={Li, Qianxiao and Tai, Cheng and others},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2101--2110},
  year={2017},
  organization={JMLR. org}
}
@article{li2019stochastic,
  title={Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms I: Mathematical Foundations.},
  author={Li, Qianxiao and Tai, Cheng and Weinan, E},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={40},
  pages={1--40},
  year={2019}
}
@article{haber2017stable,
  title={Stable architectures for deep neural networks},
  author={Haber, Eldad and Ruthotto, Lars},
  journal={Inverse Problems},
  volume={34},
  number={1},
  pages={014004},
  year={2017},
  publisher={IOP Publishing}
}
@article{chang2017multi,
  title={Multi-level residual networks from dynamical systems view},
  author={Chang, Bo and Meng, Lili and Haber, Eldad and Tung, Frederick and Begert, David},
  journal={arXiv preprint arXiv:1710.10348},
  year={2017}
}
@inproceedings{chen2018neuralode,
  title={Neural ordinary differential equations},
  author={Chen, Tian Qi and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  booktitle={Advances in neural information processing systems},
  pages={6571--6583},
  year={2018}
}

@article{sitzmann2020implicit,
  title={Implicit Neural Representations with Periodic Activation Functions},
  author={Sitzmann, Vincent and Martel, Julien NP and Bergman, Alexander W and Lindell, David B and Wetzstein, Gordon},
  journal={arXiv preprint arXiv:2006.09661},
  year={2020}
}

@inproceedings{poole2016exponential,
  title={Exponential expressivity in deep neural networks through transient chaos},
  author={Poole, Ben and Lahiri, Subhaneil and Raghu, Maithra and Sohl-Dickstein, Jascha and Ganguli, Surya},
  booktitle={Advances in neural information processing systems},
  pages={3360--3368},
  year={2016}
}
@article{banburski2019theory,
  title={Theory III: Dynamics and generalization in deep networks},
  author={Banburski, Andrzej and Liao, Qianli and Miranda, Brando and Rosasco, Lorenzo and Liang, Bob and Hidary, Jack and Poggio, Tomaso},
  journal={arXiv preprint arXiv:1903.04991},
  year={2019}
}
@article{muehlebach2020optimization,
  title={Optimization with Momentum: Dynamical, Control-Theoretic, and Symplectic Perspectives},
  author={Muehlebach, Michael and Jordan, Michael I},
  journal={arXiv preprint arXiv:2002.12493},
  year={2020}
}
@article{muehlebach2019dynamical,
  title={A dynamical systems perspective on Nesterov acceleration},
  author={Muehlebach, Michael and Jordan, Michael I},
  journal={arXiv preprint arXiv:1905.07436},
  year={2019}
}

%% Multiscale Modeling
% review
@article{weinan2003multiscale,
  title={Multiscale modeling and computation},
  author={Weinan, E and Engquist, Bjorn},
  journal={Notices of the AMS},
  volume={50},
  number={9},
  pages={1062--1070},
  year={2003}
}
@ARTICLE{E:2011,
AUTHOR = {E, W.  and Lu, J. },
TITLE   = {{M}ultiscale modeling},
YEAR    = {2011},
JOURNAL = {Scholarpedia},
VOLUME  = {6},
NUMBER  = {10},
PAGES   = {11527},
DOI     = {10.4249/scholarpedia.11527},
NOTE    = {revision \#91540}
}
% multi-grid method
@article{brandt1977multi,
  title={Multi-level adaptive solutions to boundary-value problems},
  author={Brandt, Achi},
  journal={Mathematics of computation},
  volume={31},
  number={138},
  pages={333--390},
  year={1977}
}
% fast multipole method
@article{greengard1997fast,
  title={A fast algorithm for particle simulations},
  author={Greengard, Leslie and Rokhlin, Vladimir},
  journal={Journal of Computational Physics},
  volume={135},
  number={2},
  pages={280--292},
  year={1997},
  publisher={Academic Press}
}
% adaptive mesh refinement
@article{berger1989local,
  title={Local adaptive mesh refinement for shock hydrodynamics},
  author={Berger, Marsha J and Colella, Phillip and others},
  journal={Journal of computational Physics},
  volume={82},
  number={1},
  pages={64--84},
  year={1989}
}
% domain decomposition
@book{toselli2006domain,
  title={Domain decomposition methods-algorithms and theory},
  author={Toselli, Andrea and Widlund, Olof},
  volume={34},
  year={2006},
  publisher={Springer Science \& Business Media}
}


@article{kutz2016multiresolution,
  title={Multiresolution dynamic mode decomposition},
  author={Kutz, J Nathan and Fu, Xing and Brunton, Steven L},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={15},
  number={2},
  pages={713--735},
  year={2016},
  publisher={SIAM}
}

% multi-resolution representation
@book{kutz2013data,
  title={Data-driven modeling \& scientific computation: methods for complex systems \& big data},
  author={Kutz, J Nathan},
  year={2013},
  publisher={Oxford University Press}
}
@book{daubechies1992ten,
  title={Ten lectures on wavelets},
  author={Daubechies, Ingrid},
  volume={61},
  year={1992},
  publisher={Siam}
}
% HMM
@book{weinan2011principles,
  title={Principles of multiscale modeling},
  author={Weinan, E},
  year={2011},
  publisher={Cambridge University Press}
}
@article{weinan2007heterogeneous,
  title={Heterogeneous multiscale methods: a review},
  author={Weinan, E and Engquist, Bjorn and Li, Xiantao and Ren, Weiqing and Vanden-Eijnden, Eric},
  journal={Communications in computational physics},
  volume={2},
  number={3},
  pages={367--450},
  year={2007},
  publisher={Global Science Press}
}
% equation-free modeling
@article{kevrekidis2003equation,
  title={Equation-free, coarse-grained multiscale computation: Enabling mocroscopic simulators to perform system-level analysis},
  author={Kevrekidis, Ioannis G and Gear, C William and Hyman, James M and Kevrekidid, Panagiotis G and Runborg, Olof and Theodoropoulos, Constantinos and others},
  journal={Communications in Mathematical Sciences},
  volume={1},
  number={4},
  pages={715--762},
  year={2003},
  publisher={International Press of Boston}
}
% applications
@article{car1985unified,
  title={Unified approach for molecular dynamics and density-functional theory},
  author={Car, Richard and Parrinello, Mark},
  journal={Physical review letters},
  volume={55},
  number={22},
  pages={2471},
  year={1985},
  publisher={APS}
}
@article{warshel1976theoretical,
  title={Theoretical studies of enzymic reactions: dielectric, electrostatic and steric stabilization of the carbonium ion in the reaction of lysozyme},
  author={Warshel, Arieh and Levitt, Michael},
  journal={Journal of molecular biology},
  volume={103},
  number={2},
  pages={227--249},
  year={1976},
  publisher={Elsevier}
}
@book{ottinger2012stochastic,
  title={Stochastic processes in polymeric fluids: tools and examples for developing simulation algorithms},
  author={{\"O}ttinger, Hans C},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@article{tadmor1996quasicontinuum,
  title={Quasicontinuum analysis of defects in solids},
  author={Tadmor, Ellad B and Ortiz, Michael and Phillips, Rob},
  journal={Philosophical magazine A},
  volume={73},
  number={6},
  pages={1529--1563},
  year={1996},
  publisher={Taylor \& Francis}
}
@article{bird1987dynamics,
  title={Dynamics of polymeric liquids. Vol. 1: Fluid mechanics},
  author={Bird, Robert Byron and Armstrong, Robert C and Hassager, Ole},
  year={1987}
}






% Appendix

% old ones
@article{poggio2017and,
  title={Why and when can deep-but not shallow-networks avoid the curse of dimensionality: a review},
  author={Poggio, Tomaso and Mhaskar, Hrushikesh and Rosasco, Lorenzo and Miranda, Brando and Liao, Qianli},
  journal={International Journal of Automation and Computing},
  volume={14},
  number={5},
  pages={503--519},
  year={2017},
  publisher={Springer}
}

% reservoir computing
@article{lukovsevivcius2009reservoir,
  title={Reservoir computing approaches to recurrent neural network training},
  author={Luko{\v{s}}evi{\v{c}}ius, Mantas and Jaeger, Herbert},
  journal={Computer Science Review},
  volume={3},
  number={3},
  pages={127--149},
  year={2009},
  publisher={Elsevier}
}

@article{pathak2018model,
  title={Model-free prediction of large spatiotemporally chaotic systems from data: A reservoir computing approach},
  author={Pathak, Jaideep and Hunt, Brian and Girvan, Michelle and Lu, Zhixin and Ott, Edward},
  journal={Physical review letters},
  volume={120},
  number={2},
  pages={024102},
  year={2018},
  publisher={APS}
}

% reinforcement learning
@article{dellnitz2021efficient,
  title={Efficient time stepping for numerical integration using reinforcement learning},
  author={Dellnitz, Michael and H{\"u}llermeier, Eyke and L{\"u}cke, Marvin and Ober-Bl{\"o}baum, Sina and Offen, Christian and Peitz, Sebastian and Pfannschmidt, Karlson},
  journal={arXiv preprint arXiv:2104.03562},
  year={2021}
}

@article{cole1951quasi,
  title={On a quasi-linear parabolic equation occurring in aerodynamics},
  author={Cole, Julian D},
  journal={Quarterly of applied mathematics},
  volume={9},
  number={3},
  pages={225--236},
  year={1951}
}

@techreport{hopf1950partial,
  title={THE PARTIAL DIFFERENTIAL EQUATION U SUB T+ UU SUB X= MU SUB XX},
  author={Hopf, Eberhard},
  year={1950},
  institution={INDIANA UNIV AT BLOOMINGTON}
}

@article{nathan2018applied,
  title={Applied Koopman theory for partial differential equations and data-driven modeling of spatio-temporal systems},
  author={Nathan Kutz, J and Proctor, Joshua L and Brunton, Steven L},
  journal={Complexity},
  volume={2018},
  year={2018},
  publisher={Hindawi}
}

@article{page2018koopman,
  title={Koopman analysis of Burgers equation},
  author={Page, Jacob and Kerswell, Rich R},
  journal={Physical Review Fluids},
  volume={3},
  number={7},
  pages={071901},
  year={2018},
  publisher={APS}
}

@article{balabane2021koopman,
  title={Koopman operator for Burgers's equation},
  author={Balabane, Mikhael and Mendez, Miguel Alfonso and Najem, Sara},
  journal={Physical Review Fluids},
  volume={6},
  number={6},
  pages={064401},
  year={2021},
  publisher={APS}
}

@article{page2019koopman,
  title={Koopman mode expansions between simple invariant solutions},
  author={Page, Jacob and Kerswell, Rich R},
  journal={Journal of Fluid Mechanics},
  volume={879},
  pages={1--27},
  year={2019},
  publisher={Cambridge University Press}
}

@book{evans2010partial,
  title={Partial differential equations},
  author={Evans, Lawrence C},
  volume={19},
  year={2010},
  publisher={American Mathematical Soc.}
}

@article{peherstorfer2022breaking,
  title={Breaking the Kolmogorov Barrier with Nonlinear Model Reduction},
  author={Peherstorfer, Benjamin},
  journal={Notices of the American Mathematical Society},
  volume={69},
  number={5},
  year={2022}
}

%%% extra
@book{lorenz1956empirical,
  title={Empirical orthogonal functions and statistical weather prediction},
  author={Lorenz, Edward N},
  volume={1},
  year={1956},
  publisher={Massachusetts Institute of Technology, Department of Meteorology Cambridge}
}

@article{clark2020nonlinear,
  title={Nonlinear population dynamics are ubiquitous in animals},
  author={Clark, TJ and Luis, Angela D},
  journal={Nature ecology \& evolution},
  volume={4},
  number={1},
  pages={75--81},
  year={2020},
  publisher={Nature Publishing Group}
}

@inproceedings{kalur2021robust,
  title={Robust Adaptive Dynamic Mode Decomposition for Reduce Order Modelling of Partial Differential Equations},
  author={Kalur, Aniketh and Nabi, Saleh and Benosman, Mouhacine},
  booktitle={2021 American Control Conference (ACC)},
  pages={4497--4502},
  year={2021},
  organization={IEEE}
}

@article{kramer2017sparse,
  title={Sparse sensing and DMD-based identification of flow regimes and bifurcations in complex flows},
  author={Kramer, Boris and Grover, Piyush and Boufounos, Petros and Nabi, Saleh and Benosman, Mouhacine},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={16},
  number={2},
  pages={1164--1196},
  year={2017},
  publisher={SIAM}
}

@article{mezic2020koopman,
  title={Koopman operator, geometry, and learning},
  author={Mezic, Igor},
  journal={arXiv preprint arXiv:2010.05377},
  year={2020}
}

@article{koopman1931hamiltonian,
  title={Hamiltonian systems and transformation in Hilbert space},
  author={Koopman, Bernard O},
  journal={Proceedings of the national academy of sciences of the united states of america},
  volume={17},
  number={5},
  pages={315},
  year={1931},
  publisher={National Academy of Sciences}
}

@article{mezic2005spectral,
  title={Spectral properties of dynamical systems, model reduction and decompositions},
  author={Mezi{\'c}, Igor},
  journal={Nonlinear Dynamics},
  volume={41},
  number={1},
  pages={309--325},
  year={2005},
  publisher={Springer}
}

@phdthesis{mezic1994geometrical,
  title={On the geometrical and statistical properties of dynamical systems: theory and applications},
  author={Mezic, Igor},
  year={1994},
  school={California Institute of Technology}
}

@article{brunton2021modern,
  title={Modern Koopman theory for dynamical systems},
  author={Brunton, Steven L and Budi{\v{s}}i{\'c}, Marko and Kaiser, Eurika and Kutz, J Nathan},
  journal={arXiv preprint arXiv:2102.12086},
  year={2021}
}

@article{morton2018deep,
  title={Deep dynamical modeling and control of unsteady fluid flows},
  author={Morton, Jeremy and Jameson, Antony and Kochenderfer, Mykel J and Witherden, Freddie},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{takeishi2017learning,
  title={Learning Koopman invariant subspaces for dynamic mode decomposition},
  author={Takeishi, Naoya and Kawahara, Yoshinobu and Yairi, Takehisa},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{korda2018linear,
  title={Linear predictors for nonlinear dynamical systems: Koopman operator meets model predictive control},
  author={Korda, Milan and Mezi{\'c}, Igor},
  journal={Automatica},
  volume={93},
  pages={149--160},
  year={2018},
  publisher={Elsevier}
}

@article{das2020koopman,
  title={Koopman spectra in reproducing kernel Hilbert spaces},
  author={Das, Suddhasattwa and Giannakis, Dimitrios},
  journal={Applied and Computational Harmonic Analysis},
  volume={49},
  number={2},
  pages={573--607},
  year={2020},
  publisher={Elsevier}
}

@article{koopman1932dynamical,
  title={Dynamical systems of continuous spectra},
  author={Koopman, Bernard O and Neumann, J v},
  journal={Proceedings of the National Academy of Sciences},
  volume={18},
  number={3},
  pages={255--263},
  year={1932},
  publisher={National Acad Sciences}
}

@article{mezic2022numerical,
  title={On numerical approximations of the koopman operator},
  author={Mezi{\'c}, Igor},
  journal={Mathematics},
  volume={10},
  number={7},
  pages={1180},
  year={2022},
  publisher={MDPI}
}

@incollection{pytorch, 
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith}, 
booktitle = {Advances in Neural Information Processing Systems 32}, 
pages = {8024--8035}, 
year = {2019}, 
publisher = {Curran Associates, Inc.}, 
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf} 
}


@book{brunton2022data,
  title={Data-driven science and engineering: Machine learning, dynamical systems, and control},
  author={Brunton, Steven L and Kutz, J Nathan},
  year={2022},
  publisher={Cambridge University Press}
}

@article{benner2015survey,
  title={A survey of projection-based model reduction methods for parametric dynamical systems},
  author={Benner, Peter and Gugercin, Serkan and Willcox, Karen},
  journal={SIAM review},
  volume={57},
  number={4},
  pages={483--531},
  year={2015},
  publisher={SIAM}
}

@article{rowley2017model,
  title={Model reduction for flow analysis and control},
  author={Rowley, Clarence W and Dawson, Scott TM},
  journal={Annu. Rev. Fluid Mech},
  volume={49},
  number={1},
  pages={387--417},
  year={2017}
}

@inproceedings{farahmand2016learning,
  title={Learning to control partial differential equations: Regularized fitted Q-iteration approach},
  author={Farahmand, Amir-massoud and Nabi, Saleh and Grover, Piyush and Nikovski, Daniel N},
  booktitle={2016 IEEE 55th Conference on Decision and Control (CDC)},
  pages={4578--4585},
  year={2016},
  organization={IEEE}
}

@article{nabi2022robust,
  title={Robust preconditioned one-shot methods and direct-adjoint-looping for optimizing Reynolds-averaged turbulent flows},
  author={Nabi, Saleh and Grover, Piyush and Caulfield, CP},
  journal={Computers \& Fluids},
  volume={238},
  pages={105390},
  year={2022},
  publisher={Elsevier}
}

@article{lucia2004reduced,
  title={Reduced-order modeling: new approaches for computational physics},
  author={Lucia, David J and Beran, Philip S and Silva, Walter A},
  journal={Progress in aerospace sciences},
  volume={40},
  number={1-2},
  pages={51--117},
  year={2004},
  publisher={Elsevier}
}

@article{ahmed2021closures,
  title={On closures for reduced order models—A spectrum of first-principle to machine-learned avenues},
  author={Ahmed, Shady E and Pawar, Suraj and San, Omer and Rasheed, Adil and Iliescu, Traian and Noack, Bernd R},
  journal={Physics of Fluids},
  volume={33},
  number={9},
  pages={091301},
  year={2021},
  publisher={AIP Publishing LLC}
}



@book{holmes2012turbulence,
  title={Turbulence, coherent structures, dynamical systems and symmetry},
  author={Holmes, Philip and Lumley, John L and Berkooz, Gahl and Rowley, Clarence W},
  year={2012},
  publisher={Cambridge university press}
}

@article{lee2020model,
  title={Model reduction of dynamical systems on nonlinear manifolds using deep convolutional autoencoders},
  author={Lee, Kookjin and Carlberg, Kevin T},
  journal={Journal of Computational Physics},
  volume={404},
  pages={108973},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{nabi2020improving,
  title={Improving LiDAR performance on complex terrain using CFD-based correction and direct-adjoint-loop optimization},
  author={Nabi, S and Nishio, N and Grover, P and Matai, R and Kajiyama, Y and Kotake, N and Kameyama, S and Yoshiki, W and Iida, M},
  booktitle={Journal of Physics: Conference Series},
  volume={1452},
  pages={012082},
  year={2020},
  organization={IOP Publishing}
}



@article{jones2020characterising,
  title={Characterising the Digital Twin: A systematic literature review},
  author={Jones, David and Snider, Chris and Nassehi, Aydin and Yon, Jason and Hicks, Ben},
  journal={CIRP Journal of Manufacturing Science and Technology},
  volume={29},
  pages={36--52},
  year={2020},
  publisher={Elsevier}
}

@book{noack2011reduced,
  title={Reduced-order modelling for flow control},
  author={Noack, Bernd R and Morzynski, Marek and Tadmor, Gilead},
  volume={528},
  year={2011},
  publisher={Springer Science \& Business Media}
}



@article{fries2022lasdi,
  title={Lasdi: Parametric latent space dynamics identification},
  author={Fries, William D and He, Xiaolong and Choi, Youngsoo},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={399},
  pages={115436},
  year={2022},
  publisher={Elsevier}
}

@article{he2022glasdi,
  title={gLaSDI: Parametric Physics-informed Greedy Latent Space Dynamics Identification},
  author={He, Xiaolong and Choi, Youngsoo and Fries, William D and Belof, Jon and Chen, Jiun-Shyan},
  journal={arXiv preprint arXiv:2204.12005},
  year={2022}
}

@article{cranmer2020discovering,
  title={Discovering symbolic models from deep learning with inductive biases},
  author={Cranmer, Miles and Sanchez Gonzalez, Alvaro and Battaglia, Peter and Xu, Rui and Cranmer, Kyle and Spergel, David and Ho, Shirley},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17429--17442},
  year={2020}
}




@article{liu2022physics,
  title={Physics-Informed Koopman Network},
  author={Liu, Yuying and Sholokhov, Aleksei and Mansour, Hassan and Nabi, Saleh},
  journal={arXiv preprint arXiv:2211.09419},
  year={2022}
}



@article{qian2020lift,
  title={Lift \& learn: Physics-informed machine learning for large-scale nonlinear dynamical systems},
  author={Qian, Elizabeth and Kramer, Boris and Peherstorfer, Benjamin and Willcox, Karen},
  journal={Physica D: Nonlinear Phenomena},
  volume={406},
  pages={132401},
  year={2020},
  publisher={Elsevier}
}

@article{peherstorfer2016data,
  title={Data-driven operator inference for nonintrusive projection-based model reduction},
  author={Peherstorfer, Benjamin and Willcox, Karen},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={306},
  pages={196--215},
  year={2016},
  publisher={Elsevier}
}

@article{rackauckas2020udes,
  title={Universal differential equations for scientific machine learning},
  author={Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali and Edelman, Alan},
  journal={arXiv preprint arXiv:2001.04385},
  year={2020}
}

@article{chen2021discovering,
  title={Discovering State Variables Hidden in Experimental Data},
  author={Chen, Boyuan and Huang, Kuang and Raghupathi, Sunand and Chandratreya, Ishaan and Du, Qiang and Lipson, Hod},
  journal={arXiv preprint arXiv:2112.10755},
  year={2021}
}

@article{delahunt2022sindynoise,
  title={A toolkit for data-driven discovery of governing equations in high-noise regimes},
  author={Delahunt, Charles B and Kutz, J Nathan},
  journal={IEEE Access},
  volume={10},
  pages={31210--31234},
  year={2022},
  publisher={IEEE}
}

@article{chen2018neural,
  title={Neural ordinary differential equations},
  author={Chen, Ricky TQ and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@incollection{NEURIPS2019_9015, 
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith}, 
booktitle = {Advances in Neural Information Processing Systems 32}, 
pages = {8024--8035}, 
year = {2019}, 
publisher = {Curran Associates, Inc.}, 
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf} 
}


@article{burgers1948mathematical,
  title={A mathematical model illustrating the theory of turbulence},
  author={Burgers, Johannes Martinus},
  journal={Advances in applied mechanics},
  volume={1},
  pages={171--199},
  year={1948},
  publisher={Elsevier}
}

@book{trefethen2000spectral,
  title={Spectral methods in MATLAB},
  author={Trefethen, Lloyd N},
  year={2000},
  publisher={SIAM}
}

@inproceedings{kojimalearning,
  title={Learning Deep Input-Output Stable Dynamics},
  author={Kojima, Ryosuke and Okamoto, Yuji},
  year={2022},
  booktitle={Advances in Neural Information Processing Systems}
}

@inproceedings{otterness2017evaluation,
  title={An evaluation of the NVIDIA TX1 for supporting real-time computer-vision workloads},
  author={Otterness, Nathan and Yang, Ming and Rust, Sarah and Park, Eunbyung and Anderson, James H and Smith, F Donelson and Berg, Alex and Wang, Shige},
  booktitle={2017 IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS)},
  pages={353--364},
  year={2017},
  organization={IEEE}
}

@book{duriez2017machine,
  title={Machine learning control-taming nonlinear dynamics and turbulence},
  author={Duriez, Thomas and Brunton, Steven L and Noack, Bernd R},
  volume={116},
  year={2017},
  publisher={Springer}
}

@article{patel2021global,
  title={Global convergence and stability of stochastic gradient descent},
  author={Patel, Vivak and Tian, Bowen and Zhang, Shushu},
  journal={arXiv preprint arXiv:2110.01663},
  year={2021}
}

@article{friedlander2012hybrid,
  title={Hybrid deterministic-stochastic methods for data fitting},
  author={Friedlander, Michael P and Schmidt, Mark},
  journal={SIAM Journal on Scientific Computing},
  volume={34},
  number={3},
  pages={A1380--A1405},
  year={2012},
  publisher={SIAM}
}

@article{subramanian2022adaptive,
  title={Adaptive Self-supervision Algorithms for Physics-informed Neural Networks},
  author={Subramanian, Shashank and Kirby, Robert M and Mahoney, Michael W and Gholami, Amir},
  journal={arXiv preprint arXiv:2207.04084},
  year={2022}
}

@book{shapiro2021lectures,
  title={Lectures on stochastic programming: modeling and theory},
  author={Shapiro, Alexander and Dentcheva, Darinka and Ruszczynski, Andrzej},
  year={2021},
  publisher={SIAM}
}

%% Dynamical systems
@article{bramburger2020poincare,
  title={Poincar{\'e} maps for multiscale physics discovery and nonlinear Floquet theory},
  author={Bramburger, Jason J and Kutz, J Nathan},
  journal={Physica D: Nonlinear Phenomena},
  pages={132479},
  year={2020},
  publisher={Elsevier}
}

@article{bramburger2020sparse,
  title={Sparse Identification of Slow Timescale Dynamics},
  author={Bramburger, Jason J and Dylewsky, Daniel and Kutz, J Nathan},
  journal={arXiv preprint arXiv:2006.00940},
  year={2020}
}

@article{parish2020time,
  title={Time-series machine-learning error models for approximate solutions to parameterized dynamical systems},
  author={Parish, Eric J and Carlberg, Kevin T},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={365},
  pages={112990},
  year={2020},
  publisher={Elsevier}
}

@article{lange2020fourier,
  title={From Fourier to Koopman: Spectral Methods for Long-term Time Series Prediction},
  author={Lange, Henning and Brunton, Steven L and Kutz, Nathan},
  journal={arXiv preprint arXiv:2004.00574},
  year={2020}
}

@article{regazzoni2019machine,
  title={Machine learning for fast and reliable solution of time-dependent differential equations},
  author={Regazzoni, Francesco and Ded{\`e}, Luca and Quarteroni, Alfio},
  journal={J. Comp. Phys.},
  volume={397},
  pages={108852},
  year={2019},
  publisher={Elsevier}
}

@article{dylewsky2019dynamic,
  title={Dynamic mode decomposition for multiscale nonlinear physics},
  author={Dylewsky, Daniel and Tao, Molei and Kutz, J Nathan},
  journal={Physical Review E},
  volume={99},
  number={6},
  pages={063311},
  year={2019},
  publisher={APS}
}

@book{mccormick1987multigrid,
  title={Multigrid methods},
  author={McCormick, Stephen F},
  year={1987},
  publisher={SIAM}
}

@book{trottenberg2000multigrid,
  title={Multigrid},
  author={Trottenberg, Ulrich and Oosterlee, Cornelius W and Schuller, Anton},
  year={2000},
  publisher={Elsevier}
}


@book{hildebrand1987introduction,
  title={Introduction to numerical analysis},
  author={Hildebrand, Francis Begnaud},
  year={1987},
  publisher={Courier Corporation}
}

@book{conte2017elementary,
  title={Elementary numerical analysis: an algorithmic approach},
  author={Conte, Samuel Daniel and De Boor, Carl},
  year={2017},
  publisher={SIAM}
}

@book{guckenheimer2013nonlinear,
  title={Nonlinear oscillations, dynamical systems, and bifurcations of vector fields},
  author={Guckenheimer, John and Holmes, Philip},
  volume={42},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@book{wiggins2003introduction,
  title={Introduction to applied nonlinear dynamical systems and chaos},
  author={Wiggins, Stephen},
  volume={2},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@article{byrne1987stiff,
  title={Stiff ODE solvers: A review of current and coming attractions},
  author={Byrne, George D and Hindmarsh, Alan C},
  journal={Journal of Computational physics},
  volume={70},
  number={1},
  pages={1--62},
  year={1987},
  publisher={Elsevier}
}

@article{enright1975comparing,
  title={Comparing numerical methods for stiff systems of ODE: s},
  author={Enright, Wayne H and Hull, TE and Lindberg, Bengt},
  journal={BIT Numerical Mathematics},
  volume={15},
  number={1},
  pages={10--48},
  year={1975},
  publisher={Springer}
}

@book{courant2008methods,
  title={Methods of Mathematical Physics: Partial Differential Equations},
  author={Courant, Richard and Hilbert, David},
  year={2008},
  publisher={John Wiley \& Sons}
}
@article{kass2018computational,
  title={Computational neuroscience: Mathematical and statistical perspectives},
  author={Kass, Robert E and Amari, Shun-Ichi and Arai, Kensuke and Brown, Emery N and Diekman, Casey O and Diesmann, Markus and Doiron, Brent and Eden, Uri T and Fairhall, Adrienne L and Fiddyment, Grant M and others},
  journal={Annual review of statistics and its application},
  volume={5},
  pages={183--214},
  year={2018},
  publisher={Annual Reviews}
}
@book{daley1993atmospheric,
  title={Atmospheric data analysis},
  author={Daley, Roger},
  number={2},
  year={1993},
  publisher={Cambridge university press}
}
@article{gavin1989stock,
  title={The stock market and exchange rate dynamics},
  author={Gavin, Michael},
  journal={Journal of international money and finance},
  volume={8},
  number={2},
  pages={181--200},
  year={1989},
  publisher={Elsevier}
}

%% System Identification
% historical literature
@book{billings2013nonlinear,
  title={Nonlinear system identification: NARMAX methods in the time, frequency, and spatio-temporal domains},
  author={Billings, Stephen A},
  year={2013},
  publisher={John Wiley \& Sons}
}
@article{juang1993system,
  title={System identification},
  author={Juang, Jer-Nan},
  journal={fvms},
  volume={5},
  pages={119--134},
  year={1993}
}
% Minimal realization theory of Ho and Kalman
@article{ho1966effective,
  title={Effective construction of linear state-variable models from input/output functions},
  author={Ho, BL and K{\'a}lm{\'a}n, Rudolf E},
  journal={at-Automatisierungstechnik},
  volume={14},
  number={1-12},
  pages={545--548},
  year={1966},
  publisher={OLDENBOURG WISSENSCHAFTSVERLAG}
}
% ERA
@article{juang1985eigensystem,
  title={An eigensystem realization algorithm for modal parameter identification and model reduction},
  author={Juang, Jer-Nan and Pappa, Richard S},
  journal={Journal of guidance, control, and dynamics},
  volume={8},
  number={5},
  pages={620--627},
  year={1985}
}
@article{longman1989recursive,
  title={Recursive form of the eigensystem realization algorithm for system identification},
  author={Longman, Richard W and Juang, Jer-Nan},
  journal={Journal of Guidance, Control, and Dynamics},
  volume={12},
  number={5},
  pages={647--652},
  year={1989}
}
% OKID
@article{juang1993identification,
  title={Identification of observer/Kalman filter Markov parameters-Theory and experiments},
  author={Juang, Jer-Nan and Phan, Minh and Horta, Lucas G and Longman, Richard W},
  journal={Journal of Guidance, Control, and Dynamics},
  volume={16},
  number={2},
  pages={320--329},
  year={1993}
}
@inproceedings{phan1991identification,
  title={Identification of linear multivariable systems from a single set of data by identification of observers with assigned real eigenvalues},
  author={Phan, Minh and Juang, Jer-Nan and Longman, Richard},
  booktitle={32nd Structures, Structural Dynamics, and Materials Conference},
  pages={949},
  year={1991}
}
@article{phan1993linear,
  title={Linear system identification via an asymptotically stable observer},
  author={Phan, Minh and Horta, Lucas G and Juang, Jer-Nan and Longman, Richard W},
  journal={Journal of Optimization Theory and Applications},
  volume={79},
  number={1},
  pages={59--86},
  year={1993},
  publisher={Springer}
}
% DMD
@book{kutz2016dynamic,
  title={Dynamic mode decomposition: data-driven modeling of complex systems},
  author={Kutz, J Nathan and Brunton, Steven L and Brunton, Bingni W and Proctor, Joshua L},
  year={2016},
  publisher={SIAM}
}
@article{schmid2010dynamic,
  title={Dynamic mode decomposition of numerical and experimental data},
  author={Schmid, Peter J},
  journal={Journal of fluid mechanics},
  volume={656},
  pages={5--28},
  year={2010},
  publisher={Cambridge University Press}
}
@article{rowley2009spectral,
  title={Spectral analysis of nonlinear flows},
  author={Rowley, Clarence W and Mezi{\'c}, Igor and Bagheri, Shervin and Schlatter, Philipp and Henningson, Dan S},
  journal={Journal of fluid mechanics},
  volume={641},
  pages={115--127},
  year={2009},
  publisher={Cambridge University Press}
}
@article{arbabi2017ergodic,
  title={Ergodic theory, dynamic mode decomposition, and computation of spectral properties of the Koopman operator},
  author={Arbabi, Hassan and Mezic, Igor},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={16},
  number={4},
  pages={2096--2126},
  year={2017},
  publisher={SIAM}
}
@article{jovanovic2014sparsity,
  title={Sparsity-promoting dynamic mode decomposition},
  author={Jovanovi{\'c}, Mihailo R and Schmid, Peter J and Nichols, Joseph W},
  journal={Physics of Fluids},
  volume={26},
  number={2},
  pages={024103},
  year={2014},
  publisher={American Institute of Physics}
}

@article{bistrian2017randomized,
  title={Randomized dynamic mode decomposition for nonintrusive reduced order modelling},
  author={Bistrian, Diana Alina and Navon, Ionel Michael},
  journal={International Journal for Numerical Methods in Engineering},
  volume={112},
  number={1},
  pages={3--25},
  year={2017},
  publisher={Wiley Online Library}
}

@article{erichson2019randomized,
  title={Randomized dynamic mode decomposition},
  author={Erichson, N Benjamin and Mathelin, Lionel and Kutz, J Nathan and Brunton, Steven L},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={18},
  number={4},
  pages={1867--1891},
  year={2019},
  publisher={SIAM}
}

@article{williams2015data,
  title={A data--driven approximation of the koopman operator: Extending dynamic mode decomposition},
  author={Williams, Matthew O and Kevrekidis, Ioannis G and Rowley, Clarence W},
  journal={Journal of Nonlinear Science},
  volume={25},
  number={6},
  pages={1307--1346},
  year={2015},
  publisher={Springer}
}

@article{le2017higher,
  title={Higher order dynamic mode decomposition},
  author={Le Clainche, Soledad and Vega, Jos{\'e} M},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={16},
  number={2},
  pages={882--925},
  year={2017},
  publisher={SIAM}
}

@article{proctor2016dynamic,
  title={Dynamic mode decomposition with control},
  author={Proctor, Joshua L and Brunton, Steven L and Kutz, J Nathan},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={15},
  number={1},
  pages={142--161},
  year={2016},
  publisher={SIAM}
}

@article{hemati2017biasing,
  title={De-biasing the dynamic mode decomposition for applied Koopman spectral analysis of noisy datasets},
  author={Hemati, Maziar S and Rowley, Clarence W and Deem, Eric A and Cattafesta, Louis N},
  journal={Theoretical and Computational Fluid Dynamics},
  volume={31},
  number={4},
  pages={349--368},
  year={2017},
  publisher={Springer}
}

@article{dawson2016characterizing,
  title={Characterizing and correcting for the effect of sensor noise in the dynamic mode decomposition},
  author={Dawson, Scott TM and Hemati, Maziar S and Williams, Matthew O and Rowley, Clarence W},
  journal={Experiments in Fluids},
  volume={57},
  number={3},
  pages={42},
  year={2016},
  publisher={Springer}
}

@article{askham2018variable,
  title={Variable projection methods for an optimized dynamic mode decomposition},
  author={Askham, Travis and Kutz, J Nathan},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={17},
  number={1},
  pages={380--416},
  year={2018},
  publisher={SIAM}
}

@article{proctor2015discovering,
  title={Discovering dynamic patterns from infectious disease data using dynamic mode decomposition},
  author={Proctor, Joshua L and Eckhoff, Philip A},
  journal={International health},
  volume={7},
  number={2},
  pages={139--145},
  year={2015},
  publisher={Oxford University Press}
}

@article{brunton2016extracting,
  title={Extracting spatial--temporal coherent patterns in large-scale neural recordings using dynamic mode decomposition},
  author={Brunton, Bingni W and Johnson, Lise A and Ojemann, Jeffrey G and Kutz, J Nathan},
  journal={Journal of neuroscience methods},
  volume={258},
  pages={1--15},
  year={2016},
  publisher={Elsevier}
}

@article{mann2016dynamic,
  title={Dynamic mode decomposition for financial trading strategies},
  author={Mann, Jordan and Kutz, J Nathan},
  journal={Quantitative Finance},
  volume={16},
  number={11},
  pages={1643--1655},
  year={2016},
  publisher={Taylor \& Francis}
}

@article{taylor2018dynamic,
  title={Dynamic mode decomposition for plasma diagnostics and validation},
  author={Taylor, Roy and Kutz, J Nathan and Morgan, Kyle and Nelson, Brian A},
  journal={Review of Scientific Instruments},
  volume={89},
  number={5},
  pages={053501},
  year={2018},
  publisher={AIP Publishing LLC}
}

@article{berger2015estimation,
  title={Estimation of perturbations in robotic behavior using dynamic mode decomposition},
  author={Berger, Erik and Sastuba, Mark and Vogt, David and Jung, Bernhard and Ben Amor, Heni},
  journal={Advanced Robotics},
  volume={29},
  number={5},
  pages={331--343},
  year={2015},
  publisher={Taylor \& Francis}
}

@inproceedings{berger2014dynamic,
  title={Dynamic mode decomposition for perturbation estimation in human robot interaction},
  author={Berger, Erik and Sastuba, Mark and Vogt, David and Jung, Bernhard and Amor, Heni Ben},
  booktitle={The 23rd IEEE International Symposium on Robot and Human Interactive Communication},
  pages={593--600},
  year={2014},
  organization={IEEE}
}

@article{erichson2019compressed,
  title={Compressed dynamic mode decomposition for background modeling},
  author={Erichson, N Benjamin and Brunton, Steven L and Kutz, J Nathan},
  journal={Journal of Real-Time Image Processing},
  volume={16},
  number={5},
  pages={1479--1492},
  year={2019},
  publisher={Springer}
}

@article{grosek2014dynamic,
  title={Dynamic mode decomposition for real-time background/foreground separation in video},
  author={Grosek, Jacob and Kutz, J Nathan},
  journal={arXiv preprint arXiv:1404.7592},
  year={2014}
}

@article{bi2018dynamic,
  title={Dynamic mode decomposition based video shot detection},
  author={Bi, Chongke and Yuan, Ye and Zhang, Jiawan and Shi, Yun and Xiang, Yiqing and Wang, Yuehuan and Zhang, RongHui},
  journal={IEEE Access},
  volume={6},
  pages={21397--21407},
  year={2018},
  publisher={IEEE}
}

@article{bagheri2013koopman,
  title={Koopman-mode decomposition of the cylinder wake},
  author={Bagheri, Shervin},
  journal={Journal of Fluid Mechanics},
  volume={726},
  pages={596--623},
  year={2013},
  publisher={Cambridge University Press}
}

@article{basley2013space,
  title={Space-time aspects of a three-dimensional multi-modulated open cavity flow},
  author={Basley, J{\'e}r{\'e}my and Pastur, Luc R and Delprat, Nathalie and Lusseyran, Fran{\c{c}}ois},
  journal={Physics of Fluids},
  volume={25},
  number={6},
  pages={064105},
  year={2013},
  publisher={American Institute of Physics}
}

@phdthesis{bellani2011experimental,
  title={Experimental studies of complex flows through image-based techniques},
  author={Bellani, Gabriele},
  year={2011},
  school={KTH Royal Institute of Technology}
}

@inproceedings{mizuno2011investigation,
  title={Investigation of wall-bounded turbulent flow using dynamic mode decomposition},
  author={Mizuno, Yoshinori and Duke, Daniel and Atkinson, Callum and Soria, Julio},
  booktitle={Journal of Physics: Conference Series},
  volume={318},
  number={4},
  pages={042040},
  year={2011},
  organization={IOP Publishing}
}


@article{kamb2020time,
  title={Time-delay observables for Koopman: Theory and applications},
  author={Kamb, Mason and Kaiser, Eurika and Brunton, Steven L and Kutz, J Nathan},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={19},
  number={2},
  pages={886--917},
  year={2020},
  publisher={SIAM}
}

@article{pan2020structure,
  title={On the structure of time-delay embedding in linear models of non-linear dynamical systems},
  author={Pan, Shaowu and Duraisamy, Karthik},
  journal={Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume={30},
  number={7},
  pages={073135},
  year={2020},
  publisher={AIP Publishing LLC}
}

@article{tu2013dynamic,
  title={On dynamic mode decomposition: Theory and applications},
  author={Tu, Jonathan H and Rowley, Clarence W and Luchtenburg, Dirk M and Brunton, Steven L and Kutz, J Nathan},
  journal={arXiv preprint arXiv:1312.0041},
  year={2013}
}
% Symbolic Regression
@article{bongard2007automated,
  title={Automated reverse engineering of nonlinear dynamical systems},
  author={Bongard, Josh and Lipson, Hod},
  journal={Proceedings of the National Academy of Sciences},
  volume={104},
  number={24},
  pages={9943--9948},
  year={2007},
  publisher={National Acad Sciences}
}
@article{schmidt2009distilling,
  title={Distilling free-form natural laws from experimental data},
  author={Schmidt, Michael and Lipson, Hod},
  journal={science},
  volume={324},
  number={5923},
  pages={81--85},
  year={2009},
  publisher={American Association for the Advancement of Science}
}
@article{schmidt2011automated,
  title={Automated refinement and inference of analytical models for metabolic networks},
  author={Schmidt, Michael D and Vallabhajosyula, Ravishankar R and Jenkins, Jerry W and Hood, Jonathan E and Soni, Abhishek S and Wikswo, John P and Lipson, Hod},
  journal={Physical biology},
  volume={8},
  number={5},
  pages={055011},
  year={2011},
  publisher={IOP Publishing}
}
% Gaussian Process
@article{raissi2018hidden,
  title={Hidden physics models: Machine learning of nonlinear partial differential equations},
  author={Raissi, Maziar and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={357},
  pages={125--141},
  year={2018},
  publisher={Elsevier}
}
@article{kocijan2005dynamic,
  title={Dynamic systems identification with Gaussian processes},
  author={Kocijan, Ju{\v{s}} and Girard, Agathe and Banko, Bla{\v{z}} and Murray-Smith, Roderick},
  journal={Mathematical and Computer Modelling of Dynamical Systems},
  volume={11},
  number={4},
  pages={411--424},
  year={2005},
  publisher={Taylor \& Francis}
}
@article{raissi2017machine,
  title={Machine learning of linear differential equations using Gaussian processes},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={348},
  pages={683--693},
  year={2017},
  publisher={Elsevier}
}
@article{raissi2017inferring,
  title={Inferring solutions of differential equations using noisy multi-fidelity data},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={335},
  pages={736--746},
  year={2017},
  publisher={Elsevier}
}
@article{raissi2018numerical,
  title={Numerical Gaussian processes for time-dependent and nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  journal={SIAM Journal on Scientific Computing},
  volume={40},
  number={1},
  pages={A172--A198},
  year={2018},
  publisher={SIAM}
}
% Sparse Regression
%  - ODEs
@article{brunton2016discovering,
  title={Discovering governing equations from data by sparse identification of nonlinear dynamical systems},
  author={Brunton, Steven L and Proctor, Joshua L and Kutz, J Nathan},
  journal={Proceedings of the national academy of sciences},
  volume={113},
  number={15},
  pages={3932--3937},
  year={2016},
  publisher={National Acad Sciences}
}
@article{loiseau2018constrained,
  title={Constrained sparse Galerkin regression},
  author={Loiseau, Jean-Christophe and Brunton, Steven L},
  journal={Journal of Fluid Mechanics},
  volume={838},
  pages={42--67},
  year={2018},
  publisher={Cambridge University Press}
}
@article{chang2019identification,
  title={Identification of physical processes via combined data-driven and data-assimilation methods},
  author={Chang, Haibin and Zhang, Dongxiao},
  journal={Journal of Computational Physics},
  volume={393},
  pages={337--350},
  year={2019},
  publisher={Elsevier}
}
@article{wu2019learning,
  title={Learning physics by data for the motion of a sphere falling in a non-Newtonian fluid},
  author={Wu, Zongmin and Zhang, Ran},
  journal={Communications in Nonlinear Science and Numerical Simulation},
  volume={67},
  pages={577--593},
  year={2019},
  publisher={Elsevier}
}


@article{Ying:2006,
	Author = {L. Ying AND E. J. Cand\`es},
	Journal = {Journal of Computational Physics},
	Pages = {184--215},
	Title = {The phase flow method},
	Volume = {220},
	Year = {2006}}

@article{Brunton2010chaos,
	Author = {S. L. Brunton and C. W. Rowley},
	Journal = {Chaos},
	Pages = {017503},
	Title = {Fast computation of {FTLE} fields for unsteady flows: a comparison of methods},
	Volume = {20},
	Year = {2010}}

@article{Luchtenburg2014jcp,
	Author = {D. M. Luchtenburg and S. L. Brunton and C. W. Rowley},
	Journal = {Journal of Computational Physics},
	Pages = {783--802},
	Title = {Long-time uncertainty propagation using generalized polynomial chaos and flow map composition},
	Volume = {274},
	Year = {2014}}

@article{Brunton2015amr,
	Author = {S. L. Brunton and B. R. Noack},
	Journal = {Applied Mechanics Reviews},
	Pages = {050801-1--050801-48},
	Title = {Closed-loop turbulence control: Progress and challenges},
	Volume = {67},
	Year = {2015}}

@article{Brunton2017natcomm,
	Author = {S. L. Brunton and B. W. Brunton and J. L. Proctor and E. Kaiser and J. N. Kutz},
	Journal = {Nature Communications},
	Number = {19},
	Pages = {1--9},
	Title = {Chaos as an intermittently forced linear system},
	Volume = {8},
	Year = {2017}}

@book{Brunton2019book,
	Author = {S. L. Brunton and J. N. Kutz},
	Publisher = {Cambridge University Press},
	Title = {Data-Driven Science and Engineering: Machine Learning, Dynamical Systems, and Control},
	Year = {2019}}

@article{Brunton2020arfm,
	Author = {Steven L. Brunton and Bernd R. Noack and Petros Koumoutsakos},
	Journal = {Annual Review of Fluid Mechanics},
	Pages = {477--508},
	Title = {Machine Learning for Fluid Mechanics},
	Volume = {52},
	Year = {2020}}


@article{mangan2017model,
  title={Model selection for dynamical systems via sparse regression and information criteria},
  author={Mangan, Niall M and Kutz, J Nathan and Brunton, Steven L and Proctor, Joshua L},
  journal={Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={473},
  number={2204},
  pages={20170009},
  year={2017},
  publisher={The Royal Society Publishing}
}
@article{schaeffer2017sparse,
  title={Sparse model selection via integral terms},
  author={Schaeffer, Hayden and McCalla, Scott G},
  journal={Physical Review E},
  volume={96},
  number={2},
  pages={023302},
  year={2017},
  publisher={APS}
}
@article{schaeffer2018extracting1,
  title={Extracting sparse high-dimensional dynamics from limited data},
  author={Schaeffer, Hayden and Tran, Giang and Ward, Rachel},
  journal={SIAM Journal on Applied Mathematics},
  volume={78},
  number={6},
  pages={3279--3295},
  year={2018},
  publisher={SIAM}
}
@article{schaeffer2018extracting2,
  title={Extracting structured dynamical systems using sparse optimization with very few samples},
  author={Schaeffer, Hayden and Tran, Giang and Ward, Rachel and Zhang, Linan},
  journal={arXiv preprint arXiv:1805.04158},
  year={2018}
}
@article{tran2017exact,
  title={Exact recovery of chaotic systems from highly corrupted data},
  author={Tran, Giang and Ward, Rachel},
  journal={Multiscale Modeling \& Simulation},
  volume={15},
  number={3},
  pages={1108--1129},
  year={2017},
  publisher={SIAM}
}
@article{wang2011predicting,
  title={Predicting catastrophes in nonlinear dynamical systems by compressive sensing},
  author={Wang, Wen-Xu and Yang, Rui and Lai, Ying-Cheng and Kovanis, Vassilios and Grebogi, Celso},
  journal={Physical review letters},
  volume={106},
  number={15},
  pages={154101},
  year={2011},
  publisher={APS}
}

% operator learning
@article{wang2021long,
  title={Long-time integration of parametric evolution equations with physics-informed DeepONets},
  author={Wang, Sifan and Perdikaris, Paris},
  journal={arXiv preprint arXiv:2106.05384},
  year={2021}
}

@article{lu2021learning,
  title={Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators},
  author={Lu, Lu and Jin, Pengzhan and Pang, Guofei and Zhang, Zhongqiang and Karniadakis, George Em},
  journal={Nature Machine Intelligence},
  volume={3},
  number={3},
  pages={218--229},
  year={2021},
  publisher={Nature Publishing Group}
}

%  - PDEs
@article{rudy2017data,
  title={Data-driven discovery of partial differential equations},
  author={Rudy, Samuel H and Brunton, Steven L and Proctor, Joshua L and Kutz, J Nathan},
  journal={Science Advances},
  volume={3},
  number={4},
  pages={e1602614},
  year={2017},
  publisher={American Association for the Advancement of Science}
}
@article{schaeffer2017learning,
  title={Learning partial differential equations via data discovery and sparse optimization},
  author={Schaeffer, Hayden},
  journal={Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={473},
  number={2197},
  pages={20160446},
  year={2017},
  publisher={The Royal Society Publishing}
}
%  - SDEs
@article{boninsegna2018sparse,
  title={Sparse learning of stochastic dynamical equations},
  author={Boninsegna, Lorenzo and N{\"u}ske, Feliks and Clementi, Cecilia},
  journal={The Journal of chemical physics},
  volume={148},
  number={24},
  pages={241723},
  year={2018},
  publisher={AIP Publishing LLC}
}
% others
@article{chen1990non,
  title={Non-linear systems identification using radial basis functions},
  author={Chen, S and Billings, SA and Cowan, CFN and Grant, PM},
  journal={International Journal of Systems Science},
  volume={21},
  number={12},
  pages={2513--2539},
  year={1990},
  publisher={Taylor \& Francis}
}
% Neural Networks
@article{gonzalez1998identification,
  title={Identification of distributed parameter systems: A neural net based approach},
  author={Gonzalez-Garcia, R and Rico-Martinez, R and Kevrekidis, IG},
  journal={Computers \& chemical engineering},
  volume={22},
  pages={S965--S968},
  year={1998},
  publisher={Elsevier}
}
@article{milano2002neural,
  title={Neural network modeling for near wall turbulent flow},
  author={Milano, Michele and Koumoutsakos, Petros},
  journal={Journal of Computational Physics},
  volume={182},
  number={1},
  pages={1--26},
  year={2002},
  publisher={Elsevier}
}
@article{raissi2018multistep,
  title={Multistep neural networks for data-driven discovery of nonlinear dynamical systems},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  journal={arXiv preprint arXiv:1801.01236},
  year={2018}
}
@article{rudy2019deep,
  title={Deep learning of dynamics and signal-noise decomposition with time-stepping constraints},
  author={Rudy, Samuel H and Kutz, J Nathan and Brunton, Steven L},
  journal={Journal of Computational Physics},
  volume={396},
  pages={483--506},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{kim2020robust,
  title={Robust Neural Networks inspired by Strong Stability Preserving Runge-Kutta methods},
  author={Kim, Byungjoo and Chudomelka, Bryce and Park, Jinyoung and Kang, Jaewoo and Hong, Youngjoon and Kim, Hyunwoo J},
  booktitle={European Conference on Computer Vision},
  pages={416--432},
  year={2020},
  organization={Springer}
}

@article{qin2019data,
  title={Data driven governing equations approximation using deep neural networks},
  author={Qin, Tong and Wu, Kailiang and Xiu, Dongbin},
  journal={Journal of Computational Physics},
  volume={395},
  pages={620--635},
  year={2019},
  publisher={Elsevier}
}

@article{bar2019learning,
  title={Learning data-driven discretizations for partial differential equations},
  author={Bar-Sinai, Yohai and Hoyer, Stephan and Hickey, Jason and Brenner, Michael P},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={31},
  pages={15344--15349},
  year={2019},
  publisher={National Acad Sciences}
}
@article{pan2018data,
  title={Data-driven discovery of closure models},
  author={Pan, Shaowu and Duraisamy, Karthik},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={17},
  number={4},
  pages={2381--2413},
  year={2018},
  publisher={SIAM}
}
@article{wan2018data,
  title={Data-assisted reduced-order modeling of extreme events in complex dynamical systems},
  author={Wan, Zhong Yi and Vlachas, Pantelis and Koumoutsakos, Petros and Sapsis, Themistoklis},
  journal={PloS one},
  volume={13},
  number={5},
  year={2018},
  publisher={Public Library of Science}
}
@article{liu2020multiresolution,
  title={Multiresolution Convolutional Autoencoders},
  author={Liu, Yuying and Ponce, Colin and Brunton, Steven L and Kutz, J Nathan},
  journal={arXiv preprint arXiv:2004.04946},
  year={2020}
}
@article{douglas1992mgnet,
  title={MGNet: a multigrid and domain decomposition network},
  author={Douglas, Craig C},
  journal={ACM SIGNUM Newsletter},
  volume={27},
  number={4},
  pages={2--8},
  year={1992},
  publisher={ACM New York, NY, USA}
}
@article{jacobsen2017multiscale,
  title={Multiscale hierarchical convolutional networks},
  author={Jacobsen, J{\"o}rn-Henrik and Oyallon, Edouard and Mallat, St{\'e}phane and Smeulders, Arnold WM},
  journal={arXiv preprint arXiv:1703.04140},
  year={2017}
}

@article{lusch2018deep,
  title={Deep learning for universal linear embeddings of nonlinear dynamics},
  author={Lusch, Bethany and Kutz, J Nathan and Brunton, Steven L},
  journal={Nature communications},
  volume={9},
  number={1},
  pages={1--10},
  year={2018},
  publisher={Nature Publishing Group}
}
@article{gin2021deep,
  title={Deep learning models for global coordinate transformations that linearise PDEs},
  author={Gin, Craig and Lusch, Bethany and Brunton, Steven L and Kutz, J Nathan},
  journal={European Journal of Applied Mathematics},
  volume={32},
  number={3},
  pages={515--539},
  year={2021},
  publisher={Cambridge University Press}
}

@article{li2017extended,
  title={Extended dynamic mode decomposition with dictionary learning: A data-driven adaptive spectral decomposition of the Koopman operator},
  author={Li, Qianxiao and Dietrich, Felix and Bollt, Erik M and Kevrekidis, Ioannis G},
  journal={Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume={27},
  number={10},
  pages={103111},
  year={2017},
  publisher={AIP Publishing LLC}
}

@article{terao2021extended,
  title={Extended dynamic mode decomposition with dictionary learning using neural ordinary differential equations},
  author={Terao, Hiroaki and Shirasaka, Sho and Suzuki, Hideyuki},
  journal={Nonlinear Theory and Its Applications, IEICE},
  volume={12},
  number={4},
  pages={626--638},
  year={2021},
  publisher={The Institute of Electronics, Information and Communication Engineers}
}

@inproceedings{yeung2019learning,
  title={Learning deep neural network representations for Koopman operators of nonlinear dynamical systems},
  author={Yeung, Enoch and Kundu, Soumya and Hodas, Nathan},
  booktitle={2019 American Control Conference (ACC)},
  pages={4832--4839},
  year={2019},
  organization={IEEE}
}

@inproceedings{han2020deep,
  title={Deep learning of koopman representation for control},
  author={Han, Yiqiang and Hao, Wenjian and Vaidya, Umesh},
  booktitle={2020 59th IEEE Conference on Decision and Control (CDC)},
  pages={1890--1895},
  year={2020},
  organization={IEEE}
}

@article{morton2019deep,
  title={Deep variational Koopman models: Inferring Koopman observations for uncertainty-aware dynamics modeling and control},
  author={Morton, Jeremy and Witherden, Freddie D and Kochenderfer, Mykel J},
  journal={arXiv preprint arXiv:1902.09742},
  year={2019}
}

@article{al2021deep,
  title={Deep learning for Koopman operator optimal control},
  author={Al-Gabalawy, Mostafa},
  journal={ISA transactions},
  year={2021},
  publisher={Elsevier}
}

@article{li2019learning,
  title={Learning compositional koopman operators for model-based control},
  author={Li, Yunzhu and He, Hao and Wu, Jiajun and Katabi, Dina and Torralba, Antonio},
  journal={arXiv preprint arXiv:1910.08264},
  year={2019}
}

@article{champion2019data,
  title={Data-driven discovery of coordinates and governing equations},
  author={Champion, Kathleen and Lusch, Bethany and Kutz, J Nathan and Brunton, Steven L},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={45},
  pages={22445--22451},
  year={2019},
  publisher={National Acad Sciences}
}
@article{pathak2017using,
  title={Using machine learning to replicate chaotic attractors and calculate Lyapunov exponents from data},
  author={Pathak, Jaideep and Lu, Zhixin and Hunt, Brian R and Girvan, Michelle and Ott, Edward},
  journal={Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume={27},
  number={12},
  pages={121102},
  year={2017},
  publisher={AIP Publishing LLC}
}
@article{lu2018attractor,
  title={Attractor reconstruction by machine learning},
  author={Lu, Zhixin and Hunt, Brian R and Ott, Edward},
  journal={Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume={28},
  number={6},
  pages={061104},
  year={2018},
  publisher={AIP Publishing LLC}
}
@article{pan2018long,
  title={Long-time predictive modeling of nonlinear dynamical systems using neural networks},
  author={Pan, Shaowu and Duraisamy, Karthik},
  journal={Complexity},
  volume={2018},
  year={2018},
  publisher={Hindawi}
}
@article{pathak2018hybrid,
  title={Hybrid forecasting of chaotic processes: Using machine learning in conjunction with a knowledge-based model},
  author={Pathak, Jaideep and Wikner, Alexander and Fussell, Rebeckah and Chandra, Sarthak and Hunt, Brian R and Girvan, Michelle and Ott, Edward},
  journal={Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume={28},
  number={4},
  pages={041101},
  year={2018},
  publisher={AIP Publishing LLC}
}
@article{vlachas2018data,
  title={Data-driven forecasting of high-dimensional chaotic systems with long short-term memory networks},
  author={Vlachas, Pantelis R and Byeon, Wonmin and Wan, Zhong Y and Sapsis, Themistoklis P and Koumoutsakos, Petros},
  journal={Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={474},
  number={2213},
  pages={20170844},
  year={2018},
  publisher={The Royal Society Publishing}
 }
@inproceedings{wiewel2019latent,
  title={Latent space physics: Towards learning the temporal evolution of fluid flow},
  author={Wiewel, Steffen and Becher, Moritz and Thuerey, Nils},
  booktitle={Computer Graphics Forum},
  volume={38},
  pages={71--82},
  year={2019},
  organization={Wiley Online Library}
}

@article{raissi2018deep,
  title={Deep hidden physics models: Deep learning of nonlinear partial differential equations},
  author={Raissi, Maziar},
  journal={The Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={932--955},
  year={2018},
  publisher={JMLR. org}
}
@article{long2017pde,
  title={PDE-net: Learning PDEs from data},
  author={Long, Zichao and Lu, Yiping and Ma, Xianzhong and Dong, Bin},
  journal={arXiv preprint arXiv:1710.09668},
  year={2017}
}
@article{long2019pde,
  title={PDE-Net 2.0: Learning PDEs from data with a numeric-symbolic hybrid deep network},
  author={Long, Zichao and Lu, Yiping and Dong, Bin},
  journal={Journal of Computational Physics},
  volume={399},
  pages={108925},
  year={2019},
  publisher={Elsevier}
}
@inproceedings{kim2019deep,
  title={Deep fluids: A generative network for parameterized fluid simulations},
  author={Kim, Byungsoo and Azevedo, Vinicius C and Thuerey, Nils and Kim, Theodore and Gross, Markus and Solenthaler, Barbara},
  booktitle={Computer Graphics Forum},
  volume={38},
  pages={59--70},
  year={2019},
  organization={Wiley Online Library}
}

%% PINNs
@article{raissi2017physics,
  title={Physics informed deep learning (part i): Data-driven solutions of nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  journal={arXiv preprint arXiv:1711.10561},
  year={2017}
}

@article{raissi2019physics,
  title={Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George E},
  journal={Journal of Computational Physics},
  volume={378},
  pages={686--707},
  year={2019},
  publisher={Elsevier}
}
@article{pang2019fpinns,
  title={fPINNs: Fractional physics-informed neural networks},
  author={Pang, Guofei and Lu, Lu and Karniadakis, George Em},
  journal={SIAM Journal on Scientific Computing},
  volume={41},
  number={4},
  pages={A2603--A2626},
  year={2019},
  publisher={SIAM}
}
@article{fang2019physics,
  title={A physics-informed neural network framework for PDEs on 3D surfaces: Time independent problems},
  author={Fang, Zhiwei and Zhan, Justin},
  journal={IEEE Access},
  volume={8},
  pages={26328--26335},
  year={2019},
  publisher={IEEE}
}
@article{zhang2020learning,
  title={Learning in modal space: Solving time-dependent stochastic PDEs using physics-informed neural networks},
  author={Zhang, Dongkun and Guo, Ling and Karniadakis, George Em},
  journal={SIAM Journal on Scientific Computing},
  volume={42},
  number={2},
  pages={A639--A665},
  year={2020},
  publisher={SIAM}
}
@article{kharazmi2021hp,
  title={hp-VPINNs: Variational physics-informed neural networks with domain decomposition},
  author={Kharazmi, Ehsan and Zhang, Zhongqiang and Karniadakis, George Em},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={374},
  pages={113547},
  year={2021},
  publisher={Elsevier}
}
@article{jagtap2020conservative,
  title={Conservative physics-informed neural networks on discrete domains for conservation laws: Applications to forward and inverse problems},
  author={Jagtap, Ameya D and Kharazmi, Ehsan and Karniadakis, George Em},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={365},
  pages={113028},
  year={2020},
  publisher={Elsevier}
}
@article{jagtap2020extended,
  title={Extended physics-informed neural networks (xpinns): A generalized space-time domain decomposition based deep learning framework for nonlinear partial differential equations},
  author={Jagtap, Ameya D and Karniadakis, George Em},
  journal={Communications in Computational Physics},
  volume={28},
  number={5},
  pages={2002--2041},
  year={2020}
}
@article{shukla2021parallel,
  title={Parallel physics-informed neural networks via domain decomposition},
  author={Shukla, Khemraj and Jagtap, Ameya D and Karniadakis, George Em},
  journal={arXiv preprint arXiv:2104.10013},
  year={2021}
}
@inproceedings{hennigh2021nvidia,
  title={NVIDIA SimNet™: An AI-Accelerated Multi-Physics Simulation Framework},
  author={Hennigh, Oliver and Narasimhan, Susheela and Nabian, Mohammad Amin and Subramaniam, Akshay and Tangsali, Kaustubh and Fang, Zhiwei and Rietmann, Max and Byeon, Wonmin and Choudhry, Sanjay},
  booktitle={International Conference on Computational Science},
  pages={447--461},
  year={2021},
  organization={Springer}
}
@article{yang2019adversarial,
  title={Adversarial uncertainty quantification in physics-informed neural networks},
  author={Yang, Yibo and Perdikaris, Paris},
  journal={Journal of Computational Physics},
  volume={394},
  pages={136--152},
  year={2019},
  publisher={Elsevier}
}
@article{zhang2019quantifying,
  title={Quantifying total uncertainty in physics-informed neural networks for solving forward and inverse stochastic problems},
  author={Zhang, Dongkun and Lu, Lu and Guo, Ling and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={397},
  pages={108850},
  year={2019},
  publisher={Elsevier}
}
@article{zhu2019physics,
  title={Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data},
  author={Zhu, Yinhao and Zabaras, Nicholas and Koutsourelakis, Phaedon-Stelios and Perdikaris, Paris},
  journal={Journal of Computational Physics},
  volume={394},
  pages={56--81},
  year={2019},
  publisher={Elsevier}
}
@article{sun2020physics,
  title={Physics-constrained bayesian neural network for fluid flow reconstruction with sparse and noisy data},
  author={Sun, Luning and Wang, Jian-Xun},
  journal={Theoretical and Applied Mechanics Letters},
  volume={10},
  number={3},
  pages={161--169},
  year={2020},
  publisher={Elsevier}
}
@article{yang2021b,
  title={B-PINNs: Bayesian physics-informed neural networks for forward and inverse PDE problems with noisy data},
  author={Yang, Liu and Meng, Xuhui and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={425},
  pages={109913},
  year={2021},
  publisher={Elsevier}
}
@article{meng2020composite,
  title={A composite neural network that learns from multi-fidelity data: Application to function approximation and inverse PDE problems},
  author={Meng, Xuhui and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={401},
  pages={109020},
  year={2020},
  publisher={Elsevier}
}
@article{jagtap2020adaptive,
  title={Adaptive activation functions accelerate convergence in deep and physics-informed neural networks},
  author={Jagtap, Ameya D and Kawaguchi, Kenji and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={404},
  pages={109136},
  year={2020},
  publisher={Elsevier}
}
@article{wang2021understanding,
  title={Understanding and mitigating gradient flow pathologies in physics-informed neural networks},
  author={Wang, Sifan and Teng, Yujun and Perdikaris, Paris},
  journal={SIAM Journal on Scientific Computing},
  volume={43},
  number={5},
  pages={A3055--A3081},
  year={2021},
  publisher={SIAM}
}

@article{maddu2021inverse,
  title={Inverse Dirichlet Weighting Enables Reliable Training of Physics Informed Neural Networks},
  author={Maddu, Suryanarayana and Sturm, Dominik and M{\"u}ller, Christian L and Sbalzarini, Ivo F},
  journal={Machine Learning: Science and Technology},
  year={2021},
  publisher={IOP Publishing}
}

@article{zubov2021neuralpde,
  title={NeuralPDE: Automating physics-informed neural networks (PINNs) with error approximations},
  author={Zubov, Kirill and McCarthy, Zoe and Ma, Yingbo and Calisto, Francesco and Pagliarino, Valerio and Azeglio, Simone and Bottero, Luca and Luj{\'a}n, Emmanuel and Sulzer, Valentin and Bharambe, Ashutosh and others},
  journal={arXiv preprint arXiv:2107.09443},
  year={2021}
}

@article{lu2021physics,
  title={Physics-informed neural networks with hard constraints for inverse design},
  author={Lu, Lu and Pestourie, Raphael and Yao, Wenjie and Wang, Zhicheng and Verdugo, Francesc and Johnson, Steven G},
  journal={arXiv preprint arXiv:2102.04626},
  year={2021}
}
@article{gao2021phygeonet,
  title={PhyGeoNet: physics-informed geometry-adaptive convolutional neural networks for solving parameterized steady-state PDEs on irregular domain},
  author={Gao, Han and Sun, Luning and Wang, Jian-Xun},
  journal={Journal of Computational Physics},
  volume={428},
  pages={110079},
  year={2021},
  publisher={Elsevier}
}
@article{shin2020convergence,
  title={On the convergence of physics informed neural networks for linear second-order elliptic and parabolic type PDEs},
  author={Shin, Yeonjong and Darbon, Jerome and Karniadakis, George Em},
  journal={arXiv preprint arXiv:2004.01806},
  year={2020}
}
@article{mishra2020estimates,
  title={Estimates on the generalization error of physics informed neural networks (PINNs) for approximating PDEs},
  author={Mishra, Siddhartha and Molinaro, Roberto},
  journal={arXiv preprint arXiv:2006.16144},
  year={2020}
}
@article{wang2022and,
  title={When and why PINNs fail to train: A neural tangent kernel perspective},
  author={Wang, Sifan and Yu, Xinling and Perdikaris, Paris},
  journal={Journal of Computational Physics},
  volume={449},
  pages={110768},
  year={2022},
  publisher={Elsevier}
}
@article{wang2021learning,
  title={Learning the solution operator of parametric partial differential equations with physics-informed DeepOnets},
  author={Wang, Sifan and Wang, Hanwen and Perdikaris, Paris},
  journal={arXiv preprint arXiv:2103.10974},
  year={2021}
}


%% Deep Learning
% General
@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}
@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}
@article{baldi1989neural,
  title={Neural networks and principal component analysis: Learning from examples without local minima},
  author={Baldi, Pierre and Hornik, Kurt},
  journal={Neural networks},
  volume={2},
  number={1},
  pages={53--58},
  year={1989},
  publisher={Elsevier}
}


@article{taira:07ibfs,
	Author = {K. Taira and T. Colonius},
	Journal = {Journal of Computational Physics},
	Number = 2,
	Pages = {2118-2137},
	Title = {The immersed boundary method: a projection approach.},
	Volume = 225,
	Year = 2007}

@article{taira:fastIBPM,
	Author = {T. Colonius and K. Taira},
	Journal = {Computer Methods in Applied Mechanics and Engineering},
	Pages = {2131-2146},
	Title = {A fast immersed boundary method using a nullspace approach and multi-domain far-field boundary conditions},
	Volume = {197},
	Year = {2008}}


@article{hornik1989multilayer,
	Author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	Journal = {Neural networks},
	Number = {5},
	Pages = {359--366},
	Title = {Multilayer feedforward networks are universal approximators},
	Volume = {2},
	Year = {1989}}

% transfer learning
@article{chen2015net2net,
  title={Net2net: Accelerating learning via knowledge transfer},
  author={Chen, Tianqi and Goodfellow, Ian and Shlens, Jonathon},
  journal={arXiv preprint arXiv:1511.05641},
  year={2015}
}
% Image Processing
@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}
@article{farabet2012learning,
  title={Learning hierarchical features for scene labeling},
  author={Farabet, Clement and Couprie, Camille and Najman, Laurent and LeCun, Yann},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={8},
  pages={1915--1929},
  year={2012},
  publisher={IEEE}
}
@inproceedings{tompson2014joint,
  title={Joint training of a convolutional network and a graphical model for human pose estimation},
  author={Tompson, Jonathan J and Jain, Arjun and LeCun, Yann and Bregler, Christoph},
  booktitle={Advances in neural information processing systems},
  pages={1799--1807},
  year={2014}
}
@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}
% Speech Recognition
@inproceedings{mikolov2011strategies,
  title={Strategies for training large scale neural network language models},
  author={Mikolov, Tom{\'a}{\v{s}} and Deoras, Anoop and Povey, Daniel and Burget, Luk{\'a}{\v{s}} and {\v{C}}ernock{\`y}, Jan},
  booktitle={2011 IEEE Workshop on Automatic Speech Recognition \& Understanding},
  pages={196--201},
  year={2011},
  organization={IEEE}
}
@article{senior2012deep,
  title={Deep neural networks for acoustic modeling in speech recognition},
  author={Senior, A and Vanhoucke, V and Nguyen, P and Sainath, T and others},
  journal={IEEE Signal processing magazine},
  year={2012}
}
@inproceedings{sainath2013deep,
  title={Deep convolutional neural networks for LVCSR},
  author={Sainath, Tara N and Mohamed, Abdel-rahman and Kingsbury, Brian and Ramabhadran, Bhuvana},
  booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
  pages={8614--8618},
  year={2013},
  organization={IEEE}
}
% Natural Language Processing
@article{collobert2011natural,
  title={Natural language processing (almost) from scratch},
  author={Collobert, Ronan and Weston, Jason and Bottou, L{\'e}on and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
  journal={Journal of machine learning research},
  volume={12},
  number={Aug},
  pages={2493--2537},
  year={2011}
}
@article{bordes2014question,
  title={Question answering with subgraph embeddings},
  author={Bordes, Antoine and Chopra, Sumit and Weston, Jason},
  journal={arXiv preprint arXiv:1406.3676},
  year={2014}
}
@article{jean2014using,
  title={On using very large target vocabulary for neural machine translation},
  author={Jean, S{\'e}bastien and Cho, Kyunghyun and Memisevic, Roland and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.2007},
  year={2014}
}
@inproceedings{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  booktitle={Advances in neural information processing systems},
  pages={3104--3112},
  year={2014}
}
% Science
@article{wehmeyer2018time,
  title={Time-lagged autoencoders: Deep learning of slow collective variables for molecular kinetics},
  author={Wehmeyer, Christoph and No{\'e}, Frank},
  journal={The Journal of chemical physics},
  volume={148},
  number={24},
  pages={241703},
  year={2018},
  publisher={AIP Publishing LLC}
}
@article{mardt2018vampnets,
  title={VAMPnets for deep learning of molecular kinetics},
  author={Mardt, Andreas and Pasquali, Luca and Wu, Hao and No{\'e}, Frank},
  journal={Nature communications},
  volume={9},
  number={1},
  pages={1--11},
  year={2018},
  publisher={Nature Publishing Group}
}
@article{ma2015deep,
  title={Deep neural nets as a method for quantitative structure--activity relationships},
  author={Ma, Junshui and Sheridan, Robert P and Liaw, Andy and Dahl, George E and Svetnik, Vladimir},
  journal={Journal of chemical information and modeling},
  volume={55},
  number={2},
  pages={263--274},
  year={2015},
  publisher={ACS Publications}
}
@inproceedings{ciodaro2012online,
  title={Online particle detection with neural networks based on topological calorimetry information},
  author={Ciodaro, T and Deva, D and De Seixas, JM and Damazio, D},
  booktitle={Journal of physics: conference series},
  volume={368},
  number={1},
  pages={012030},
  year={2012},
  organization={IOP Publishing}
}
@article{helmstaedter2013connectomic,
  title={Connectomic reconstruction of the inner plexiform layer in the mouse retina},
  author={Helmstaedter, Moritz and Briggman, Kevin L and Turaga, Srinivas C and Jain, Viren and Seung, H Sebastian and Denk, Winfried},
  journal={Nature},
  volume={500},
  number={7461},
  pages={168--174},
  year={2013},
  publisher={Nature Publishing Group}
}
@article{leung2014deep,
  title={Deep learning of the tissue-regulated splicing code},
  author={Leung, Michael KK and Xiong, Hui Yuan and Lee, Leo J and Frey, Brendan J},
  journal={Bioinformatics},
  volume={30},
  number={12},
  pages={i121--i129},
  year={2014},
  publisher={Oxford University Press}
}
@article{xiong2015human,
  title={The human splicing code reveals new insights into the genetic determinants of disease},
  author={Xiong, Hui Y and Alipanahi, Babak and Lee, Leo J and Bretschneider, Hannes and Merico, Daniele and Yuen, Ryan KC and Hua, Yimin and Gueroussov, Serge and Najafabadi, Hamed S and Hughes, Timothy R and others},
  journal={Science},
  volume={347},
  number={6218},
  pages={1254806},
  year={2015},
  publisher={American Association for the Advancement of Science}
}
% Back Propagation 
@book{werbos1994roots,
  title={The roots of backpropagation: from ordered derivatives to neural networks and political forecasting},
  author={Werbos, Paul John},
  volume={1},
  year={1994},
  publisher={John Wiley \& Sons}
}
@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group}
}
@inproceedings{7fa6b6a5cde14bcfbd7ab3a8f19d0d56,
title = "Une procedure d'apprentissage pour reseau a seuil asymmetrique (A learning scheme for asymmetric threshold networks)",
author = "Yann Lecun",
year = "1985",
language = "English (US)",
pages = "599--604",
booktitle = "Proceedings of Cognitiva 85, Paris, France",
}
% optimization
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}
@article{zhu1997algorithm,
  title={Algorithm 778: L-BFGS-B: Fortran subroutines for large-scale bound-constrained optimization},
  author={Zhu, Ciyou and Byrd, Richard H and Lu, Peihuang and Nocedal, Jorge},
  journal={ACM Transactions on Mathematical Software (TOMS)},
  volume={23},
  number={4},
  pages={550--560},
  year={1997},
  publisher={ACM New York, NY, USA}
}
@misc{Tieleman2012,
  title={{Lecture 6.5---RmsProp: Divide the gradient by a running average of its recent magnitude}},
  author={Tieleman, T. and Hinton, G.},
  howpublished={COURSERA: Neural Networks for Machine Learning},
  year={2012}
}
@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}
% RNN
@misc{Hochreiter:91,
  added-at = {2008-03-11T14:52:34.000+0100},
  author = {Hochreiter, S.},
  biburl = {https://www.bibsonomy.org/bibtex/21e476a44125e2b2b588d2fafbb5f69b0/idsia},
  citeulike-article-id = {2381309},
  comment = {See www7.informatik.tu-muenchen.de/\~{}hochreit; advisor: J. Schmidhuber},
  interhash = {c89e6c3623f880f8f4fbe62fd0d320ac},
  intrahash = {1e476a44125e2b2b588d2fafbb5f69b0},
  keywords = {juergen},
  priority = {2},
  timestamp = {2008-03-11T14:54:33.000+0100},
  title = {{Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, Institut f\"{u}r Informatik, Lehrstuhl Prof. Brauer, Technische Universit\"{a}t M\"{u}nchen}},
  year = 1991
}
@article{bengio1994learning,
  title={Learning long-term dependencies with gradient descent is difficult},
  author={Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
  journal={IEEE transactions on neural networks},
  volume={5},
  number={2},
  pages={157--166},
  year={1994},
  publisher={IEEE}
}
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}
@book{jaeger2002tutorial,
  title={Tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the" echo state network" approach},
  author={Jaeger, Herbert},
  volume={5},
  year={2002},
  publisher={GMD-Forschungszentrum Informationstechnik Bonn}
}
@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013}
}
% ResNet
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
% CNN
@article{peng2018red,
  title={Red-net: A recurrent encoder--decoder network for video-based face alignment},
  author={Peng, Xi and Feris, Rogerio S and Wang, Xiaoyu and Metaxas, Dimitris N},
  journal={International Journal of Computer Vision},
  volume={126},
  number={10},
  pages={1103--1119},
  year={2018},
  publisher={Springer}
}
@article{mallat2016understanding,
  title={Understanding deep convolutional networks},
  author={Mallat, St{\'e}phane},
  journal={Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={374},
  number={2065},
  pages={20150203},
  year={2016},
  publisher={The Royal Society Publishing}
}
@incollection{lecun1999object,
  title={Object recognition with gradient-based learning},
  author={LeCun, Yann and Haffner, Patrick and Bottou, L{\'e}on and Bengio, Yoshua},
  booktitle={Shape, contour and grouping in computer vision},
  pages={319--345},
  year={1999},
  publisher={Springer}
}
@article{hubel1962receptive,
  title={Receptive fields, binocular interaction and functional architecture in the cat's visual cortex},
  author={Hubel, David H and Wiesel, Torsten N},
  journal={The Journal of physiology},
  volume={160},
  number={1},
  pages={106--154},
  year={1962},
  publisher={Wiley Online Library}
}
% Approximation theory
@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}
@article{ma2018priori,
  title={A Priori Estimates for Two-layer Neural Networks},
  author={Ma, Chao and Wu, Lei and others},
  journal={arXiv preprint arXiv:1810.06397},
  year={2018}
}
@article{ma2019priori,
  title={A priori estimates of the population risk for residual networks},
  author={Ma, Chao and Wang, Qingcan and others},
  journal={arXiv preprint arXiv:1903.02154},
  year={2019}
}
@article{ma2019barron,
  title={Barron spaces and the compositional function spaces for neural network models},
  author={Ma, Chao and Wu, Lei and others},
  journal={arXiv preprint arXiv:1906.08039},
  year={2019}
}
@article{poggio2019theoretical,
  title={Theoretical Issues in Deep Networks: Approximation, Optimization and Generalization},
  author={Poggio, Tomaso and Banburski, Andrzej and Liao, Qianli},
  journal={arXiv preprint arXiv:1908.09375},
  year={2019}
}
% Connection to Dynamical Systems
@article{weinan2017proposal,
  title={A proposal on machine learning via dynamical systems},
  author={Weinan, E},
  journal={Communications in Mathematics and Statistics},
  volume={5},
  number={1},
  pages={1--11},
  year={2017},
  publisher={Springer}
}
@article{weinan2019mean,
  title={A mean-field optimal control formulation of deep learning},
  author={Weinan, E and Han, Jiequn and Li, Qianxiao},
  journal={Research in the Mathematical Sciences},
  volume={6},
  number={1},
  pages={10},
  year={2019},
  publisher={Springer}
}
@article{ma2019machine,
  title={Machine Learning from a Continuous Viewpoint},
  author={Ma, Chao and Wu, Lei and others},
  journal={arXiv preprint arXiv:1912.12777},
  year={2019}
}
@article{li2015dynamics,
  title={Dynamics of stochastic gradient algorithms},
  author={Li, Qianxiao and Tai, Cheng and Weinan, E},
  journal={arXiv preprint arXiv:1511.06251},
  year={2015}
}
@inproceedings{li2017stochastic,
  title={Stochastic modified equations and adaptive stochastic gradient algorithms},
  author={Li, Qianxiao and Tai, Cheng and others},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2101--2110},
  year={2017},
  organization={JMLR. org}
}
@article{li2019stochastic,
  title={Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms I: Mathematical Foundations.},
  author={Li, Qianxiao and Tai, Cheng and Weinan, E},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={40},
  pages={1--40},
  year={2019}
}
@article{haber2017stable,
  title={Stable architectures for deep neural networks},
  author={Haber, Eldad and Ruthotto, Lars},
  journal={Inverse Problems},
  volume={34},
  number={1},
  pages={014004},
  year={2017},
  publisher={IOP Publishing}
}
@article{chang2017multi,
  title={Multi-level residual networks from dynamical systems view},
  author={Chang, Bo and Meng, Lili and Haber, Eldad and Tung, Frederick and Begert, David},
  journal={arXiv preprint arXiv:1710.10348},
  year={2017}
}
@inproceedings{chen2018neuralode,
  title={Neural ordinary differential equations},
  author={Chen, Tian Qi and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  booktitle={Advances in neural information processing systems},
  pages={6571--6583},
  year={2018}
}

@article{sitzmann2020implicit,
  title={Implicit Neural Representations with Periodic Activation Functions},
  author={Sitzmann, Vincent and Martel, Julien NP and Bergman, Alexander W and Lindell, David B and Wetzstein, Gordon},
  journal={arXiv preprint arXiv:2006.09661},
  year={2020}
}

@inproceedings{poole2016exponential,
  title={Exponential expressivity in deep neural networks through transient chaos},
  author={Poole, Ben and Lahiri, Subhaneil and Raghu, Maithra and Sohl-Dickstein, Jascha and Ganguli, Surya},
  booktitle={Advances in neural information processing systems},
  pages={3360--3368},
  year={2016}
}
@article{banburski2019theory,
  title={Theory III: Dynamics and generalization in deep networks},
  author={Banburski, Andrzej and Liao, Qianli and Miranda, Brando and Rosasco, Lorenzo and Liang, Bob and Hidary, Jack and Poggio, Tomaso},
  journal={arXiv preprint arXiv:1903.04991},
  year={2019}
}
@article{muehlebach2020optimization,
  title={Optimization with Momentum: Dynamical, Control-Theoretic, and Symplectic Perspectives},
  author={Muehlebach, Michael and Jordan, Michael I},
  journal={arXiv preprint arXiv:2002.12493},
  year={2020}
}
@article{muehlebach2019dynamical,
  title={A dynamical systems perspective on Nesterov acceleration},
  author={Muehlebach, Michael and Jordan, Michael I},
  journal={arXiv preprint arXiv:1905.07436},
  year={2019}
}

%% Multiscale Modeling
% review
@article{weinan2003multiscale,
  title={Multiscale modeling and computation},
  author={Weinan, E and Engquist, Bjorn},
  journal={Notices of the AMS},
  volume={50},
  number={9},
  pages={1062--1070},
  year={2003}
}
@ARTICLE{E:2011,
AUTHOR = {E, W.  and Lu, J. },
TITLE   = {{M}ultiscale modeling},
YEAR    = {2011},
JOURNAL = {Scholarpedia},
VOLUME  = {6},
NUMBER  = {10},
PAGES   = {11527},
DOI     = {10.4249/scholarpedia.11527},
NOTE    = {revision \#91540}
}
% multi-grid method
@article{brandt1977multi,
  title={Multi-level adaptive solutions to boundary-value problems},
  author={Brandt, Achi},
  journal={Mathematics of computation},
  volume={31},
  number={138},
  pages={333--390},
  year={1977}
}
% fast multipole method
@article{greengard1997fast,
  title={A fast algorithm for particle simulations},
  author={Greengard, Leslie and Rokhlin, Vladimir},
  journal={Journal of Computational Physics},
  volume={135},
  number={2},
  pages={280--292},
  year={1997},
  publisher={Academic Press}
}
% adaptive mesh refinement
@article{berger1989local,
  title={Local adaptive mesh refinement for shock hydrodynamics},
  author={Berger, Marsha J and Colella, Phillip and others},
  journal={Journal of computational Physics},
  volume={82},
  number={1},
  pages={64--84},
  year={1989}
}
% domain decomposition
@book{toselli2006domain,
  title={Domain decomposition methods-algorithms and theory},
  author={Toselli, Andrea and Widlund, Olof},
  volume={34},
  year={2006},
  publisher={Springer Science \& Business Media}
}


@article{kutz2016multiresolution,
  title={Multiresolution dynamic mode decomposition},
  author={Kutz, J Nathan and Fu, Xing and Brunton, Steven L},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={15},
  number={2},
  pages={713--735},
  year={2016},
  publisher={SIAM}
}

% multi-resolution representation
@book{kutz2013data,
  title={Data-driven modeling \& scientific computation: methods for complex systems \& big data},
  author={Kutz, J Nathan},
  year={2013},
  publisher={Oxford University Press}
}
@book{daubechies1992ten,
  title={Ten lectures on wavelets},
  author={Daubechies, Ingrid},
  volume={61},
  year={1992},
  publisher={Siam}
}
% HMM
@book{weinan2011principles,
  title={Principles of multiscale modeling},
  author={Weinan, E},
  year={2011},
  publisher={Cambridge University Press}
}
@article{weinan2007heterogeneous,
  title={Heterogeneous multiscale methods: a review},
  author={Weinan, E and Engquist, Bjorn and Li, Xiantao and Ren, Weiqing and Vanden-Eijnden, Eric},
  journal={Communications in computational physics},
  volume={2},
  number={3},
  pages={367--450},
  year={2007},
  publisher={Global Science Press}
}
% equation-free modeling
@article{kevrekidis2003equation,
  title={Equation-free, coarse-grained multiscale computation: Enabling mocroscopic simulators to perform system-level analysis},
  author={Kevrekidis, Ioannis G and Gear, C William and Hyman, James M and Kevrekidid, Panagiotis G and Runborg, Olof and Theodoropoulos, Constantinos and others},
  journal={Communications in Mathematical Sciences},
  volume={1},
  number={4},
  pages={715--762},
  year={2003},
  publisher={International Press of Boston}
}
% applications
@article{car1985unified,
  title={Unified approach for molecular dynamics and density-functional theory},
  author={Car, Richard and Parrinello, Mark},
  journal={Physical review letters},
  volume={55},
  number={22},
  pages={2471},
  year={1985},
  publisher={APS}
}
@article{warshel1976theoretical,
  title={Theoretical studies of enzymic reactions: dielectric, electrostatic and steric stabilization of the carbonium ion in the reaction of lysozyme},
  author={Warshel, Arieh and Levitt, Michael},
  journal={Journal of molecular biology},
  volume={103},
  number={2},
  pages={227--249},
  year={1976},
  publisher={Elsevier}
}
@book{ottinger2012stochastic,
  title={Stochastic processes in polymeric fluids: tools and examples for developing simulation algorithms},
  author={{\"O}ttinger, Hans C},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@article{tadmor1996quasicontinuum,
  title={Quasicontinuum analysis of defects in solids},
  author={Tadmor, Ellad B and Ortiz, Michael and Phillips, Rob},
  journal={Philosophical magazine A},
  volume={73},
  number={6},
  pages={1529--1563},
  year={1996},
  publisher={Taylor \& Francis}
}
@article{bird1987dynamics,
  title={Dynamics of polymeric liquids. Vol. 1: Fluid mechanics},
  author={Bird, Robert Byron and Armstrong, Robert C and Hassager, Ole},
  year={1987}
}






% Appendix

% old ones
@article{poggio2017and,
  title={Why and when can deep-but not shallow-networks avoid the curse of dimensionality: a review},
  author={Poggio, Tomaso and Mhaskar, Hrushikesh and Rosasco, Lorenzo and Miranda, Brando and Liao, Qianli},
  journal={International Journal of Automation and Computing},
  volume={14},
  number={5},
  pages={503--519},
  year={2017},
  publisher={Springer}
}

% reservoir computing
@article{lukovsevivcius2009reservoir,
  title={Reservoir computing approaches to recurrent neural network training},
  author={Luko{\v{s}}evi{\v{c}}ius, Mantas and Jaeger, Herbert},
  journal={Computer Science Review},
  volume={3},
  number={3},
  pages={127--149},
  year={2009},
  publisher={Elsevier}
}

@article{pathak2018model,
  title={Model-free prediction of large spatiotemporally chaotic systems from data: A reservoir computing approach},
  author={Pathak, Jaideep and Hunt, Brian and Girvan, Michelle and Lu, Zhixin and Ott, Edward},
  journal={Physical review letters},
  volume={120},
  number={2},
  pages={024102},
  year={2018},
  publisher={APS}
}

% reinforcement learning
@article{dellnitz2021efficient,
  title={Efficient time stepping for numerical integration using reinforcement learning},
  author={Dellnitz, Michael and H{\"u}llermeier, Eyke and L{\"u}cke, Marvin and Ober-Bl{\"o}baum, Sina and Offen, Christian and Peitz, Sebastian and Pfannschmidt, Karlson},
  journal={arXiv preprint arXiv:2104.03562},
  year={2021}
}

@article{cole1951quasi,
  title={On a quasi-linear parabolic equation occurring in aerodynamics},
  author={Cole, Julian D},
  journal={Quarterly of applied mathematics},
  volume={9},
  number={3},
  pages={225--236},
  year={1951}
}

@techreport{hopf1950partial,
  title={THE PARTIAL DIFFERENTIAL EQUATION U SUB T+ UU SUB X= MU SUB XX},
  author={Hopf, Eberhard},
  year={1950},
  institution={INDIANA UNIV AT BLOOMINGTON}
}

@article{nathan2018applied,
  title={Applied Koopman theory for partial differential equations and data-driven modeling of spatio-temporal systems},
  author={Nathan Kutz, J and Proctor, Joshua L and Brunton, Steven L},
  journal={Complexity},
  volume={2018},
  year={2018},
  publisher={Hindawi}
}

@article{page2018koopman,
  title={Koopman analysis of Burgers equation},
  author={Page, Jacob and Kerswell, Rich R},
  journal={Physical Review Fluids},
  volume={3},
  number={7},
  pages={071901},
  year={2018},
  publisher={APS}
}

@article{balabane2021koopman,
  title={Koopman operator for Burgers's equation},
  author={Balabane, Mikhael and Mendez, Miguel Alfonso and Najem, Sara},
  journal={Physical Review Fluids},
  volume={6},
  number={6},
  pages={064401},
  year={2021},
  publisher={APS}
}

@article{page2019koopman,
  title={Koopman mode expansions between simple invariant solutions},
  author={Page, Jacob and Kerswell, Rich R},
  journal={Journal of Fluid Mechanics},
  volume={879},
  pages={1--27},
  year={2019},
  publisher={Cambridge University Press}
}

@book{evans2010partial,
  title={Partial differential equations},
  author={Evans, Lawrence C},
  volume={19},
  year={2010},
  publisher={American Mathematical Soc.}
}

@article{peherstorfer2022breaking,
  title={Breaking the Kolmogorov Barrier with Nonlinear Model Reduction},
  author={Peherstorfer, Benjamin},
  journal={Notices of the American Mathematical Society},
  volume={69},
  number={5},
  year={2022}
}

%%% extra
@book{lorenz1956empirical,
  title={Empirical orthogonal functions and statistical weather prediction},
  author={Lorenz, Edward N},
  volume={1},
  year={1956},
  publisher={Massachusetts Institute of Technology, Department of Meteorology Cambridge}
}

@article{clark2020nonlinear,
  title={Nonlinear population dynamics are ubiquitous in animals},
  author={Clark, TJ and Luis, Angela D},
  journal={Nature ecology \& evolution},
  volume={4},
  number={1},
  pages={75--81},
  year={2020},
  publisher={Nature Publishing Group}
}

@inproceedings{kalur2021robust,
  title={Robust Adaptive Dynamic Mode Decomposition for Reduce Order Modelling of Partial Differential Equations},
  author={Kalur, Aniketh and Nabi, Saleh and Benosman, Mouhacine},
  booktitle={2021 American Control Conference (ACC)},
  pages={4497--4502},
  year={2021},
  organization={IEEE}
}

@article{kramer2017sparse,
  title={Sparse sensing and DMD-based identification of flow regimes and bifurcations in complex flows},
  author={Kramer, Boris and Grover, Piyush and Boufounos, Petros and Nabi, Saleh and Benosman, Mouhacine},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={16},
  number={2},
  pages={1164--1196},
  year={2017},
  publisher={SIAM}
}

@article{mezic2020koopman,
  title={Koopman operator, geometry, and learning},
  author={Mezic, Igor},
  journal={arXiv preprint arXiv:2010.05377},
  year={2020}
}

@article{koopman1931hamiltonian,
  title={Hamiltonian systems and transformation in Hilbert space},
  author={Koopman, Bernard O},
  journal={Proceedings of the national academy of sciences of the united states of america},
  volume={17},
  number={5},
  pages={315},
  year={1931},
  publisher={National Academy of Sciences}
}

@article{mezic2005spectral,
  title={Spectral properties of dynamical systems, model reduction and decompositions},
  author={Mezi{\'c}, Igor},
  journal={Nonlinear Dynamics},
  volume={41},
  number={1},
  pages={309--325},
  year={2005},
  publisher={Springer}
}

@phdthesis{mezic1994geometrical,
  title={On the geometrical and statistical properties of dynamical systems: theory and applications},
  author={Mezic, Igor},
  year={1994},
  school={California Institute of Technology}
}

@article{brunton2021modern,
  title={Modern Koopman theory for dynamical systems},
  author={Brunton, Steven L and Budi{\v{s}}i{\'c}, Marko and Kaiser, Eurika and Kutz, J Nathan},
  journal={arXiv preprint arXiv:2102.12086},
  year={2021}
}

@article{morton2018deep,
  title={Deep dynamical modeling and control of unsteady fluid flows},
  author={Morton, Jeremy and Jameson, Antony and Kochenderfer, Mykel J and Witherden, Freddie},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{takeishi2017learning,
  title={Learning Koopman invariant subspaces for dynamic mode decomposition},
  author={Takeishi, Naoya and Kawahara, Yoshinobu and Yairi, Takehisa},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{korda2018linear,
  title={Linear predictors for nonlinear dynamical systems: Koopman operator meets model predictive control},
  author={Korda, Milan and Mezi{\'c}, Igor},
  journal={Automatica},
  volume={93},
  pages={149--160},
  year={2018},
  publisher={Elsevier}
}

@article{das2020koopman,
  title={Koopman spectra in reproducing kernel Hilbert spaces},
  author={Das, Suddhasattwa and Giannakis, Dimitrios},
  journal={Applied and Computational Harmonic Analysis},
  volume={49},
  number={2},
  pages={573--607},
  year={2020},
  publisher={Elsevier}
}

@article{koopman1932dynamical,
  title={Dynamical systems of continuous spectra},
  author={Koopman, Bernard O and Neumann, J v},
  journal={Proceedings of the National Academy of Sciences},
  volume={18},
  number={3},
  pages={255--263},
  year={1932},
  publisher={National Acad Sciences}
}

@article{mezic2022numerical,
  title={On numerical approximations of the koopman operator},
  author={Mezi{\'c}, Igor},
  journal={Mathematics},
  volume={10},
  number={7},
  pages={1180},
  year={2022},
  publisher={MDPI}
}

@incollection{pytorch, 
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith}, 
booktitle = {Advances in Neural Information Processing Systems 32}, 
pages = {8024--8035}, 
year = {2019}, 
publisher = {Curran Associates, Inc.}, 
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf} 
}


@book{brunton2022data,
  title={Data-driven science and engineering: Machine learning, dynamical systems, and control},
  author={Brunton, Steven L and Kutz, J Nathan},
  year={2022},
  publisher={Cambridge University Press}
}

@article{benner2015survey,
  title={A survey of projection-based model reduction methods for parametric dynamical systems},
  author={Benner, Peter and Gugercin, Serkan and Willcox, Karen},
  journal={SIAM review},
  volume={57},
  number={4},
  pages={483--531},
  year={2015},
  publisher={SIAM}
}

@article{rowley2017model,
  title={Model reduction for flow analysis and control},
  author={Rowley, Clarence W and Dawson, Scott TM},
  journal={Annu. Rev. Fluid Mech},
  volume={49},
  number={1},
  pages={387--417},
  year={2017}
}

@inproceedings{farahmand2016learning,
  title={Learning to control partial differential equations: Regularized fitted Q-iteration approach},
  author={Farahmand, Amir-massoud and Nabi, Saleh and Grover, Piyush and Nikovski, Daniel N},
  booktitle={2016 IEEE 55th Conference on Decision and Control (CDC)},
  pages={4578--4585},
  year={2016},
  organization={IEEE}
}

@article{nabi2022robust,
  title={Robust preconditioned one-shot methods and direct-adjoint-looping for optimizing Reynolds-averaged turbulent flows},
  author={Nabi, Saleh and Grover, Piyush and Caulfield, CP},
  journal={Computers \& Fluids},
  volume={238},
  pages={105390},
  year={2022},
  publisher={Elsevier}
}

@article{lucia2004reduced,
  title={Reduced-order modeling: new approaches for computational physics},
  author={Lucia, David J and Beran, Philip S and Silva, Walter A},
  journal={Progress in aerospace sciences},
  volume={40},
  number={1-2},
  pages={51--117},
  year={2004},
  publisher={Elsevier}
}

@article{ahmed2021closures,
  title={On closures for reduced order models—A spectrum of first-principle to machine-learned avenues},
  author={Ahmed, Shady E and Pawar, Suraj and San, Omer and Rasheed, Adil and Iliescu, Traian and Noack, Bernd R},
  journal={Physics of Fluids},
  volume={33},
  number={9},
  pages={091301},
  year={2021},
  publisher={AIP Publishing LLC}
}



@book{holmes2012turbulence,
  title={Turbulence, coherent structures, dynamical systems and symmetry},
  author={Holmes, Philip and Lumley, John L and Berkooz, Gahl and Rowley, Clarence W},
  year={2012},
  publisher={Cambridge university press}
}

@article{lee2020model,
  title={Model reduction of dynamical systems on nonlinear manifolds using deep convolutional autoencoders},
  author={Lee, Kookjin and Carlberg, Kevin T},
  journal={Journal of Computational Physics},
  volume={404},
  pages={108973},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{nabi2020improving,
  title={Improving LiDAR performance on complex terrain using CFD-based correction and direct-adjoint-loop optimization},
  author={Nabi, S and Nishio, N and Grover, P and Matai, R and Kajiyama, Y and Kotake, N and Kameyama, S and Yoshiki, W and Iida, M},
  booktitle={Journal of Physics: Conference Series},
  volume={1452},
  pages={012082},
  year={2020},
  organization={IOP Publishing}
}



@article{jones2020characterising,
  title={Characterising the Digital Twin: A systematic literature review},
  author={Jones, David and Snider, Chris and Nassehi, Aydin and Yon, Jason and Hicks, Ben},
  journal={CIRP Journal of Manufacturing Science and Technology},
  volume={29},
  pages={36--52},
  year={2020},
  publisher={Elsevier}
}

@book{noack2011reduced,
  title={Reduced-order modelling for flow control},
  author={Noack, Bernd R and Morzynski, Marek and Tadmor, Gilead},
  volume={528},
  year={2011},
  publisher={Springer Science \& Business Media}
}



@article{fries2022lasdi,
  title={Lasdi: Parametric latent space dynamics identification},
  author={Fries, William D and He, Xiaolong and Choi, Youngsoo},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={399},
  pages={115436},
  year={2022},
  publisher={Elsevier}
}

@article{he2022glasdi,
  title={gLaSDI: Parametric Physics-informed Greedy Latent Space Dynamics Identification},
  author={He, Xiaolong and Choi, Youngsoo and Fries, William D and Belof, Jon and Chen, Jiun-Shyan},
  journal={arXiv preprint arXiv:2204.12005},
  year={2022}
}

@article{cranmer2020discovering,
  title={Discovering symbolic models from deep learning with inductive biases},
  author={Cranmer, Miles and Sanchez Gonzalez, Alvaro and Battaglia, Peter and Xu, Rui and Cranmer, Kyle and Spergel, David and Ho, Shirley},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17429--17442},
  year={2020}
}




@article{liu2022physics,
  title={Physics-Informed Koopman Network},
  author={Liu, Yuying and Sholokhov, Aleksei and Mansour, Hassan and Nabi, Saleh},
  journal={arXiv preprint arXiv:2211.09419},
  year={2022}
}



@article{qian2020lift,
  title={Lift \& learn: Physics-informed machine learning for large-scale nonlinear dynamical systems},
  author={Qian, Elizabeth and Kramer, Boris and Peherstorfer, Benjamin and Willcox, Karen},
  journal={Physica D: Nonlinear Phenomena},
  volume={406},
  pages={132401},
  year={2020},
  publisher={Elsevier}
}

@article{peherstorfer2016data,
  title={Data-driven operator inference for nonintrusive projection-based model reduction},
  author={Peherstorfer, Benjamin and Willcox, Karen},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={306},
  pages={196--215},
  year={2016},
  publisher={Elsevier}
}

@article{rackauckas2020udes,
  title={Universal differential equations for scientific machine learning},
  author={Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali and Edelman, Alan},
  journal={arXiv preprint arXiv:2001.04385},
  year={2020}
}

@article{chen2021discovering,
  title={Discovering State Variables Hidden in Experimental Data},
  author={Chen, Boyuan and Huang, Kuang and Raghupathi, Sunand and Chandratreya, Ishaan and Du, Qiang and Lipson, Hod},
  journal={arXiv preprint arXiv:2112.10755},
  year={2021}
}

@article{delahunt2022sindynoise,
  title={A toolkit for data-driven discovery of governing equations in high-noise regimes},
  author={Delahunt, Charles B and Kutz, J Nathan},
  journal={IEEE Access},
  volume={10},
  pages={31210--31234},
  year={2022},
  publisher={IEEE}
}

@article{chen2018neural,
  title={Neural ordinary differential equations},
  author={Chen, Ricky TQ and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@incollection{NEURIPS2019_9015, 
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith}, 
booktitle = {Advances in Neural Information Processing Systems 32}, 
pages = {8024--8035}, 
year = {2019}, 
publisher = {Curran Associates, Inc.}, 
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf} 
}


@article{burgers1948mathematical,
  title={A mathematical model illustrating the theory of turbulence},
  author={Burgers, Johannes Martinus},
  journal={Advances in applied mechanics},
  volume={1},
  pages={171--199},
  year={1948},
  publisher={Elsevier}
}

@book{trefethen2000spectral,
  title={Spectral methods in MATLAB},
  author={Trefethen, Lloyd N},
  year={2000},
  publisher={SIAM}
}

@inproceedings{kojimalearning,
  title={Learning Deep Input-Output Stable Dynamics},
  author={Kojima, Ryosuke and Okamoto, Yuji},
  year={2022},
  booktitle={Advances in Neural Information Processing Systems}
}

@inproceedings{otterness2017evaluation,
  title={An evaluation of the NVIDIA TX1 for supporting real-time computer-vision workloads},
  author={Otterness, Nathan and Yang, Ming and Rust, Sarah and Park, Eunbyung and Anderson, James H and Smith, F Donelson and Berg, Alex and Wang, Shige},
  booktitle={2017 IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS)},
  pages={353--364},
  year={2017},
  organization={IEEE}
}

@book{duriez2017machine,
  title={Machine learning control-taming nonlinear dynamics and turbulence},
  author={Duriez, Thomas and Brunton, Steven L and Noack, Bernd R},
  volume={116},
  year={2017},
  publisher={Springer}
}

@article{patel2021global,
  title={Global convergence and stability of stochastic gradient descent},
  author={Patel, Vivak and Tian, Bowen and Zhang, Shushu},
  journal={arXiv preprint arXiv:2110.01663},
  year={2021}
}

@article{friedlander2012hybrid,
  title={Hybrid deterministic-stochastic methods for data fitting},
  author={Friedlander, Michael P and Schmidt, Mark},
  journal={SIAM Journal on Scientific Computing},
  volume={34},
  number={3},
  pages={A1380--A1405},
  year={2012},
  publisher={SIAM}
}

@article{subramanian2022adaptive,
  title={Adaptive Self-supervision Algorithms for Physics-informed Neural Networks},
  author={Subramanian, Shashank and Kirby, Robert M and Mahoney, Michael W and Gholami, Amir},
  journal={arXiv preprint arXiv:2207.04084},
  year={2022}
}

@book{shapiro2021lectures,
  title={Lectures on stochastic programming: modeling and theory},
  author={Shapiro, Alexander and Dentcheva, Darinka and Ruszczynski, Andrzej},
  year={2021},
  publisher={SIAM}
}

@article{jumper2021alphafold,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
  journal={Nature},
  volume={596},
  number={7873},
  pages={583--589},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@book{fornberg1998practical,
  title={A practical guide to pseudospectral methods},
  author={Fornberg, Bengt},
  number={1},
  year={1998},
  publisher={Cambridge university press}
}

@book{trefethen2022numerical,
  title={Numerical linear algebra},
  author={Trefethen, Lloyd N and Bau, David},
  volume={181},
  year={2022},
  publisher={Siam}
}



@article{Edgar2019,
author = {Edgar, Matthew P. and Gibson, Graham M. and Padgett, Miles J.},
doi = {10.1038/s41566-018-0300-7},
file = {:Users/aksh/Documents/Papers/2019/Edgar, Gibson, Padgett/Principles and prospects for single-pixel imaging/Edgar, Gibson, Padgett - 2019 - Principles and prospects for single-pixel imaging.pdf:pdf},
isbn = {4156601803},
issn = {1749-4885},
journal = {Nature Photonics},
mendeley-groups = {Compressive sensing},
month = {jan},
number = {1},
pages = {13--20},
title = {{Principles and prospects for single-pixel imaging}},
url = {http://www.nature.com/articles/s41566-018-0300-7},
volume = {13},
year = {2019}
}

@article{pittman1995optical,
  title={Optical imaging by means of two-photon quantum entanglement},
  author={Pittman, Todd B and Shih, YH and Strekalov, DV and Sergienko, Alexander V},
  journal={Physical Review A},
  volume={52},
  number={5},
  pages={R3429},
  year={1995},
  publisher={APS}
}

@article{duarte2008single,
  title={Single-pixel imaging via compressive sampling},
  author={Duarte, Marco F and Davenport, Mark A and Takhar, Dharmpal and Laska, Jason N and Sun, Ting and Kelly, Kevin F and Baraniuk, Richard G},
  journal={IEEE signal processing magazine},
  volume={25},
  number={2},
  pages={83--91},
  year={2008},
  publisher={IEEE}
}

@article{donoho2006compressed,
  title={Compressed sensing},
  author={Donoho, David L},
  journal={IEEE Transactions on information theory},
  volume={52},
  number={4},
  pages={1289--1306},
  year={2006},
  publisher={IEEE}
}

@inproceedings{candes2006compressive,
  title={Compressive sampling},
  author={Cand{\`e}s, Emmanuel J and others},
  booktitle={Proceedings of the international congress of mathematicians},
  volume={3},
  pages={1433--1452},
  year={2006},
  organization={Madrid, Spain}
}

@article{baraniuk2008simple,
  title={A simple proof of the restricted isometry property for random matrices},
  author={Baraniuk, Richard and Davenport, Mark and DeVore, Ronald and Wakin, Michael},
  journal={Constructive approximation},
  volume={28},
  pages={253--263},
  year={2008},
  publisher={Springer}
}

@article{baraniuk2014introduction,
  title={An introduction to compressive sensing},
  author={Baraniuk, Richard and Davenport, Mark A and Duarte, Marco F and Hegde, Chinmay},
  year={2014},
  publisher={Rice University}
}
@inproceedings{sampsell1993overview,
  title={An overview of the digital micromirror device (DMD) and its application to projection displays},
  author={Sampsell, JB},
  booktitle={Society for Information Display International Symposium Digest of Technical Paper, 1993},
  volume={24},
  pages={1012--1015},
  year={1993}
}

@article{skodras2001jpeg,
  title={The JPEG 2000 still image compression standard},
  author={Skodras, Athanassios and Christopoulos, Charilaos and Ebrahimi, Touradj},
  journal={IEEE Signal processing magazine},
  volume={18},
  number={5},
  pages={36--58},
  year={2001},
  publisher={IEEE}
}

@article{bian2016multispectral,
  title={Multispectral imaging using a single bucket detector},
  author={Bian, Liheng and Suo, Jinli and Situ, Guohai and Li, Ziwei and Fan, Jingtao and Chen, Feng and Dai, Qionghai},
  journal={Scientific reports},
  volume={6},
  number={1},
  pages={1--7},
  year={2016},
  publisher={Springer}
}

@article{magalhaes2012high,
  title={High-resolution hyperspectral single-pixel imaging system based on compressive sensing},
  author={Magalh{\~a}es, Filipe and Abolbashari, Mehrdad and Ara{\'u}jo, Francisco M and Correia, Miguel V and Farahi, Faramarz},
  journal={Optical Engineering},
  volume={51},
  number={7},
  pages={071406--071406},
  year={2012},
  publisher={Society of Photo-Optical Instrumentation Engineers}
}

@article{radwell2014single,
  title={Single-pixel infrared and visible microscope},
  author={Radwell, Neal and Mitchell, Kevin J and Gibson, Graham M and Edgar, Matthew P and Bowman, Richard and Padgett, Miles J},
  journal={Optica},
  volume={1},
  number={5},
  pages={285--289},
  year={2014},
  publisher={Optica Publishing Group}
}

@article{gibson2020single,
  title={Single-pixel imaging 12 years on: a review},
  author={Gibson, Graham M and Johnson, Steven D and Padgett, Miles J},
  journal={Optics express},
  volume={28},
  number={19},
  pages={28190--28208},
  year={2020},
  publisher={Optica Publishing Group}
}

@article{zhang2017fast,
  title={Fast Fourier single-pixel imaging via binary illumination},
  author={Zhang, Zibang and Wang, Xueying and Zheng, Guoan and Zhong, Jingang},
  journal={Scientific reports},
  volume={7},
  number={1},
  pages={12029},
  year={2017},
  publisher={Nature Publishing Group UK London}
}

@article{sun2017russian,
  title={A Russian Dolls ordering of the Hadamard basis for compressive single-pixel imaging},
  author={Sun, Ming-Jie and Meng, Ling-Tong and Edgar, Matthew P and Padgett, Miles J and Radwell, Neal},
  journal={Scientific reports},
  volume={7},
  number={1},
  pages={3464},
  year={2017},
  publisher={Nature Publishing Group UK London}
}

@article{xu20181000,
  title={1000 fps computational ghost imaging using LED-based structured illumination},
  author={Xu, Zi-Hao and Chen, Wen and Penuelas, Jos{\'e} and Padgett, Miles and Sun, Ming-Jie},
  journal={Optics express},
  volume={26},
  number={3},
  pages={2427--2434},
  year={2018},
  publisher={Optica Publishing Group}
}

@article{katz2009compressive,
  title={Compressive ghost imaging},
  author={Katz, Ori and Bromberg, Yaron and Silberberg, Yaron},
  journal={Applied Physics Letters},
  volume={95},
  number={13},
  pages={131110},
  year={2009},
  publisher={American Institute of Physics}
}

@article{lyu2017deep,
  title={Deep-learning-based ghost imaging},
  author={Lyu, Meng and Wang, Wei and Wang, Hao and Wang, Haichao and Li, Guowei and Chen, Ni and Situ, Guohai},
  journal={Scientific reports},
  volume={7},
  number={1},
  pages={17865},
  year={2017},
  publisher={Nature Publishing Group UK London}
}

@article{higham2018deep,
  title={Deep learning for real-time single-pixel video},
  author={Higham, Catherine F and Murray-Smith, Roderick and Padgett, Miles J and Edgar, Matthew P},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={2369},
  year={2018},
  publisher={Nature Publishing Group UK London}
}

@article{wang2019learning,
  title={Learning from simulation: An end-to-end deep-learning approach for computational ghost imaging},
  author={Wang, Fei and Wang, Hao and Wang, Haichao and Li, Guowei and Situ, Guohai},
  journal={Optics express},
  volume={27},
  number={18},
  pages={25560--25572},
  year={2019},
  publisher={Optica Publishing Group}
}

@article{wang2022single,
  title={Single-pixel imaging using physics enhanced deep learning},
  author={Wang, Fei and Wang, Chenglong and Deng, Chenjin and Han, Shensheng and Situ, Guohai},
  journal={Photonics Research},
  volume={10},
  number={1},
  pages={104--110},
  year={2022},
  publisher={Optica Publishing Group}
}

@article{bian2018experimental,
  title={Experimental comparison of single-pixel imaging algorithms},
  author={Bian, Liheng and Suo, Jinli and Dai, Qionghai and Chen, Feng},
  journal={JOSA A},
  volume={35},
  number={1},
  pages={78--87},
  year={2018},
  publisher={Optica Publishing Group}
}

@article{guo2016multilayer,
  title={Multilayer fluorescence imaging on a single-pixel detector},
  author={Guo, Kaikai and Jiang, Shaowei and Zheng, Guoan},
  journal={Biomedical optics express},
  volume={7},
  number={7},
  pages={2425--2431},
  year={2016},
  publisher={Optica Publishing Group}
}


@article{li2017efficient,
  title={Efficient single-pixel multispectral imaging via non-mechanical spatio-spectral modulation},
  author={Li, Ziwei and Suo, Jinli and Hu, Xuemei and Deng, Chao and Fan, Jingtao and Dai, Qionghai},
  journal={Scientific Reports},
  volume={7},
  number={1},
  pages={41435},
  year={2017},
  publisher={Nature Publishing Group UK London}
}

@article{sun20133d,
  title={3D computational imaging with single-pixel detectors},
  author={Sun, Baoqing and Edgar, Matthew P and Bowman, Richard and Vittert, Liberty E and Welsh, Stuart and Bowman, Adrian and Padgett, Miles J},
  journal={Science},
  volume={340},
  number={6134},
  pages={844--847},
  year={2013},
  publisher={American Association for the Advancement of Science}
}

@article{chen2013ghost,
  title={Ghost imaging for three-dimensional optical security},
  author={Chen, Wen and Chen, Xudong},
  journal={Applied Physics Letters},
  volume={103},
  number={22},
  pages={221106},
  year={2013},
  publisher={American Institute of Physics}
}

@article{zhao2012ghost,
  title={Ghost imaging lidar via sparsity constraints},
  author={Zhao, Chengqiang and Gong, Wenlin and Chen, Mingliang and Li, Enrong and Wang, Hui and Xu, Wendong and Han, Shensheng},
  journal={Applied Physics Letters},
  volume={101},
  number={14},
  pages={141123},
  year={2012},
  publisher={American Institute of Physics}
}

@article{li2014ghost,
  title={Ghost imaging of a moving target with an unknown constant speed},
  author={Li, Enrong and Bo, Zunwang and Chen, Mingliang and Gong, Wenlin and Han, Shensheng},
  journal={Applied Physics Letters},
  volume={104},
  number={25},
  pages={251120},
  year={2014},
  publisher={American Institute of Physics}
}

@article{cheng2009ghost,
  title={Ghost imaging through turbulent atmosphere},
  author={Cheng, Jing},
  journal={Optics express},
  volume={17},
  number={10},
  pages={7916--7921},
  year={2009},
  publisher={Optica Publishing Group}
}

@article{zhang2010correlated,
  title={Correlated imaging through atmospheric turbulence},
  author={Zhang, Pengli and Gong, Wenlin and Shen, Xia and Han, Shensheng},
  journal={Physical Review A},
  volume={82},
  number={3},
  pages={033817},
  year={2010},
  publisher={APS}
}


@article{gong2010method,
  title={A method to improve the visibility of ghost images obtained by thermal light},
  author={Gong, Wenlin and Han, Shensheng},
  journal={Physics Letters A},
  volume={374},
  number={8},
  pages={1005--1008},
  year={2010},
  publisher={Elsevier}
}

@article{suo2016signal,
  title={Signal-dependent noise removal for color videos using temporal and cross-channel priors},
  author={Suo, Jinli and Bian, Liheng and Chen, Feng and Dai, Qionghai},
  journal={Journal of Visual Communication and Image Representation},
  volume={36},
  pages={130--141},
  year={2016},
  publisher={Elsevier}
}

@article{bian2018experimental,
  title={Experimental comparison of single-pixel imaging algorithms},
  author={Bian, Liheng and Suo, Jinli and Dai, Qionghai and Chen, Feng},
  journal={JOSA A},
  volume={35},
  number={1},
  pages={78--87},
  year={2018},
  publisher={Optica Publishing Group}
}

@article{czajkowski2018real,
  title={Real-time single-pixel video imaging with Fourier domain regularization},
  author={Czajkowski, Krzysztof M and Pastuszczak, Anna and Koty{\'n}ski, Rafa{\l}},
  journal={Optics express},
  volume={26},
  number={16},
  pages={20009--20022},
  year={2018},
  publisher={Optica Publishing Group}
}

@article{wang2022single,
  title={Single-pixel imaging using physics enhanced deep learning},
  author={Wang, Fei and Wang, Chenglong and Deng, Chenjin and Han, Shensheng and Situ, Guohai},
  journal={Photonics Research},
  volume={10},
  number={1},
  pages={104--110},
  year={2022},
  publisher={Optica Publishing Group}
}

@inproceedings{bora2017compressed,
  title={Compressed sensing using generative models},
  author={Bora, Ashish and Jalal, Ajil and Price, Eric and Dimakis, Alexandros G},
  booktitle={International Conference on Machine Learning},
  pages={537--546},
  year={2017},
  organization={PMLR}
}

@article{ferri2010differential,
  title={Differential ghost imaging},
  author={Ferri, F and Magatti, D and Lugiato, LA and Gatti, A},
  journal={Physical review letters},
  volume={104},
  number={25},
  pages={253603},
  year={2010},
  publisher={APS}
}

@article{gong2010method,
  title={A method to improve the visibility of ghost images obtained by thermal light},
  author={Gong, Wenlin and Han, Shensheng},
  journal={Physics Letters A},
  volume={374},
  number={8},
  pages={1005--1008},
  year={2010},
  publisher={Elsevier}
}

@article{tithof2017bifurcations,
  title={Bifurcations in a quasi-two-dimensional Kolmogorov-like flow},
  author={Tithof, Jeffrey and Suri, Balachandra and Pallantla, Ravi Kumar and Grigoriev, Roman O and Schatz, Michael F},
  journal={Journal of Fluid Mechanics},
  volume={828},
  pages={837--866},
  year={2017},
  publisher={Cambridge University Press}
}

@article{dovzhenko1981generation,
  title={Generation of vortices in axisymmetric shear flow},
  author={Dovzhenko, VA and Obukhov, AM and Ponomarev, VM},
  journal={Akademiia Nauk SSSR Izvestiia Mekhanika Zhidkosti i Gaza},
  volume={17},
  pages={27--36},
  year={1981}
}

@article{suri2017forecasting,
  title={Forecasting fluid flows using the geometry of turbulence},
  author={Suri, Balachandra and Tithof, Jeffrey and Grigoriev, Roman O and Schatz, Michael F},
  journal={Physical review letters},
  volume={118},
  number={11},
  pages={114501},
  year={2017},
  publisher={APS}
}

@article{wan2018data,
  title={Data-assisted reduced-order modeling of extreme events in complex dynamical systems},
  author={Wan, Zhong Yi and Vlachas, Pantelis and Koumoutsakos, Petros and Sapsis, Themistoklis},
  journal={PloS one},
  volume={13},
  number={5},
  pages={e0197704},
  year={2018},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{wang2022single,
  title={Single-pixel imaging using physics enhanced deep learning},
  author={Wang, Fei and Wang, Chenglong and Deng, Chenjin and Han, Shensheng and Situ, Guohai},
  journal={Photonics Research},
  volume={10},
  number={1},
  pages={104--110},
  year={2022},
  publisher={Optica Publishing Group}
}

@article{wang2020machine,
  title={Machine vision for natural gas methane emissions detection using an infrared camera},
  author={Wang, Jingfan and Tchapmi, Lyne P and Ravikumar, Arvind P and McGuire, Mike and Bell, Clay S and Zimmerle, Daniel and Savarese, Silvio and Brandt, Adam R},
  journal={Applied Energy},
  volume={257},
  pages={113998},
  year={2020},
  publisher={Elsevier}
}

@article{zivkovic2006efficient,
  title={Efficient adaptive density estimation per image pixel for the task of background subtraction},
  author={Zivkovic, Zoran and Van Der Heijden, Ferdinand},
  journal={Pattern recognition letters},
  volume={27},
  number={7},
  pages={773--780},
  year={2006},
  publisher={Elsevier}
}

@inproceedings{zivkovic2004improved,
  title={Improved adaptive Gaussian mixture model for background subtraction},
  author={Zivkovic, Zoran},
  booktitle={Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.},
  volume={2},
  pages={28--31},
  year={2004},
  organization={IEEE}
}

@article{opencv_library, 
    author = {Bradski, G.}, 
    citeulike-article-id = {2236121}, 
    journal = {Dr. Dobb's Journal of Software Tools}, 
    keywords = {bibtex-import}, 
    posted-at = {2008-01-15 19:21:54}, 
    priority = {4}, 
    title = {{The OpenCV Library}}, 
    year = {2000} 
}